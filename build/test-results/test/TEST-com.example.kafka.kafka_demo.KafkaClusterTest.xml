<?xml version="1.0" encoding="UTF-8"?>
<testsuite name="com.example.kafka.kafka_demo.KafkaClusterTest" tests="1" skipped="0" failures="1" errors="0" timestamp="2019-08-22T23:51:26" hostname="Prachis-MBP" time="0.511">
  <properties/>
  <testcase name="testTemplate" classname="com.example.kafka.kafka_demo.KafkaClusterTest" time="0.511">
    <failure message="org.apache.kafka.common.KafkaException: Failed to construct kafka producer" type="org.apache.kafka.common.KafkaException">org.apache.kafka.common.KafkaException: Failed to construct kafka producer
	at org.apache.kafka.clients.producer.KafkaProducer.&lt;init&gt;(KafkaProducer.java:457)
	at org.apache.kafka.clients.producer.KafkaProducer.&lt;init&gt;(KafkaProducer.java:289)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory.createKafkaProducer(DefaultKafkaProducerFactory.java:318)
	at org.springframework.kafka.core.DefaultKafkaProducerFactory.createProducer(DefaultKafkaProducerFactory.java:305)
	at org.springframework.kafka.core.KafkaTemplate.getTheProducer(KafkaTemplate.java:448)
	at org.springframework.kafka.core.KafkaTemplate.doSend(KafkaTemplate.java:378)
	at org.springframework.kafka.core.KafkaTemplate.send(KafkaTemplate.java:193)
	at org.springframework.kafka.core.KafkaTemplate.sendDefault(KafkaTemplate.java:172)
	at com.example.kafka.kafka_demo.KafkaClusterTest.testTemplate(KafkaClusterTest.java:122)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)
	at org.junit.rules.RunRules.evaluate(RunRules.java:20)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.runTestClass(JUnitTestClassExecutor.java:110)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.execute(JUnitTestClassExecutor.java:58)
	at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecutor.execute(JUnitTestClassExecutor.java:38)
	at org.gradle.api.internal.tasks.testing.junit.AbstractJUnitTestClassProcessor.processTestClass(AbstractJUnitTestClassProcessor.java:62)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:51)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)
	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)
	at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:118)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:175)
	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:157)
	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:404)
	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:63)
	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:46)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:55)
	at java.lang.Thread.run(Thread.java:748)
Caused by: org.apache.kafka.common.KafkaException: io.confluent.kafka.serializers.KafkaAvroDeserializer is not an instance of org.apache.kafka.common.serialization.Serializer
	at org.apache.kafka.common.config.AbstractConfig.getConfiguredInstance(AbstractConfig.java:304)
	at org.apache.kafka.clients.producer.KafkaProducer.&lt;init&gt;(KafkaProducer.java:370)
	... 57 more
</failure>
  </testcase>
  <system-out><![CDATA[09:51:25.187 [Test worker] INFO kafka.utils.Log4jControllerRegistration$ - Registered kafka:type=kafka.Log4jController MBean
09:51:25.252 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT
09:51:25.253 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:host.name=localhost
09:51:25.253 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:java.version=1.8.0_221
09:51:25.253 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:java.vendor=Oracle Corporation
09:51:25.253 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_221.jdk/Contents/Home/jre
09:51:25.254 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:java.class.path=/Users/prachi/Documents/InteliJWorkplace/kafka_demo/build/classes/java/test:/Users/prachi/Documents/InteliJWorkplace/kafka_demo/build/resources/test:/Users/prachi/Documents/InteliJWorkplace/kafka_demo/build/classes/java/main:/Users/prachi/Documents/InteliJWorkplace/kafka_demo/build/resources/main:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-web/2.1.7.RELEASE/fa43baf40bde3ecdb93ac9c545dd39f82ab29c35/spring-boot-starter-web-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.avro/avro-maven-plugin/1.9.0/1dcdd14d3075f7610cbce0c14853878ed4155034/avro-maven-plugin-1.9.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/io.confluent/kafka-avro-serializer/3.3.1/523114bba98a219c029116c8c72ca6e1c817565a/kafka-avro-serializer-3.3.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-json/2.1.7.RELEASE/9c12f046a7c4ae110d89163a491ad0d7cf036e79/spring-boot-starter-json-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.avro/avro-compiler/1.9.0/275e1b5efa61429d8f3b4d117022b5581b210732/avro-compiler-1.9.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/io.confluent/kafka-schema-registry-client/3.3.1/a90a87192bd82119330a1e46d9f8ba84a149286e/kafka-schema-registry-client-3.3.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.kafka/spring-kafka-test/2.2.8.RELEASE/caaa76db4de843ccbe72099a15acb6f835b2653d/spring-kafka-test-2.2.8.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka_2.11/2.0.1/74edf9dcfe1b298422dcf133e8f02b64caa9c2ed/kafka_2.11-2.0.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka_2.11/2.0.1/eae5412d901a120f9042e6e1032c6fa2f8910a7e/kafka_2.11-2.0.1-test.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.datatype/jackson-datatype-jdk8/2.9.9/4b04126963103216c9c43b0f34bbc36315654204/jackson-datatype-jdk8-2.9.9.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.datatype/jackson-datatype-jsr310/2.9.9/a33df137557793b0404a486888dbe049f7abeeeb/jackson-datatype-jsr310-2.9.9.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.module/jackson-module-parameter-names/2.9.9/a92facb55a2538e7b2fe14294570a18b823ad431/jackson-module-parameter-names-2.9.9.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.avro/avro/1.9.0/ee9524dab06632dcf9adea769376380d69810ead/avro-1.9.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.9.4/498bbc3b94f566982c7f7c6d4d303fce365529be/jackson-databind-2.9.4.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.9.4/a9a71ec1aa37da47db168fede9a4a5fb5e374320/jackson-core-2.9.4.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.codehaus.jackson/jackson-mapper-asl/1.9.13/1ee2f2bed0e5dd29d1cb155a166e6f8d50bbddb7/jackson-mapper-asl-1.9.13.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.codehaus.jackson/jackson-core-asl/1.9.13/3c304d70f42f832e0a86d45bd437f692129299a4/jackson-core-asl-1.9.13.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-test/2.1.7.RELEASE/39e82379a28c217ab892eb00ef601dc0571f56a4/spring-boot-starter-test-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter/2.1.7.RELEASE/e23f4e9460e0e2220b444e40fc7fd6e95f66e0fe/spring-boot-starter-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.kafka/spring-kafka/2.2.8.RELEASE/2ada45678b48af5289a95f5f03066b568926fdc8/spring-kafka-2.2.8.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-project/2.0.11/adc2114aa1d9b7a599aa226849ad7f463de3cadc/maven-project-2.0.11.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven.shared/file-management/1.2.1/8f98bcaa7fd3625a172fd3de10bba8c32b9820ea/file-management-1.2.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-settings/2.0.11/3f81af64ca039c3ef000ecee0a31668a2b9a432d/maven-settings-2.0.11.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-profile/2.0.11/130057d04b0e914509f1223a85a6b1e83b08957f/maven-profile-2.0.11.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven.shared/maven-shared-io/1.1/2e1d57be05ecac7dbe56a3c73b113e98f22240f/maven-shared-io-1.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-artifact-manager/2.0.11/6c8764f10c7bd2ef8ad050190e3922be6078ecca/maven-artifact-manager-2.0.11.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-plugin-registry/2.0.11/c4703e5496fa93dcea339f9cc665290f9179c108/maven-plugin-registry-2.0.11.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.codehaus.plexus/plexus-container-default/1.0-alpha-9/50596183cd7b688d9d7b6d868a0193ca1a8a7b3d/plexus-container-default-1.0-alpha-9.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/junit/junit/4.12/2973d150c0dc1fefe998f834810d68f278ea58ec/junit-4.12.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-tomcat/2.1.7.RELEASE/11f2a86aefefba72a4efe5ff18f4165a4b4e78b/spring-boot-starter-tomcat-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.hibernate.validator/hibernate-validator/6.0.17.Final/af73055fc4a103ab347c56e7da5a143d68a0170/hibernate-validator-6.0.17.Final.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-webmvc/5.1.9.RELEASE/b9d4a2140488f0e6f9aa231e7938ae18da77b637/spring-webmvc-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-web/5.1.9.RELEASE/9fe4390420fdd0b63dc4ed90d9027dafa9f74f80/spring-web-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-plugin-api/2.0.11/f7aa99d1f2c0e941b60c107194dc5f9d107a0d77/maven-plugin-api-2.0.11.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/io.confluent/common-config/3.3.1/8906a6853baf3a530d3934e6fe46db8ac9a0c3ee/common-config-3.3.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/io.confluent/common-utils/3.3.1/370b5cffef42277d4b0fa4391afba2a64fcfe500/common-utils-3.3.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-clients/2.0.1/61576d880bafea639d6b091adbaf260c729a3ceb/kafka-clients-2.0.1-test.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-clients/2.0.1/db87f87e64714faff9c90fdc97a06c7d8e79b672/kafka-clients-2.0.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.jayway.jsonpath/json-path/2.4.0/765a4401ceb2dc8d40553c2075eb80a8fa35c2ae/json-path-2.4.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.velocity/velocity-engine-core/2.0/6e5f29e1237b1764a4ce769feeffb85b0b19cfa7/velocity-engine-core-2.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.101tec/zkclient/0.10/c54d4b5a5e89af75a80b6d5857400165ce5188d0/zkclient-0.10.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-logging/2.1.7.RELEASE/6e829f739992a7f368c0af44a08ed89ad2a1972f/spring-boot-starter-logging-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-classic/1.2.3/7c4f3c474fb2c041d8028740440937705ebb473a/logback-classic-1.2.3.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.logging.log4j/log4j-to-slf4j/2.11.2/6d37bf7b046c0ce2669f26b99365a2cfa45c4c18/log4j-to-slf4j-2.11.2.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.slf4j/jul-to-slf4j/1.7.26/8031352b2bb0a49e67818bf04c027aa92e645d5c/jul-to-slf4j-1.7.26.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.zookeeper/zookeeper/3.4.13/31e9937541cef95c4585b547eb2dbd34d3a76f1c/zookeeper-3.4.13.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.yammer.metrics/metrics-core/2.2.0/f82c035cfa786d3cbec362c38c22a5f5b1bc8724/metrics-core-2.2.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.typesafe.scala-logging/scala-logging_2.11/3.9.0/e0dba06b4a763a0e2208182b264421baedbb0df/scala-logging_2.11-3.9.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.26/77100a62c2e6f04b53977b9f541044d7d722693d/slf4j-api-1.7.26.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-annotations/2.9.0/7c10d545325e3a6e72e06381afe469fd40eb701/jackson-annotations-2.9.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-test-autoconfigure/2.1.7.RELEASE/8c9847259e14419d2bcc4eed26bcf48dc56686ef/spring-boot-test-autoconfigure-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-autoconfigure/2.1.7.RELEASE/2c9d3e2c6ea3cb435e99e2973009636b62a9d816/spring-boot-autoconfigure-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-test/2.1.7.RELEASE/70ed88830a08e8baa0b562090168fdba0e92810/spring-boot-test-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot/2.1.7.RELEASE/1599a2ad1fc6d36dbfc2a7c0dd5dab3a0bb27c61/spring-boot-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/javax.annotation/javax.annotation-api/1.3.2/934c04d3cfef185a8008e7bf34331b79730a9d43/javax.annotation-api-1.3.2.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-context/5.1.9.RELEASE/c37f8fe15a5ae4ea1f351bd46167fd492a84eefa/spring-context-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-test/5.1.9.RELEASE/653fa9de816677b3318e7058af54e7ee56866b09/spring-test-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.retry/spring-retry/1.2.4.RELEASE/e5a1e629b2743dc7bbe4a8d07ebe9ff6c3b816ce/spring-retry-1.2.4.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-messaging/5.1.9.RELEASE/fa164c4c2a5299138ed344bc5d424f5f4219e267/spring-messaging-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-tx/5.1.9.RELEASE/a9125e2c8eeb193030f3972c6293616943c55ef2/spring-tx-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aop/5.1.9.RELEASE/bc2312ffad02251b9d472e4a7c0e472a58f50fbf/spring-aop-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-beans/5.1.9.RELEASE/5a03b3983108d73978aec2fa3e681aedad6782c/spring-beans-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-expression/5.1.9.RELEASE/db3a2468c1b7d697ec3b3ec6e5652dc282994fe3/spring-expression-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-core/5.1.9.RELEASE/dc3815439579b4fa0c19970e6b8e5d774af8d988/spring-core-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.yaml/snakeyaml/1.23/ec62d74fe50689c28c0ff5b35d3aebcaa8b5be68/snakeyaml-1.23.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-library/1.3/4785a3c21320980282f9f33d0d1264a69040538f/hamcrest-library-1.3.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-core/1.3/42a25dc3219429f0e5d060061f71acb49bf010a0/hamcrest-core-1.3.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.assertj/assertj-core/3.11.1/fdac3217b804d6900fa3650f17b5cb48e620b140/assertj-core-3.11.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.mockito/mockito-core/2.23.4/a35b6f8ffcfa786771eac7d7d903429e790fdf3f/mockito-core-2.23.4.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.skyscreamer/jsonassert/1.5.0/6c9d5fe2f59da598d9aefc1cfc6528ff3cf32df3/jsonassert-1.5.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.xmlunit/xmlunit-core/2.6.3/cdb208320aed4a7b94fb236cfbf91aeb6d0ede14/xmlunit-core-2.6.3.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-websocket/9.0.22/45974d3443cc15ad9d10239d762d5e15759e6364/tomcat-embed-websocket-9.0.22.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-core/9.0.22/79f39903498b28adacb18fe2ea046edd306295a6/tomcat-embed-core-9.0.22.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-el/9.0.22/4da4b778b635a7e78ca7cd7288253e2e47b88a9f/tomcat-embed-el-9.0.22.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/javax.validation/validation-api/2.0.1.Final/cb855558e6271b1b32e716d24cb85c7f583ce09e/validation-api-2.0.1.Final.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging/3.3.2.Final/3789d00e859632e6c6206adc0c71625559e6e3b0/jboss-logging-3.3.2.Final.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.fasterxml/classmate/1.4.0/291658ac2ce2476256c7115943652c0accb5c857/classmate-1.4.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-model/2.0.11/b4947c88b8f0e19944b1e5d121e2f7dcd2440895/maven-model-2.0.11.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.codehaus.plexus/plexus-interpolation/1.1/66a644c26e8a1cd2945981422c33ba247226a2ef/plexus-interpolation-1.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-artifact/2.0.11/432e01884f40b5d1d0b4706b019322d352c3b77b/maven-artifact-2.0.11.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-repository-metadata/2.0.11/88b1222854edcbf0ca02bfa5484b65c5f9240fdb/maven-repository-metadata-2.0.11.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven.wagon/wagon-provider-api/1.0-beta-2/abd1c9ace6e87c94a4b91f5176aeb09d954b23a3/wagon-provider-api-1.0-beta-2.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.codehaus.plexus/plexus-utils/1.5.6/8fb6b798a4036048b3005e058553bf21a87802ed/plexus-utils-1.5.6.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.commons/commons-lang3/3.8.1/6505a72a097d9270f7a9e7bf42c4238283247755/commons-lang3-3.8.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/joda-time/joda-time/2.10.3/2e5366cf1f77ca3bafffecf6e87d30e1d504e959/joda-time-2.10.3.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-jcl/5.1.9.RELEASE/7c372790c999777d20f364960cf557dd74f890cf/spring-jcl-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.lz4/lz4-java/1.4.1/ad89b11ac280a2992d65e078af06f6709f1fe2fc/lz4-java-1.4.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.xerial.snappy/snappy-java/1.1.7.1/d5190b41f3de61e3b83d692322d58630252bc8c3/snappy-java-1.1.7.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/net.sf.jopt-simple/jopt-simple/5.0.4/4fdac2fbe92dfad86aa6e9301736f6b4342a3f5c/jopt-simple-5.0.4.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.scala-lang/scala-reflect/2.11.12/2bb23c13c527566d9828107ca4108be2a2c06f01/scala-reflect-2.11.12.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.scala-lang/scala-library/2.11.12/bf5534e6fec3d665bd6419c952a929a8bdd4b591/scala-library-2.11.12.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/net.minidev/json-smart/2.3/7396407491352ce4fa30de92efb158adb76b5b/json-smart-2.3.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/net.bytebuddy/byte-buddy/1.9.16/e7d63009be7b87ff1f15b72e5b8c59c897a8d8bd/byte-buddy-1.9.16.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/net.bytebuddy/byte-buddy-agent/1.9.16/fd213511a0a845632456f636e576d24c2d6ac3bc/byte-buddy-agent-1.9.16.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.objenesis/objenesis/2.6/639033469776fd37c08358c6b92a4761feb2af4b/objenesis-2.6.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.vaadin.external.google/android-json/0.0.20131108.vaadin1/fa26d351fe62a6a17f5cda1287c1c6110dec413f/android-json-0.0.20131108.vaadin1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/classworlds/classworlds/1.1-alpha-2/5adf2e681c57d7f48038b602f3ca2254ee82d47/classworlds-1.1-alpha-2.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.commons/commons-compress/1.18/1191f9f2bc0c47a8cce69193feb1ff0a8bcb37d5/commons-compress-1.18.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-core/1.2.3/864344400c3d4d92dfeb0a305dc87d953677c03c/logback-core-1.2.3.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.logging.log4j/log4j-api/2.11.2/f5e9a2ffca496057d6891a3de65128efc636e26e/log4j-api-2.11.2.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/log4j/log4j/1.2.17/5af35056b4d257e4b64b9e8069c0746e8b08629f/log4j-1.2.17.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/jline/jline/0.9.94/99a18e9a44834afdebc467294e1138364c207402/jline-0.9.94.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.yetus/audience-annotations/0.5.0/55762d3191a8d6610ef46d11e8cb70c7667342a3/audience-annotations-0.5.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/io.netty/netty/3.10.6.Final/18ed04a0e502896552854926e908509db2987a00/netty-3.10.6.Final.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/net.minidev/accessors-smart/1.2/c592b500269bfde36096641b01238a8350f8aa31/accessors-smart-1.2.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.ow2.asm/asm/5.0.4/da08b8cce7bbf903602a25a3a163ae252435795/asm-5.0.4.jar
09:51:25.256 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:java.library.path=/Users/prachi/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
09:51:25.256 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:java.io.tmpdir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/
09:51:25.256 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:java.compiler=<NA>
09:51:25.256 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:os.name=Mac OS X
09:51:25.256 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:os.arch=x86_64
09:51:25.256 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:os.version=10.14.5
09:51:25.256 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:user.name=prachi
09:51:25.256 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:user.home=/Users/prachi
09:51:25.256 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer - Server environment:user.dir=/Users/prachi/Documents/InteliJWorkplace/kafka_demo
09:51:25.261 [Test worker] DEBUG org.apache.zookeeper.server.persistence.FileTxnSnapLog - Opening datadir:/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-4438925975171885947 snapDir:/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-944841860734215339
09:51:25.270 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer - Created server with tickTime 500 minSessionTimeout 1000 maxSessionTimeout 10000 datadir /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-4438925975171885947/version-2 snapdir /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-944841860734215339/version-2
09:51:25.285 [Test worker] INFO org.apache.zookeeper.server.NIOServerCnxnFactory - binding to port /127.0.0.1:0
09:51:25.298 [Test worker] DEBUG org.apache.zookeeper.server.ZooKeeperServer - ZKShutdownHandler is not registered, so ZooKeeper server won't take any action on ERROR or SHUTDOWN server state changes
09:51:25.303 [ZkClient-EventThread-19-127.0.0.1:59713] INFO org.I0Itec.zkclient.ZkEventThread - Starting ZkClient event thread.
09:51:25.303 [Test worker] DEBUG org.I0Itec.zkclient.ZkConnection - Creating new ZookKeeper instance to connect to 127.0.0.1:59713.
09:51:25.305 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.13-2d71af4dbe22557fda74f9a9b4309b15a7487f03, built on 06/29/2018 00:39 GMT
09:51:25.306 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Client environment:host.name=localhost
09:51:25.306 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_221
09:51:25.306 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
09:51:25.306 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.8.0_221.jdk/Contents/Home/jre
09:51:25.306 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/Users/prachi/Documents/InteliJWorkplace/kafka_demo/build/classes/java/test:/Users/prachi/Documents/InteliJWorkplace/kafka_demo/build/resources/test:/Users/prachi/Documents/InteliJWorkplace/kafka_demo/build/classes/java/main:/Users/prachi/Documents/InteliJWorkplace/kafka_demo/build/resources/main:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-web/2.1.7.RELEASE/fa43baf40bde3ecdb93ac9c545dd39f82ab29c35/spring-boot-starter-web-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.avro/avro-maven-plugin/1.9.0/1dcdd14d3075f7610cbce0c14853878ed4155034/avro-maven-plugin-1.9.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/io.confluent/kafka-avro-serializer/3.3.1/523114bba98a219c029116c8c72ca6e1c817565a/kafka-avro-serializer-3.3.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-json/2.1.7.RELEASE/9c12f046a7c4ae110d89163a491ad0d7cf036e79/spring-boot-starter-json-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.avro/avro-compiler/1.9.0/275e1b5efa61429d8f3b4d117022b5581b210732/avro-compiler-1.9.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/io.confluent/kafka-schema-registry-client/3.3.1/a90a87192bd82119330a1e46d9f8ba84a149286e/kafka-schema-registry-client-3.3.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.kafka/spring-kafka-test/2.2.8.RELEASE/caaa76db4de843ccbe72099a15acb6f835b2653d/spring-kafka-test-2.2.8.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka_2.11/2.0.1/74edf9dcfe1b298422dcf133e8f02b64caa9c2ed/kafka_2.11-2.0.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka_2.11/2.0.1/eae5412d901a120f9042e6e1032c6fa2f8910a7e/kafka_2.11-2.0.1-test.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.datatype/jackson-datatype-jdk8/2.9.9/4b04126963103216c9c43b0f34bbc36315654204/jackson-datatype-jdk8-2.9.9.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.datatype/jackson-datatype-jsr310/2.9.9/a33df137557793b0404a486888dbe049f7abeeeb/jackson-datatype-jsr310-2.9.9.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.module/jackson-module-parameter-names/2.9.9/a92facb55a2538e7b2fe14294570a18b823ad431/jackson-module-parameter-names-2.9.9.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.avro/avro/1.9.0/ee9524dab06632dcf9adea769376380d69810ead/avro-1.9.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-databind/2.9.4/498bbc3b94f566982c7f7c6d4d303fce365529be/jackson-databind-2.9.4.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-core/2.9.4/a9a71ec1aa37da47db168fede9a4a5fb5e374320/jackson-core-2.9.4.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.codehaus.jackson/jackson-mapper-asl/1.9.13/1ee2f2bed0e5dd29d1cb155a166e6f8d50bbddb7/jackson-mapper-asl-1.9.13.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.codehaus.jackson/jackson-core-asl/1.9.13/3c304d70f42f832e0a86d45bd437f692129299a4/jackson-core-asl-1.9.13.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-test/2.1.7.RELEASE/39e82379a28c217ab892eb00ef601dc0571f56a4/spring-boot-starter-test-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter/2.1.7.RELEASE/e23f4e9460e0e2220b444e40fc7fd6e95f66e0fe/spring-boot-starter-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.kafka/spring-kafka/2.2.8.RELEASE/2ada45678b48af5289a95f5f03066b568926fdc8/spring-kafka-2.2.8.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-project/2.0.11/adc2114aa1d9b7a599aa226849ad7f463de3cadc/maven-project-2.0.11.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven.shared/file-management/1.2.1/8f98bcaa7fd3625a172fd3de10bba8c32b9820ea/file-management-1.2.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-settings/2.0.11/3f81af64ca039c3ef000ecee0a31668a2b9a432d/maven-settings-2.0.11.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-profile/2.0.11/130057d04b0e914509f1223a85a6b1e83b08957f/maven-profile-2.0.11.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven.shared/maven-shared-io/1.1/2e1d57be05ecac7dbe56a3c73b113e98f22240f/maven-shared-io-1.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-artifact-manager/2.0.11/6c8764f10c7bd2ef8ad050190e3922be6078ecca/maven-artifact-manager-2.0.11.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-plugin-registry/2.0.11/c4703e5496fa93dcea339f9cc665290f9179c108/maven-plugin-registry-2.0.11.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.codehaus.plexus/plexus-container-default/1.0-alpha-9/50596183cd7b688d9d7b6d868a0193ca1a8a7b3d/plexus-container-default-1.0-alpha-9.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/junit/junit/4.12/2973d150c0dc1fefe998f834810d68f278ea58ec/junit-4.12.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-tomcat/2.1.7.RELEASE/11f2a86aefefba72a4efe5ff18f4165a4b4e78b/spring-boot-starter-tomcat-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.hibernate.validator/hibernate-validator/6.0.17.Final/af73055fc4a103ab347c56e7da5a143d68a0170/hibernate-validator-6.0.17.Final.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-webmvc/5.1.9.RELEASE/b9d4a2140488f0e6f9aa231e7938ae18da77b637/spring-webmvc-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-web/5.1.9.RELEASE/9fe4390420fdd0b63dc4ed90d9027dafa9f74f80/spring-web-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-plugin-api/2.0.11/f7aa99d1f2c0e941b60c107194dc5f9d107a0d77/maven-plugin-api-2.0.11.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/io.confluent/common-config/3.3.1/8906a6853baf3a530d3934e6fe46db8ac9a0c3ee/common-config-3.3.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/io.confluent/common-utils/3.3.1/370b5cffef42277d4b0fa4391afba2a64fcfe500/common-utils-3.3.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-clients/2.0.1/61576d880bafea639d6b091adbaf260c729a3ceb/kafka-clients-2.0.1-test.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.kafka/kafka-clients/2.0.1/db87f87e64714faff9c90fdc97a06c7d8e79b672/kafka-clients-2.0.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.jayway.jsonpath/json-path/2.4.0/765a4401ceb2dc8d40553c2075eb80a8fa35c2ae/json-path-2.4.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.velocity/velocity-engine-core/2.0/6e5f29e1237b1764a4ce769feeffb85b0b19cfa7/velocity-engine-core-2.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.101tec/zkclient/0.10/c54d4b5a5e89af75a80b6d5857400165ce5188d0/zkclient-0.10.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-starter-logging/2.1.7.RELEASE/6e829f739992a7f368c0af44a08ed89ad2a1972f/spring-boot-starter-logging-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-classic/1.2.3/7c4f3c474fb2c041d8028740440937705ebb473a/logback-classic-1.2.3.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.logging.log4j/log4j-to-slf4j/2.11.2/6d37bf7b046c0ce2669f26b99365a2cfa45c4c18/log4j-to-slf4j-2.11.2.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.slf4j/jul-to-slf4j/1.7.26/8031352b2bb0a49e67818bf04c027aa92e645d5c/jul-to-slf4j-1.7.26.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.zookeeper/zookeeper/3.4.13/31e9937541cef95c4585b547eb2dbd34d3a76f1c/zookeeper-3.4.13.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.yammer.metrics/metrics-core/2.2.0/f82c035cfa786d3cbec362c38c22a5f5b1bc8724/metrics-core-2.2.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.typesafe.scala-logging/scala-logging_2.11/3.9.0/e0dba06b4a763a0e2208182b264421baedbb0df/scala-logging_2.11-3.9.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.slf4j/slf4j-api/1.7.26/77100a62c2e6f04b53977b9f541044d7d722693d/slf4j-api-1.7.26.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.fasterxml.jackson.core/jackson-annotations/2.9.0/7c10d545325e3a6e72e06381afe469fd40eb701/jackson-annotations-2.9.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-test-autoconfigure/2.1.7.RELEASE/8c9847259e14419d2bcc4eed26bcf48dc56686ef/spring-boot-test-autoconfigure-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-autoconfigure/2.1.7.RELEASE/2c9d3e2c6ea3cb435e99e2973009636b62a9d816/spring-boot-autoconfigure-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot-test/2.1.7.RELEASE/70ed88830a08e8baa0b562090168fdba0e92810/spring-boot-test-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.boot/spring-boot/2.1.7.RELEASE/1599a2ad1fc6d36dbfc2a7c0dd5dab3a0bb27c61/spring-boot-2.1.7.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/javax.annotation/javax.annotation-api/1.3.2/934c04d3cfef185a8008e7bf34331b79730a9d43/javax.annotation-api-1.3.2.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-context/5.1.9.RELEASE/c37f8fe15a5ae4ea1f351bd46167fd492a84eefa/spring-context-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-test/5.1.9.RELEASE/653fa9de816677b3318e7058af54e7ee56866b09/spring-test-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework.retry/spring-retry/1.2.4.RELEASE/e5a1e629b2743dc7bbe4a8d07ebe9ff6c3b816ce/spring-retry-1.2.4.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-messaging/5.1.9.RELEASE/fa164c4c2a5299138ed344bc5d424f5f4219e267/spring-messaging-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-tx/5.1.9.RELEASE/a9125e2c8eeb193030f3972c6293616943c55ef2/spring-tx-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-aop/5.1.9.RELEASE/bc2312ffad02251b9d472e4a7c0e472a58f50fbf/spring-aop-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-beans/5.1.9.RELEASE/5a03b3983108d73978aec2fa3e681aedad6782c/spring-beans-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-expression/5.1.9.RELEASE/db3a2468c1b7d697ec3b3ec6e5652dc282994fe3/spring-expression-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-core/5.1.9.RELEASE/dc3815439579b4fa0c19970e6b8e5d774af8d988/spring-core-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.yaml/snakeyaml/1.23/ec62d74fe50689c28c0ff5b35d3aebcaa8b5be68/snakeyaml-1.23.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-library/1.3/4785a3c21320980282f9f33d0d1264a69040538f/hamcrest-library-1.3.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.hamcrest/hamcrest-core/1.3/42a25dc3219429f0e5d060061f71acb49bf010a0/hamcrest-core-1.3.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.assertj/assertj-core/3.11.1/fdac3217b804d6900fa3650f17b5cb48e620b140/assertj-core-3.11.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.mockito/mockito-core/2.23.4/a35b6f8ffcfa786771eac7d7d903429e790fdf3f/mockito-core-2.23.4.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.skyscreamer/jsonassert/1.5.0/6c9d5fe2f59da598d9aefc1cfc6528ff3cf32df3/jsonassert-1.5.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.xmlunit/xmlunit-core/2.6.3/cdb208320aed4a7b94fb236cfbf91aeb6d0ede14/xmlunit-core-2.6.3.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-websocket/9.0.22/45974d3443cc15ad9d10239d762d5e15759e6364/tomcat-embed-websocket-9.0.22.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-core/9.0.22/79f39903498b28adacb18fe2ea046edd306295a6/tomcat-embed-core-9.0.22.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.tomcat.embed/tomcat-embed-el/9.0.22/4da4b778b635a7e78ca7cd7288253e2e47b88a9f/tomcat-embed-el-9.0.22.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/javax.validation/validation-api/2.0.1.Final/cb855558e6271b1b32e716d24cb85c7f583ce09e/validation-api-2.0.1.Final.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.jboss.logging/jboss-logging/3.3.2.Final/3789d00e859632e6c6206adc0c71625559e6e3b0/jboss-logging-3.3.2.Final.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.fasterxml/classmate/1.4.0/291658ac2ce2476256c7115943652c0accb5c857/classmate-1.4.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-model/2.0.11/b4947c88b8f0e19944b1e5d121e2f7dcd2440895/maven-model-2.0.11.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.codehaus.plexus/plexus-interpolation/1.1/66a644c26e8a1cd2945981422c33ba247226a2ef/plexus-interpolation-1.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-artifact/2.0.11/432e01884f40b5d1d0b4706b019322d352c3b77b/maven-artifact-2.0.11.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven/maven-repository-metadata/2.0.11/88b1222854edcbf0ca02bfa5484b65c5f9240fdb/maven-repository-metadata-2.0.11.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.maven.wagon/wagon-provider-api/1.0-beta-2/abd1c9ace6e87c94a4b91f5176aeb09d954b23a3/wagon-provider-api-1.0-beta-2.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.codehaus.plexus/plexus-utils/1.5.6/8fb6b798a4036048b3005e058553bf21a87802ed/plexus-utils-1.5.6.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.commons/commons-lang3/3.8.1/6505a72a097d9270f7a9e7bf42c4238283247755/commons-lang3-3.8.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/joda-time/joda-time/2.10.3/2e5366cf1f77ca3bafffecf6e87d30e1d504e959/joda-time-2.10.3.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.springframework/spring-jcl/5.1.9.RELEASE/7c372790c999777d20f364960cf557dd74f890cf/spring-jcl-5.1.9.RELEASE.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.lz4/lz4-java/1.4.1/ad89b11ac280a2992d65e078af06f6709f1fe2fc/lz4-java-1.4.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.xerial.snappy/snappy-java/1.1.7.1/d5190b41f3de61e3b83d692322d58630252bc8c3/snappy-java-1.1.7.1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/net.sf.jopt-simple/jopt-simple/5.0.4/4fdac2fbe92dfad86aa6e9301736f6b4342a3f5c/jopt-simple-5.0.4.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.scala-lang/scala-reflect/2.11.12/2bb23c13c527566d9828107ca4108be2a2c06f01/scala-reflect-2.11.12.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.scala-lang/scala-library/2.11.12/bf5534e6fec3d665bd6419c952a929a8bdd4b591/scala-library-2.11.12.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/net.minidev/json-smart/2.3/7396407491352ce4fa30de92efb158adb76b5b/json-smart-2.3.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/net.bytebuddy/byte-buddy/1.9.16/e7d63009be7b87ff1f15b72e5b8c59c897a8d8bd/byte-buddy-1.9.16.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/net.bytebuddy/byte-buddy-agent/1.9.16/fd213511a0a845632456f636e576d24c2d6ac3bc/byte-buddy-agent-1.9.16.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.objenesis/objenesis/2.6/639033469776fd37c08358c6b92a4761feb2af4b/objenesis-2.6.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/com.vaadin.external.google/android-json/0.0.20131108.vaadin1/fa26d351fe62a6a17f5cda1287c1c6110dec413f/android-json-0.0.20131108.vaadin1.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/classworlds/classworlds/1.1-alpha-2/5adf2e681c57d7f48038b602f3ca2254ee82d47/classworlds-1.1-alpha-2.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.commons/commons-compress/1.18/1191f9f2bc0c47a8cce69193feb1ff0a8bcb37d5/commons-compress-1.18.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/ch.qos.logback/logback-core/1.2.3/864344400c3d4d92dfeb0a305dc87d953677c03c/logback-core-1.2.3.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.logging.log4j/log4j-api/2.11.2/f5e9a2ffca496057d6891a3de65128efc636e26e/log4j-api-2.11.2.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/log4j/log4j/1.2.17/5af35056b4d257e4b64b9e8069c0746e8b08629f/log4j-1.2.17.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/jline/jline/0.9.94/99a18e9a44834afdebc467294e1138364c207402/jline-0.9.94.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.apache.yetus/audience-annotations/0.5.0/55762d3191a8d6610ef46d11e8cb70c7667342a3/audience-annotations-0.5.0.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/io.netty/netty/3.10.6.Final/18ed04a0e502896552854926e908509db2987a00/netty-3.10.6.Final.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/net.minidev/accessors-smart/1.2/c592b500269bfde36096641b01238a8350f8aa31/accessors-smart-1.2.jar:/Users/prachi/.gradle/caches/modules-2/files-2.1/org.ow2.asm/asm/5.0.4/da08b8cce7bbf903602a25a3a163ae252435795/asm-5.0.4.jar
09:51:25.307 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/Users/prachi/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
09:51:25.307 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/
09:51:25.307 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
09:51:25.307 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Client environment:os.name=Mac OS X
09:51:25.307 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Client environment:os.arch=x86_64
09:51:25.307 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Client environment:os.version=10.14.5
09:51:25.307 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Client environment:user.name=prachi
09:51:25.307 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Client environment:user.home=/Users/prachi
09:51:25.307 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/Users/prachi/Documents/InteliJWorkplace/kafka_demo
09:51:25.308 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=127.0.0.1:59713 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@31acd974
09:51:25.311 [Test worker] DEBUG org.apache.zookeeper.ClientCnxn - zookeeper.disableAutoWatchReset is false
09:51:25.317 [Test worker] DEBUG org.I0Itec.zkclient.ZkClient - Awaiting connection to Zookeeper server
09:51:25.317 [Test worker] INFO org.I0Itec.zkclient.ZkClient - Waiting for keeper state SyncConnected
09:51:25.319 [Test worker-SendThread(localhost:59713)] INFO org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:59713. Will not attempt to authenticate using SASL (unknown error)
09:51:25.321 [Test worker-SendThread(localhost:59713)] INFO org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/127.0.0.1:59713, initiating session
09:51:25.322 [NIOServerCxn.Factory:/127.0.0.1:0] INFO org.apache.zookeeper.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:59714
09:51:25.322 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Session establishment request sent on localhost/127.0.0.1:59713
09:51:25.325 [NIOServerCxn.Factory:/127.0.0.1:0] DEBUG org.apache.zookeeper.server.ZooKeeperServer - Session establishment request from client /127.0.0.1:59714 client's lastZxid is 0x0
09:51:25.326 [NIOServerCxn.Factory:/127.0.0.1:0] INFO org.apache.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:59714
09:51:25.327 [SyncThread:0] INFO org.apache.zookeeper.server.persistence.FileTxnLog - Creating new log file: log.1
09:51:25.330 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210000 type:createSession cxid:0x0 zxid:0x1 txntype:-10 reqpath:n/a
09:51:25.332 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210000 type:createSession cxid:0x0 zxid:0x1 txntype:-10 reqpath:n/a
09:51:25.334 [SyncThread:0] INFO org.apache.zookeeper.server.ZooKeeperServer - Established session 0x1000a57cb210000 with negotiated timeout 6000 for client /127.0.0.1:59714
09:51:25.335 [Test worker-SendThread(localhost:59713)] INFO org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:59713, sessionid = 0x1000a57cb210000, negotiated timeout = 6000
09:51:25.336 [Test worker-EventThread] DEBUG org.I0Itec.zkclient.ZkClient - Received event: WatchedEvent state:SyncConnected type:None path:null
09:51:25.336 [Test worker-EventThread] INFO org.I0Itec.zkclient.ZkClient - zookeeper state changed (SyncConnected)
09:51:25.336 [Test worker-EventThread] DEBUG org.I0Itec.zkclient.ZkClient - Leaving process event
09:51:25.336 [Test worker] DEBUG org.I0Itec.zkclient.ZkClient - State is SyncConnected
09:51:25.493 [Test worker] INFO kafka.server.KafkaConfig - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59713
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

09:51:25.575 [Test worker] INFO kafka.server.KafkaServer - starting
09:51:25.576 [Test worker] INFO kafka.server.KafkaServer - Connecting to zookeeper on 127.0.0.1:59713
09:51:25.585 [Test worker] INFO kafka.zookeeper.ZooKeeperClient - [ZooKeeperClient] Initializing a new session to 127.0.0.1:59713.
09:51:25.586 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=127.0.0.1:59713 sessionTimeout=6000 watcher=kafka.zookeeper.ZooKeeperClient$ZooKeeperClientWatcher$@c679851
09:51:25.587 [Test worker-SendThread(localhost:59713)] INFO org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:59713. Will not attempt to authenticate using SASL (unknown error)
09:51:25.587 [Test worker] DEBUG kafka.utils.KafkaScheduler - Initializing task scheduler.
09:51:25.587 [Test worker-SendThread(localhost:59713)] INFO org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/127.0.0.1:59713, initiating session
09:51:25.587 [NIOServerCxn.Factory:/127.0.0.1:0] INFO org.apache.zookeeper.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:59715
09:51:25.587 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Session establishment request sent on localhost/127.0.0.1:59713
09:51:25.588 [NIOServerCxn.Factory:/127.0.0.1:0] DEBUG org.apache.zookeeper.server.ZooKeeperServer - Session establishment request from client /127.0.0.1:59715 client's lastZxid is 0x0
09:51:25.588 [NIOServerCxn.Factory:/127.0.0.1:0] INFO org.apache.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:59715
09:51:25.588 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:createSession cxid:0x0 zxid:0x2 txntype:-10 reqpath:n/a
09:51:25.588 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:createSession cxid:0x0 zxid:0x2 txntype:-10 reqpath:n/a
09:51:25.589 [SyncThread:0] INFO org.apache.zookeeper.server.ZooKeeperServer - Established session 0x1000a57cb210001 with negotiated timeout 6000 for client /127.0.0.1:59715
09:51:25.591 [Test worker-SendThread(localhost:59713)] INFO org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:59713, sessionid = 0x1000a57cb210001, negotiated timeout = 6000
09:51:25.591 [Test worker-EventThread] DEBUG kafka.zookeeper.ZooKeeperClient - [ZooKeeperClient] Received event: WatchedEvent state:SyncConnected type:None path:null
09:51:25.593 [Test worker] INFO kafka.zookeeper.ZooKeeperClient - [ZooKeeperClient] Waiting until connected.
09:51:25.595 [Test worker] INFO kafka.zookeeper.ZooKeeperClient - [ZooKeeperClient] Connected.
09:51:25.629 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x1 zxid:0x3 txntype:1 reqpath:n/a
09:51:25.630 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x1 zxid:0x3 txntype:1 reqpath:n/a
09:51:25.632 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/consumers serverPath:/consumers finished:false header:: 1,1  replyHeader:: 1,3,0  request:: '/consumers,,v{s{31,s{'world,'anyone}}},0  response:: '/consumers 
09:51:25.639 [ProcessThread(sid:0 cport:59713):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1000a57cb210001 type:create cxid:0x2 zxid:0x4 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
09:51:25.639 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x2 zxid:0x4 txntype:-1 reqpath:n/a
09:51:25.639 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Ignoring processTxn failure hdr: -1 : error: -101
09:51:25.640 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/ids serverPath:/brokers/ids finished:false header:: 2,1  replyHeader:: 2,4,-101  request:: '/brokers/ids,,v{s{31,s{'world,'anyone}}},0  response::  
09:51:25.641 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x3 zxid:0x5 txntype:1 reqpath:n/a
09:51:25.641 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x3 zxid:0x5 txntype:1 reqpath:n/a
09:51:25.642 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers serverPath:/brokers finished:false header:: 3,1  replyHeader:: 3,5,0  request:: '/brokers,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers 
09:51:25.643 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x4 zxid:0x6 txntype:1 reqpath:n/a
09:51:25.643 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x4 zxid:0x6 txntype:1 reqpath:n/a
09:51:25.644 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/ids serverPath:/brokers/ids finished:false header:: 4,1  replyHeader:: 4,6,0  request:: '/brokers/ids,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/ids 
09:51:25.645 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x5 zxid:0x7 txntype:1 reqpath:n/a
09:51:25.645 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x5 zxid:0x7 txntype:1 reqpath:n/a
09:51:25.645 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics serverPath:/brokers/topics finished:false header:: 5,1  replyHeader:: 5,7,0  request:: '/brokers/topics,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics 
09:51:25.646 [ProcessThread(sid:0 cport:59713):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1000a57cb210001 type:create cxid:0x6 zxid:0x8 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
09:51:25.647 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x6 zxid:0x8 txntype:-1 reqpath:n/a
09:51:25.647 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Ignoring processTxn failure hdr: -1 : error: -101
09:51:25.647 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/changes serverPath:/config/changes finished:false header:: 6,1  replyHeader:: 6,8,-101  request:: '/config/changes,,v{s{31,s{'world,'anyone}}},0  response::  
09:51:25.648 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x7 zxid:0x9 txntype:1 reqpath:n/a
09:51:25.649 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x7 zxid:0x9 txntype:1 reqpath:n/a
09:51:25.649 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config serverPath:/config finished:false header:: 7,1  replyHeader:: 7,9,0  request:: '/config,,v{s{31,s{'world,'anyone}}},0  response:: '/config 
09:51:25.650 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x8 zxid:0xa txntype:1 reqpath:n/a
09:51:25.650 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x8 zxid:0xa txntype:1 reqpath:n/a
09:51:25.651 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/changes serverPath:/config/changes finished:false header:: 8,1  replyHeader:: 8,10,0  request:: '/config/changes,,v{s{31,s{'world,'anyone}}},0  response:: '/config/changes 
09:51:25.651 [ProcessThread(sid:0 cport:59713):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1000a57cb210001 type:create cxid:0x9 zxid:0xb txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
09:51:25.652 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x9 zxid:0xb txntype:-1 reqpath:n/a
09:51:25.652 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Ignoring processTxn failure hdr: -1 : error: -101
09:51:25.652 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/admin/delete_topics serverPath:/admin/delete_topics finished:false header:: 9,1  replyHeader:: 9,11,-101  request:: '/admin/delete_topics,,v{s{31,s{'world,'anyone}}},0  response::  
09:51:25.653 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0xa zxid:0xc txntype:1 reqpath:n/a
09:51:25.653 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0xa zxid:0xc txntype:1 reqpath:n/a
09:51:25.654 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/admin serverPath:/admin finished:false header:: 10,1  replyHeader:: 10,12,0  request:: '/admin,,v{s{31,s{'world,'anyone}}},0  response:: '/admin 
09:51:25.654 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0xb zxid:0xd txntype:1 reqpath:n/a
09:51:25.655 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0xb zxid:0xd txntype:1 reqpath:n/a
09:51:25.655 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/admin/delete_topics serverPath:/admin/delete_topics finished:false header:: 11,1  replyHeader:: 11,13,0  request:: '/admin/delete_topics,,v{s{31,s{'world,'anyone}}},0  response:: '/admin/delete_topics 
09:51:25.656 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0xc zxid:0xe txntype:1 reqpath:n/a
09:51:25.657 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0xc zxid:0xe txntype:1 reqpath:n/a
09:51:25.657 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/seqid serverPath:/brokers/seqid finished:false header:: 12,1  replyHeader:: 12,14,0  request:: '/brokers/seqid,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/seqid 
09:51:25.658 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0xd zxid:0xf txntype:1 reqpath:n/a
09:51:25.658 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0xd zxid:0xf txntype:1 reqpath:n/a
09:51:25.659 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/isr_change_notification serverPath:/isr_change_notification finished:false header:: 13,1  replyHeader:: 13,15,0  request:: '/isr_change_notification,,v{s{31,s{'world,'anyone}}},0  response:: '/isr_change_notification 
09:51:25.660 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0xe zxid:0x10 txntype:1 reqpath:n/a
09:51:25.660 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0xe zxid:0x10 txntype:1 reqpath:n/a
09:51:25.661 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/latest_producer_id_block serverPath:/latest_producer_id_block finished:false header:: 14,1  replyHeader:: 14,16,0  request:: '/latest_producer_id_block,,v{s{31,s{'world,'anyone}}},0  response:: '/latest_producer_id_block 
09:51:25.663 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0xf zxid:0x11 txntype:1 reqpath:n/a
09:51:25.663 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0xf zxid:0x11 txntype:1 reqpath:n/a
09:51:25.663 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/log_dir_event_notification serverPath:/log_dir_event_notification finished:false header:: 15,1  replyHeader:: 15,17,0  request:: '/log_dir_event_notification,,v{s{31,s{'world,'anyone}}},0  response:: '/log_dir_event_notification 
09:51:25.664 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x10 zxid:0x12 txntype:1 reqpath:n/a
09:51:25.664 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x10 zxid:0x12 txntype:1 reqpath:n/a
09:51:25.665 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/topics serverPath:/config/topics finished:false header:: 16,1  replyHeader:: 16,18,0  request:: '/config/topics,,v{s{31,s{'world,'anyone}}},0  response:: '/config/topics 
09:51:25.666 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x11 zxid:0x13 txntype:1 reqpath:n/a
09:51:25.666 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x11 zxid:0x13 txntype:1 reqpath:n/a
09:51:25.667 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/clients serverPath:/config/clients finished:false header:: 17,1  replyHeader:: 17,19,0  request:: '/config/clients,,v{s{31,s{'world,'anyone}}},0  response:: '/config/clients 
09:51:25.668 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x12 zxid:0x14 txntype:1 reqpath:n/a
09:51:25.668 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x12 zxid:0x14 txntype:1 reqpath:n/a
09:51:25.668 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/users serverPath:/config/users finished:false header:: 18,1  replyHeader:: 18,20,0  request:: '/config/users,,v{s{31,s{'world,'anyone}}},0  response:: '/config/users 
09:51:25.669 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x13 zxid:0x15 txntype:1 reqpath:n/a
09:51:25.669 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x13 zxid:0x15 txntype:1 reqpath:n/a
09:51:25.670 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/brokers serverPath:/config/brokers finished:false header:: 19,1  replyHeader:: 19,21,0  request:: '/config/brokers,,v{s{31,s{'world,'anyone}}},0  response:: '/config/brokers 
09:51:25.673 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x14 zxid:0xfffffffffffffffe txntype:unknown reqpath:/cluster/id
09:51:25.673 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x14 zxid:0xfffffffffffffffe txntype:unknown reqpath:/cluster/id
09:51:25.674 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/cluster/id serverPath:/cluster/id finished:false header:: 20,4  replyHeader:: 20,21,-101  request:: '/cluster/id,F  response::  
09:51:25.803 [ProcessThread(sid:0 cport:59713):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1000a57cb210001 type:create cxid:0x15 zxid:0x16 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
09:51:25.805 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x15 zxid:0x16 txntype:-1 reqpath:n/a
09:51:25.805 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Ignoring processTxn failure hdr: -1 : error: -101
09:51:25.805 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/cluster/id serverPath:/cluster/id finished:false header:: 21,1  replyHeader:: 21,22,-101  request:: '/cluster/id,#7b2276657273696f6e223a2231222c226964223a227a66416179764a7a543157373866654f375930307341227d,v{s{31,s{'world,'anyone}}},0  response::  
09:51:25.811 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x16 zxid:0x17 txntype:1 reqpath:n/a
09:51:25.811 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x16 zxid:0x17 txntype:1 reqpath:n/a
09:51:25.812 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/cluster serverPath:/cluster finished:false header:: 22,1  replyHeader:: 22,23,0  request:: '/cluster,,v{s{31,s{'world,'anyone}}},0  response:: '/cluster 
09:51:25.817 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x17 zxid:0x18 txntype:1 reqpath:n/a
09:51:25.817 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x17 zxid:0x18 txntype:1 reqpath:n/a
09:51:25.817 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/cluster/id serverPath:/cluster/id finished:false header:: 23,1  replyHeader:: 23,24,0  request:: '/cluster/id,#7b2276657273696f6e223a2231222c226964223a227a66416179764a7a543157373866654f375930307341227d,v{s{31,s{'world,'anyone}}},0  response:: '/cluster/id 
09:51:25.818 [Test worker] INFO kafka.server.KafkaServer - Cluster ID = zfAayvJzT1W78feO7Y00sA
09:51:25.821 [Test worker] WARN kafka.server.BrokerMetadataCheckpoint - No meta.properties file under dir /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473/meta.properties
09:51:25.827 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x18 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/brokers/<default>
09:51:25.827 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x18 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/brokers/<default>
09:51:25.827 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/brokers/<default> serverPath:/config/brokers/<default> finished:false header:: 24,4  replyHeader:: 24,24,-101  request:: '/config/brokers/<default>,F  response::  
09:51:25.880 [Test worker] INFO kafka.server.KafkaConfig - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59713
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

09:51:25.905 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x19 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/brokers/0
09:51:25.905 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x19 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/brokers/0
09:51:25.905 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/brokers/0 serverPath:/config/brokers/0 finished:false header:: 25,4  replyHeader:: 25,24,-101  request:: '/config/brokers/0,F  response::  
09:51:25.910 [Test worker] INFO kafka.server.KafkaConfig - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	alter.config.policy.class.name = null
	alter.log.dirs.replication.quota.window.num = 11
	alter.log.dirs.replication.quota.window.size.seconds = 1
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 0
	broker.id.generation.enable = true
	broker.rack = null
	client.quota.callback.class = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 100
	controller.socket.timeout.ms = 1000
	create.topic.policy.class.name = null
	default.replication.factor = 1
	delegation.token.expiry.check.interval.ms = 3600000
	delegation.token.expiry.time.ms = 86400000
	delegation.token.master.key = null
	delegation.token.max.lifetime.ms = 604800000
	delete.records.purgatory.purge.interval.requests = 1
	delete.topic.enable = true
	fetch.purgatory.purge.interval.requests = 1000
	group.initial.rebalance.delay.ms = 0
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.listener.name = null
	inter.broker.protocol.version = 2.0-IV1
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
	listeners = PLAINTEXT://localhost:0
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 2097152
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473
	log.dirs = null
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.flush.start.offset.checkpoint.interval.ms = 60000
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.downconversion.enable = true
	log.message.format.version = 2.0-IV1
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 1000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	max.incremental.fetch.session.cache.slots = 1000
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 1
	num.recovery.threads.per.data.dir = 1
	num.replica.alter.log.dirs.threads = null
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 10080
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 5
	offsets.topic.replication.factor = 1
	offsets.topic.segment.bytes = 104857600
	password.encoder.cipher.algorithm = AES/CBC/PKCS5Padding
	password.encoder.iterations = 4096
	password.encoder.key.length = 128
	password.encoder.keyfactory.algorithm = null
	password.encoder.old.secret = null
	password.encoder.secret = null
	port = 9092
	principal.builder.class = null
	producer.purgatory.purge.interval.requests = 1000
	queued.max.request.bytes = -1
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 9223372036854775807
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 1000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.client.callback.handler.class = null
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism.inter.broker.protocol = GSSAPI
	sasl.server.callback.handler.class = null
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = []
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.abort.timed.out.transaction.cleanup.interval.ms = 60000
	transaction.max.timeout.ms = 900000
	transaction.remove.expired.transaction.cleanup.interval.ms = 3600000
	transaction.state.log.load.buffer.size = 5242880
	transaction.state.log.min.isr = 2
	transaction.state.log.num.partitions = 50
	transaction.state.log.replication.factor = 3
	transaction.state.log.segment.bytes = 104857600
	transactional.id.expiration.ms = 604800000
	unclean.leader.election.enable = false
	zookeeper.connect = 127.0.0.1:59713
	zookeeper.connection.timeout.ms = 10000
	zookeeper.max.in.flight.requests = 10
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

09:51:25.937 [Test worker] DEBUG kafka.utils.KafkaScheduler - Initializing task scheduler.
09:51:25.952 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name Fetch-delayQueue
09:51:25.953 [ThrottledChannelReaper-Fetch] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper - [ThrottledChannelReaper-Fetch]: Starting
09:51:25.953 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name Produce-delayQueue
09:51:25.954 [ThrottledChannelReaper-Produce] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper - [ThrottledChannelReaper-Produce]: Starting
09:51:25.954 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name Request-delayQueue
09:51:25.955 [ThrottledChannelReaper-Request] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper - [ThrottledChannelReaper-Request]: Starting
09:51:25.963 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x1a zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics
09:51:25.964 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x1a zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics
09:51:25.965 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics serverPath:/brokers/topics finished:false header:: 26,12  replyHeader:: 26,24,0  request:: '/brokers/topics,F  response:: v{},s{7,7,1566517885644,1566517885644,0,0,0,0,0,0,7} 
09:51:25.977 [Test worker] INFO kafka.log.LogManager - Loading logs.
09:51:25.982 [Test worker] INFO kafka.log.LogManager - Logs loading complete in 5 ms.
09:51:25.988 [Test worker] INFO kafka.log.LogManager - Starting log cleanup with a period of 300000 ms.
09:51:25.988 [Test worker] DEBUG kafka.utils.KafkaScheduler - Scheduling task kafka-log-retention with initial delay 30000 ms and period 300000 ms.
09:51:25.989 [Test worker] INFO kafka.log.LogManager - Starting log flusher with a default period of 9223372036854775807 ms.
09:51:25.990 [Test worker] DEBUG kafka.utils.KafkaScheduler - Scheduling task kafka-log-flusher with initial delay 30000 ms and period 9223372036854775807 ms.
09:51:25.990 [Test worker] DEBUG kafka.utils.KafkaScheduler - Scheduling task kafka-recovery-point-checkpoint with initial delay 30000 ms and period 60000 ms.
09:51:25.991 [Test worker] DEBUG kafka.utils.KafkaScheduler - Scheduling task kafka-log-start-offset-checkpoint with initial delay 30000 ms and period 60000 ms.
09:51:25.991 [Test worker] DEBUG kafka.utils.KafkaScheduler - Scheduling task kafka-delete-logs with initial delay 30000 ms and period -1 ms.
09:51:25.992 [Test worker] INFO kafka.log.LogCleaner - Starting the log cleaner
09:51:25.997 [kafka-log-cleaner-thread-0] INFO kafka.log.LogCleaner - [kafka-log-cleaner-thread-0]: Starting
09:51:26.002 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name MemoryPoolUtilization
09:51:26.150 [Test worker] INFO kafka.network.Acceptor - Awaiting socket connections on localhost:59716.
09:51:26.159 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:listener-PLAINTEXTnetworkProcessor-0
09:51:26.159 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:listener-PLAINTEXTnetworkProcessor-0
09:51:26.159 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name successful-authentication:listener-PLAINTEXTnetworkProcessor-0
09:51:26.160 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name failed-authentication:listener-PLAINTEXTnetworkProcessor-0
09:51:26.160 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:listener-PLAINTEXTnetworkProcessor-0
09:51:26.160 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:listener-PLAINTEXTnetworkProcessor-0
09:51:26.161 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:listener-PLAINTEXTnetworkProcessor-0
09:51:26.162 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:listener-PLAINTEXTnetworkProcessor-0
09:51:26.162 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:listener-PLAINTEXTnetworkProcessor-0
09:51:26.164 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:listener-PLAINTEXTnetworkProcessor-1
09:51:26.165 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:listener-PLAINTEXTnetworkProcessor-1
09:51:26.165 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name successful-authentication:listener-PLAINTEXTnetworkProcessor-1
09:51:26.165 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name failed-authentication:listener-PLAINTEXTnetworkProcessor-1
09:51:26.165 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:listener-PLAINTEXTnetworkProcessor-1
09:51:26.166 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:listener-PLAINTEXTnetworkProcessor-1
09:51:26.166 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:listener-PLAINTEXTnetworkProcessor-1
09:51:26.167 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:listener-PLAINTEXTnetworkProcessor-1
09:51:26.167 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:listener-PLAINTEXTnetworkProcessor-1
09:51:26.168 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:listener-PLAINTEXTnetworkProcessor-2
09:51:26.169 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:listener-PLAINTEXTnetworkProcessor-2
09:51:26.169 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name successful-authentication:listener-PLAINTEXTnetworkProcessor-2
09:51:26.169 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name failed-authentication:listener-PLAINTEXTnetworkProcessor-2
09:51:26.169 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:listener-PLAINTEXTnetworkProcessor-2
09:51:26.169 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:listener-PLAINTEXTnetworkProcessor-2
09:51:26.170 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:listener-PLAINTEXTnetworkProcessor-2
09:51:26.171 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:listener-PLAINTEXTnetworkProcessor-2
09:51:26.171 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:listener-PLAINTEXTnetworkProcessor-2
09:51:26.174 [Test worker] INFO kafka.network.SocketServer - [SocketServer brokerId=0] Started 1 acceptor threads
09:51:26.186 [ExpirationReaper-0-Produce] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Produce]: Starting
09:51:26.187 [ExpirationReaper-0-Fetch] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Fetch]: Starting
09:51:26.188 [ExpirationReaper-0-DeleteRecords] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-DeleteRecords]: Starting
09:51:26.193 [Test worker] DEBUG kafka.utils.KafkaScheduler - Scheduling task isr-expiration with initial delay 0 ms and period 5000 ms.
09:51:26.194 [Test worker] DEBUG kafka.utils.KafkaScheduler - Scheduling task isr-change-propagation with initial delay 0 ms and period 2500 ms.
09:51:26.195 [Test worker] DEBUG kafka.utils.KafkaScheduler - Scheduling task shutdown-idle-replica-alter-log-dirs-thread with initial delay 0 ms and period 10000 ms.
09:51:26.196 [LogDirFailureHandler] INFO kafka.server.ReplicaManager$LogDirFailureHandler - [LogDirFailureHandler]: Starting
09:51:26.197 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x1b zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids
09:51:26.197 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x1b zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids
09:51:26.198 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/ids serverPath:/brokers/ids finished:false header:: 27,12  replyHeader:: 27,24,0  request:: '/brokers/ids,F  response:: v{},s{6,6,1566517885642,1566517885642,0,0,0,0,0,0,6} 
09:51:26.226 [Test worker] INFO kafka.zk.KafkaZkClient - Creating /brokers/ids/0 (is it secure? false)
09:51:26.228 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x1c zxid:0x19 txntype:1 reqpath:n/a
09:51:26.229 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x1c zxid:0x19 txntype:1 reqpath:n/a
09:51:26.231 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/ids/0 serverPath:/brokers/ids/0 finished:false header:: 28,1  replyHeader:: 28,25,0  request:: '/brokers/ids/0,#7b226c697374656e65725f73656375726974795f70726f746f636f6c5f6d6170223a7b22504c41494e54455854223a22504c41494e54455854227d2c22656e64706f696e7473223a5b22504c41494e544558543a2f2f6c6f63616c686f73743a3539373136225d2c226a6d785f706f7274223a2d312c22686f7374223a226c6f63616c686f7374222c2274696d657374616d70223a2231353636353137383836323037222c22706f7274223a35393731362c2276657273696f6e223a347d,v{s{31,s{'world,'anyone}}},1  response:: '/brokers/ids/0 
09:51:26.232 [Test worker] INFO kafka.zk.KafkaZkClient - Result of znode creation at /brokers/ids/0 is: OK
09:51:26.234 [Test worker] INFO kafka.zk.KafkaZkClient - Registered broker 0 at path /brokers/ids/0 with addresses: ArrayBuffer(EndPoint(localhost,59716,ListenerName(PLAINTEXT),PLAINTEXT))
09:51:26.235 [Test worker] WARN kafka.server.BrokerMetadataCheckpoint - No meta.properties file under dir /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473/meta.properties
09:51:26.274 [controller-event-thread] INFO kafka.controller.ControllerEventManager$ControllerEventThread - [ControllerEventThread controllerId=0] Starting
09:51:26.277 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:exists cxid:0x1d zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller
09:51:26.277 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:exists cxid:0x1d zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller
09:51:26.277 [ExpirationReaper-0-topic] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-topic]: Starting
09:51:26.277 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/controller serverPath:/controller finished:false header:: 29,3  replyHeader:: 29,25,-101  request:: '/controller,T  response::  
09:51:26.278 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x1e zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller
09:51:26.278 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x1e zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller
09:51:26.279 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/controller serverPath:/controller finished:false header:: 30,4  replyHeader:: 30,25,-101  request:: '/controller,T  response::  
09:51:26.280 [controller-event-thread] INFO kafka.zk.KafkaZkClient - Creating /controller (is it secure? false)
09:51:26.281 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x1f zxid:0x1a txntype:1 reqpath:n/a
09:51:26.281 [ExpirationReaper-0-Heartbeat] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Heartbeat]: Starting
09:51:26.282 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x1f zxid:0x1a txntype:1 reqpath:n/a
09:51:26.282 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Got notification sessionid:0x1000a57cb210001
09:51:26.282 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Got WatchedEvent state:SyncConnected type:NodeCreated path:/controller for sessionid 0x1000a57cb210001
09:51:26.282 [Test worker-EventThread] DEBUG kafka.zookeeper.ZooKeeperClient - [ZooKeeperClient] Received event: WatchedEvent state:SyncConnected type:NodeCreated path:/controller
09:51:26.282 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/controller serverPath:/controller finished:false header:: 31,1  replyHeader:: 31,26,0  request:: '/controller,#7b2276657273696f6e223a312c2262726f6b65726964223a302c2274696d657374616d70223a2231353636353137383836323738227d,v{s{31,s{'world,'anyone}}},1  response:: '/controller 
09:51:26.283 [controller-event-thread] INFO kafka.zk.KafkaZkClient - Result of znode creation at /controller is: OK
09:51:26.283 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] 0 successfully elected as the controller
09:51:26.283 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Reading controller epoch from ZooKeeper
09:51:26.284 [ExpirationReaper-0-Rebalance] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Rebalance]: Starting
09:51:26.284 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x20 zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller_epoch
09:51:26.284 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x20 zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller_epoch
09:51:26.284 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/controller_epoch serverPath:/controller_epoch finished:false header:: 32,4  replyHeader:: 32,26,-101  request:: '/controller_epoch,F  response::  
09:51:26.285 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Incrementing controller epoch in ZooKeeper
09:51:26.288 [ProcessThread(sid:0 cport:59713):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1000a57cb210001 type:setData cxid:0x21 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
09:51:26.289 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:setData cxid:0x21 zxid:0x1b txntype:-1 reqpath:n/a
09:51:26.289 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Ignoring processTxn failure hdr: -1 : error: -101
09:51:26.289 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/controller_epoch serverPath:/controller_epoch finished:false header:: 33,5  replyHeader:: 33,27,-101  request:: '/controller_epoch,#31,0  response::  
09:51:26.290 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x22 zxid:0x1c txntype:1 reqpath:n/a
09:51:26.290 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x22 zxid:0x1c txntype:1 reqpath:n/a
09:51:26.291 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/controller_epoch serverPath:/controller_epoch finished:false header:: 34,1  replyHeader:: 34,28,0  request:: '/controller_epoch,#31,v{s{31,s{'world,'anyone}}},0  response:: '/controller_epoch 
09:51:26.291 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Epoch incremented to 1
09:51:26.292 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Registering handlers
09:51:26.293 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:exists cxid:0x23 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/preferred_replica_election
09:51:26.293 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:exists cxid:0x23 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/preferred_replica_election
09:51:26.293 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/admin/preferred_replica_election serverPath:/admin/preferred_replica_election finished:false header:: 35,3  replyHeader:: 35,28,-101  request:: '/admin/preferred_replica_election,T  response::  
09:51:26.294 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:exists cxid:0x24 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/reassign_partitions
09:51:26.294 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:exists cxid:0x24 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/reassign_partitions
09:51:26.294 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/admin/reassign_partitions serverPath:/admin/reassign_partitions finished:false header:: 36,3  replyHeader:: 36,28,-101  request:: '/admin/reassign_partitions,T  response::  
09:51:26.295 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Deleting log dir event notifications
09:51:26.295 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x25 zxid:0xfffffffffffffffe txntype:unknown reqpath:/log_dir_event_notification
09:51:26.295 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x25 zxid:0xfffffffffffffffe txntype:unknown reqpath:/log_dir_event_notification
09:51:26.296 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/log_dir_event_notification serverPath:/log_dir_event_notification finished:false header:: 37,12  replyHeader:: 37,28,0  request:: '/log_dir_event_notification,T  response:: v{},s{17,17,1566517885662,1566517885662,0,0,0,0,0,0,17} 
09:51:26.296 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Deleting isr change notifications
09:51:26.297 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x26 zxid:0xfffffffffffffffe txntype:unknown reqpath:/isr_change_notification
09:51:26.297 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x26 zxid:0xfffffffffffffffe txntype:unknown reqpath:/isr_change_notification
09:51:26.297 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/isr_change_notification serverPath:/isr_change_notification finished:false header:: 38,12  replyHeader:: 38,28,0  request:: '/isr_change_notification,T  response:: v{},s{15,15,1566517885658,1566517885658,0,0,0,0,0,0,15} 
09:51:26.298 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Initializing controller context
09:51:26.299 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x27 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids
09:51:26.299 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x27 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids
09:51:26.299 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/ids serverPath:/brokers/ids finished:false header:: 39,12  replyHeader:: 39,28,0  request:: '/brokers/ids,T  response:: v{'0},s{6,6,1566517885642,1566517885642,0,1,0,0,0,1,25} 
09:51:26.300 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x28 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids/0
09:51:26.300 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x28 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids/0
09:51:26.301 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/ids/0 serverPath:/brokers/ids/0 finished:false header:: 40,4  replyHeader:: 40,28,0  request:: '/brokers/ids/0,F  response:: #7b226c697374656e65725f73656375726974795f70726f746f636f6c5f6d6170223a7b22504c41494e54455854223a22504c41494e54455854227d2c22656e64706f696e7473223a5b22504c41494e544558543a2f2f6c6f63616c686f73743a3539373136225d2c226a6d785f706f7274223a2d312c22686f7374223a226c6f63616c686f7374222c2274696d657374616d70223a2231353636353137383836323037222c22706f7274223a35393731362c2276657273696f6e223a347d,s{25,25,1566517886227,1566517886227,0,0,0,72068966224297985,190,0,25} 
09:51:26.303 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x29 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/__consumer_offsets
09:51:26.303 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x29 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/__consumer_offsets
09:51:26.303 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/__consumer_offsets serverPath:/brokers/topics/__consumer_offsets finished:false header:: 41,4  replyHeader:: 41,28,-101  request:: '/brokers/topics/__consumer_offsets,F  response::  
09:51:26.309 [Test worker] INFO kafka.coordinator.group.GroupCoordinator - [GroupCoordinator 0]: Starting up.
09:51:26.310 [Test worker] DEBUG kafka.utils.KafkaScheduler - Initializing task scheduler.
09:51:26.310 [Test worker] DEBUG kafka.utils.KafkaScheduler - Scheduling task delete-expired-group-metadata with initial delay 0 ms and period 600000 ms.
09:51:26.311 [Test worker] INFO kafka.coordinator.group.GroupCoordinator - [GroupCoordinator 0]: Startup complete.
09:51:26.312 [group-metadata-manager-0] INFO kafka.coordinator.group.GroupMetadataManager - [GroupMetadataManager brokerId=0] Removed 0 expired offsets in 1 milliseconds.
09:51:26.314 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x2a zxid:0xfffffffffffffffe txntype:unknown reqpath:/latest_producer_id_block
09:51:26.314 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x2a zxid:0xfffffffffffffffe txntype:unknown reqpath:/latest_producer_id_block
09:51:26.314 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/latest_producer_id_block serverPath:/latest_producer_id_block finished:false header:: 42,4  replyHeader:: 42,28,0  request:: '/latest_producer_id_block,F  response:: ,s{16,16,1566517885660,1566517885660,0,0,0,0,0,0,16} 
09:51:26.315 [Test worker] DEBUG kafka.coordinator.transaction.ProducerIdManager - [ProducerId Manager 0]: There is no producerId block yet (Zk path version 0), creating the first block
09:51:26.321 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:setData cxid:0x2b zxid:0x1d txntype:5 reqpath:n/a
09:51:26.321 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:setData cxid:0x2b zxid:0x1d txntype:5 reqpath:n/a
09:51:26.322 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/latest_producer_id_block serverPath:/latest_producer_id_block finished:false header:: 43,5  replyHeader:: 43,29,0  request:: '/latest_producer_id_block,#7b2276657273696f6e223a312c2262726f6b6572223a302c22626c6f636b5f7374617274223a2230222c22626c6f636b5f656e64223a22393939227d,0  response:: s{16,29,1566517885660,1566517886320,1,0,0,0,60,0,16} 
09:51:26.323 [Test worker] DEBUG kafka.zk.KafkaZkClient - Conditional update of path /latest_producer_id_block with value {"version":1,"broker":0,"block_start":"0","block_end":"999"} and expected version 0 succeeded, returning the new version: 1
09:51:26.323 [Test worker] INFO kafka.coordinator.transaction.ProducerIdManager - [ProducerId Manager 0]: Acquired new producerId block (brokerId:0,blockStartProducerId:0,blockEndProducerId:999) by writing to Zk with path version 1
09:51:26.326 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x2c zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/__transaction_state
09:51:26.326 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x2c zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/__transaction_state
09:51:26.327 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/__transaction_state serverPath:/brokers/topics/__transaction_state finished:false header:: 44,4  replyHeader:: 44,29,-101  request:: '/brokers/topics/__transaction_state,F  response::  
09:51:26.329 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x2d zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics
09:51:26.329 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x2d zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics
09:51:26.329 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics serverPath:/brokers/topics finished:false header:: 45,12  replyHeader:: 45,29,0  request:: '/brokers/topics,T  response:: v{},s{7,7,1566517885644,1566517885644,0,0,0,0,0,0,7} 
09:51:26.331 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
09:51:26.332 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
09:51:26.332 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name successful-authentication:
09:51:26.332 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name failed-authentication:
09:51:26.332 [controller-event-thread] DEBUG kafka.controller.KafkaController - [Controller id=0] Register BrokerModifications handler for Set(0)
09:51:26.333 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
09:51:26.333 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:exists cxid:0x2e zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids/0
09:51:26.334 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:exists cxid:0x2e zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids/0
09:51:26.334 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
09:51:26.334 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/ids/0 serverPath:/brokers/ids/0 finished:false header:: 46,3  replyHeader:: 46,29,0  request:: '/brokers/ids/0,T  response:: s{25,25,1566517886227,1566517886227,0,0,0,72068966224297985,190,0,25} 
09:51:26.334 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
09:51:26.335 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
09:51:26.336 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
09:51:26.338 [controller-event-thread] DEBUG kafka.controller.ControllerChannelManager - [Channel manager on controller 0]: Controller 0 trying to connect to broker 0
09:51:26.340 [controller-event-thread] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:broker-id-0
09:51:26.340 [controller-event-thread] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:broker-id-0
09:51:26.340 [controller-event-thread] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name successful-authentication:broker-id-0
09:51:26.341 [controller-event-thread] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name failed-authentication:broker-id-0
09:51:26.341 [controller-event-thread] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:broker-id-0
09:51:26.341 [controller-event-thread] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:broker-id-0
09:51:26.342 [controller-event-thread] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:broker-id-0
09:51:26.342 [controller-event-thread] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:broker-id-0
09:51:26.342 [controller-event-thread] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:broker-id-0
09:51:26.345 [Controller-0-to-broker-0-send-thread] INFO kafka.controller.RequestSendThread - [RequestSendThread controllerId=0] Starting
09:51:26.345 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x2f zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/reassign_partitions
09:51:26.345 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x2f zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/reassign_partitions
09:51:26.346 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/admin/reassign_partitions serverPath:/admin/reassign_partitions finished:false header:: 47,4  replyHeader:: 47,29,-101  request:: '/admin/reassign_partitions,T  response::  
09:51:26.347 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Partitions being reassigned: Map()
09:51:26.348 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Currently active brokers in the cluster: Set(0)
09:51:26.348 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Currently shutting brokers in the cluster: Set()
09:51:26.348 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Current list of topics in the cluster: Set()
09:51:26.349 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Fetching topic deletions in progress
09:51:26.349 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x30 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/delete_topics
09:51:26.349 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x30 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/delete_topics
09:51:26.350 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/admin/delete_topics serverPath:/admin/delete_topics finished:false header:: 48,12  replyHeader:: 48,29,0  request:: '/admin/delete_topics,T  response:: v{},s{13,13,1566517885654,1566517885654,0,0,0,0,0,0,13} 
09:51:26.351 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] List of topics to be deleted: 
09:51:26.352 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] List of topics ineligible for deletion: 
09:51:26.352 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Initializing topic deletion manager
09:51:26.353 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Sending update metadata request
09:51:26.358 [controller-event-thread] INFO kafka.controller.ReplicaStateMachine - [ReplicaStateMachine controllerId=0] Initializing replica state
09:51:26.358 [controller-event-thread] INFO kafka.controller.ReplicaStateMachine - [ReplicaStateMachine controllerId=0] Triggering online replica state changes
09:51:26.359 [Test worker] INFO kafka.coordinator.transaction.TransactionCoordinator - [TransactionCoordinator id=0] Starting up.
09:51:26.359 [Controller-0-to-broker-0-send-thread] DEBUG org.apache.kafka.clients.NetworkClient - [Controller id=0, targetBrokerId=0] Initiating connection to node localhost:59716 (id: 0 rack: null)
09:51:26.360 [Test worker] DEBUG kafka.utils.KafkaScheduler - Initializing task scheduler.
09:51:26.360 [Test worker] DEBUG kafka.utils.KafkaScheduler - Scheduling task transaction-abort with initial delay 60000 ms and period 60000 ms.
09:51:26.362 [controller-event-thread] INFO kafka.controller.ReplicaStateMachine - [ReplicaStateMachine controllerId=0] Started replica state machine with initial state -> Map()
09:51:26.363 [kafka-socket-acceptor-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Acceptor - Accepted connection from /127.0.0.1:59717 on /127.0.0.1:59716 and assigned it to processor 0, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400]
09:51:26.363 [controller-event-thread] INFO kafka.controller.PartitionStateMachine - [PartitionStateMachine controllerId=0] Initializing partition state
09:51:26.363 [controller-event-thread] INFO kafka.controller.PartitionStateMachine - [PartitionStateMachine controllerId=0] Triggering online partition state changes
09:51:26.364 [Test worker] DEBUG kafka.utils.KafkaScheduler - Scheduling task transactionalId-expiration with initial delay 3600000 ms and period 3600000 ms.
09:51:26.364 [Controller-0-to-broker-0-send-thread] DEBUG org.apache.kafka.common.network.Selector - [Controller id=0, targetBrokerId=0] Created socket with SO_RCVBUF = 408300, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node 0
09:51:26.364 [Controller-0-to-broker-0-send-thread] DEBUG org.apache.kafka.clients.NetworkClient - [Controller id=0, targetBrokerId=0] Completed connection to node 0. Ready.
09:51:26.365 [Controller-0-to-broker-0-send-thread] INFO kafka.controller.RequestSendThread - [RequestSendThread controllerId=0] Controller 0 connected to localhost:59716 (id: 0 rack: null) for sending state change requests
09:51:26.365 [TxnMarkerSenderThread-0] INFO kafka.coordinator.transaction.TransactionMarkerChannelManager - [Transaction Marker Channel Manager 0]: Starting
09:51:26.366 [controller-event-thread] INFO kafka.controller.PartitionStateMachine - [PartitionStateMachine controllerId=0] Started partition state machine with initial state -> Map()
09:51:26.366 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Ready to serve as the new controller with epoch 1
09:51:26.367 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Removing partitions Set() from the list of reassigned partitions in zookeeper
09:51:26.368 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] No more partitions need to be reassigned. Deleting zk path /admin/reassign_partitions
09:51:26.369 [Test worker] INFO kafka.coordinator.transaction.TransactionCoordinator - [TransactionCoordinator id=0] Startup complete.
09:51:26.370 [ProcessThread(sid:0 cport:59713):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1000a57cb210001 type:delete cxid:0x31 zxid:0x1e txntype:-1 reqpath:n/a Error Path:/admin/reassign_partitions Error:KeeperErrorCode = NoNode for /admin/reassign_partitions
09:51:26.370 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:delete cxid:0x31 zxid:0x1e txntype:-1 reqpath:n/a
09:51:26.371 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Ignoring processTxn failure hdr: -1 : error: -101
09:51:26.371 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/admin/reassign_partitions serverPath:/admin/reassign_partitions finished:false header:: 49,2  replyHeader:: 49,30,-101  request:: '/admin/reassign_partitions,-1  response:: null
09:51:26.373 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x32 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/preferred_replica_election
09:51:26.373 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x32 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/preferred_replica_election
09:51:26.373 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/admin/preferred_replica_election serverPath:/admin/preferred_replica_election finished:false header:: 50,4  replyHeader:: 50,30,-101  request:: '/admin/preferred_replica_election,T  response::  
09:51:26.374 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Partitions undergoing preferred replica election: 
09:51:26.375 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Partitions that completed preferred replica election: 
09:51:26.375 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Skipping preferred replica election for partitions due to topic deletion: 
09:51:26.375 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Resuming preferred replica election for partitions: 
09:51:26.376 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Starting preferred replica leader election for partitions 
09:51:26.377 [ProcessThread(sid:0 cport:59713):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1000a57cb210001 type:delete cxid:0x33 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
09:51:26.377 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:delete cxid:0x33 zxid:0x1f txntype:-1 reqpath:n/a
09:51:26.377 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Ignoring processTxn failure hdr: -1 : error: -101
09:51:26.378 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/admin/preferred_replica_election serverPath:/admin/preferred_replica_election finished:false header:: 51,2  replyHeader:: 51,31,-101  request:: '/admin/preferred_replica_election,-1  response:: null
09:51:26.378 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Starting the controller scheduler
09:51:26.379 [controller-event-thread] DEBUG kafka.utils.KafkaScheduler - Initializing task scheduler.
09:51:26.379 [controller-event-thread] DEBUG kafka.utils.KafkaScheduler - Scheduling task auto-leader-rebalance-task with initial delay 5000 ms and period -1000 ms.
09:51:26.381 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:exists cxid:0x34 zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller
09:51:26.381 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:exists cxid:0x34 zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller
09:51:26.381 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/controller serverPath:/controller finished:false header:: 52,3  replyHeader:: 52,31,0  request:: '/controller,T  response:: s{26,26,1566517886280,1566517886280,0,0,0,72068966224297985,54,0,26} 
09:51:26.382 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x35 zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller
09:51:26.382 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x35 zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller
09:51:26.382 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/controller serverPath:/controller finished:false header:: 53,4  replyHeader:: 53,31,0  request:: '/controller,T  response:: #7b2276657273696f6e223a312c2262726f6b65726964223a302c2274696d657374616d70223a2231353636353137383836323738227d,s{26,26,1566517886280,1566517886280,0,0,0,72068966224297985,54,0,26} 
09:51:26.384 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:exists cxid:0x36 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/reassign_partitions
09:51:26.384 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:exists cxid:0x36 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/reassign_partitions
09:51:26.384 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/admin/reassign_partitions serverPath:/admin/reassign_partitions finished:false header:: 54,3  replyHeader:: 54,31,-101  request:: '/admin/reassign_partitions,T  response::  
09:51:26.385 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:exists cxid:0x37 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/preferred_replica_election
09:51:26.385 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:exists cxid:0x37 zxid:0xfffffffffffffffe txntype:unknown reqpath:/admin/preferred_replica_election
09:51:26.385 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/admin/preferred_replica_election serverPath:/admin/preferred_replica_election finished:false header:: 55,3  replyHeader:: 55,31,-101  request:: '/admin/preferred_replica_election,T  response::  
09:51:26.410 [/config/changes-event-process-thread] INFO kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread - [/config/changes-event-process-thread]: Starting
09:51:26.410 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x38 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/changes
09:51:26.410 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x38 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/changes
09:51:26.410 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x39 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics
09:51:26.410 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x39 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics
09:51:26.411 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/changes serverPath:/config/changes finished:false header:: 56,12  replyHeader:: 56,31,0  request:: '/config/changes,T  response:: v{},s{10,10,1566517885650,1566517885650,0,0,0,0,0,0,10} 
09:51:26.411 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/topics serverPath:/config/topics finished:false header:: 57,12  replyHeader:: 57,31,0  request:: '/config/topics,F  response:: v{},s{18,18,1566517885664,1566517885664,0,0,0,0,0,0,18} 
09:51:26.412 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x3a zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/clients
09:51:26.412 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x3a zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/clients
09:51:26.413 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/clients serverPath:/config/clients finished:false header:: 58,12  replyHeader:: 58,31,0  request:: '/config/clients,F  response:: v{},s{19,19,1566517885665,1566517885665,0,0,0,0,0,0,19} 
09:51:26.413 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x3b zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/users
09:51:26.413 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x3b zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/users
09:51:26.413 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/users serverPath:/config/users finished:false header:: 59,12  replyHeader:: 59,31,0  request:: '/config/users,F  response:: v{},s{20,20,1566517885667,1566517885667,0,0,0,0,0,0,20} 
09:51:26.414 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x3c zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/users
09:51:26.415 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x3c zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/users
09:51:26.415 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/users serverPath:/config/users finished:false header:: 60,12  replyHeader:: 60,31,0  request:: '/config/users,F  response:: v{},s{20,20,1566517885667,1566517885667,0,0,0,0,0,0,20} 
09:51:26.416 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x3d zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/brokers
09:51:26.416 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x3d zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/brokers
09:51:26.417 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/brokers serverPath:/config/brokers finished:false header:: 61,12  replyHeader:: 61,31,0  request:: '/config/brokers,F  response:: v{},s{21,21,1566517885669,1566517885669,0,0,0,0,0,0,21} 
09:51:26.418 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Processor - Processor 0 listening to new connection from /127.0.0.1:59717
09:51:26.419 [Test worker] INFO kafka.network.SocketServer - [SocketServer brokerId=0] Started processors for 1 acceptors
09:51:26.421 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
09:51:26.421 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
09:51:26.422 [Test worker] INFO kafka.server.KafkaServer - [KafkaServer id=0] started
09:51:26.435 [Test worker] INFO org.apache.kafka.clients.admin.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [127.0.0.1:59716]
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

09:51:26.440 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=UPDATE_METADATA, apiVersion=4, clientId=0, correlationId=0) -- {controller_id=0,controller_epoch=1,partition_states=[],live_brokers=[{id=0,end_points=[{port=59716,host=localhost,listener_name=PLAINTEXT,security_protocol_type=0}],rack=null}]},response:{error_code=0} from connection 127.0.0.1:59716-127.0.0.1:59717-0;totalTime:14.533,requestQueueTime:2.817,localTime:9.789,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.262,sendTime:1.85,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.448 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
09:51:26.448 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
09:51:26.448 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name successful-authentication:
09:51:26.448 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name failed-authentication:
09:51:26.449 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
09:51:26.449 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
09:51:26.449 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
09:51:26.449 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
09:51:26.450 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
09:51:26.450 [Test worker] DEBUG org.apache.kafka.clients.admin.internals.AdminMetadataManager - [AdminClient clientId=adminclient-1] Setting bootstrap cluster metadata Cluster(id = null, nodes = [127.0.0.1:59716 (id: -1 rack: null)], partitions = [], controller = null).
09:51:26.454 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
09:51:26.455 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
09:51:26.457 [Test worker] DEBUG org.apache.kafka.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Kafka admin client initialized
09:51:26.459 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating connection to node 127.0.0.1:59716 (id: -1 rack: null)
09:51:26.459 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
09:51:26.459 [kafka-socket-acceptor-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Acceptor - Accepted connection from /127.0.0.1:59718 on /127.0.0.1:59716 and assigned it to processor 1, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400]
09:51:26.460 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG kafka.network.Processor - Processor 1 listening to new connection from /127.0.0.1:59718
09:51:26.460 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
09:51:26.460 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
09:51:26.460 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.network.Selector - [AdminClient clientId=adminclient-1] Created socket with SO_RCVBUF = 342972, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node -1
09:51:26.460 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Completed connection to node -1. Fetching API versions.
09:51:26.460 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node -1.
09:51:26.465 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=API_VERSIONS, apiVersion=2, clientId=adminclient-1, correlationId=0) -- {},response:{error_code=0,api_versions=[{api_key=0,min_version=0,max_version=6},{api_key=1,min_version=0,max_version=8},{api_key=2,min_version=0,max_version=3},{api_key=3,min_version=0,max_version=6},{api_key=4,min_version=0,max_version=1},{api_key=5,min_version=0,max_version=0},{api_key=6,min_version=0,max_version=4},{api_key=7,min_version=0,max_version=1},{api_key=8,min_version=0,max_version=4},{api_key=9,min_version=0,max_version=4},{api_key=10,min_version=0,max_version=2},{api_key=11,min_version=0,max_version=3},{api_key=12,min_version=0,max_version=2},{api_key=13,min_version=0,max_version=2},{api_key=14,min_version=0,max_version=2},{api_key=15,min_version=0,max_version=2},{api_key=16,min_version=0,max_version=2},{api_key=17,min_version=0,max_version=1},{api_key=18,min_version=0,max_version=2},{api_key=19,min_version=0,max_version=3},{api_key=20,min_version=0,max_version=2},{api_key=21,min_version=0,max_version=1},{api_key=22,min_version=0,max_version=1},{api_key=23,min_version=0,max_version=1},{api_key=24,min_version=0,max_version=1},{api_key=25,min_version=0,max_version=1},{api_key=26,min_version=0,max_version=1},{api_key=27,min_version=0,max_version=0},{api_key=28,min_version=0,max_version=1},{api_key=29,min_version=0,max_version=1},{api_key=30,min_version=0,max_version=1},{api_key=31,min_version=0,max_version=1},{api_key=32,min_version=0,max_version=2},{api_key=33,min_version=0,max_version=1},{api_key=34,min_version=0,max_version=1},{api_key=35,min_version=0,max_version=1},{api_key=36,min_version=0,max_version=0},{api_key=37,min_version=0,max_version=1},{api_key=38,min_version=0,max_version=1},{api_key=39,min_version=0,max_version=1},{api_key=40,min_version=0,max_version=1},{api_key=41,min_version=0,max_version=1},{api_key=42,min_version=0,max_version=1}],throttle_time_ms=0} from connection 127.0.0.1:59716-127.0.0.1:59718-0;totalTime:2.229,requestQueueTime:0.068,localTime:1.904,remoteTime:0.0,throttleTime:1.511,responseQueueTime:0.09,sendTime:0.19,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.467 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Recorded API versions for node -1: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
09:51:26.472 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=METADATA, apiVersion=6, clientId=adminclient-1, correlationId=1) -- {topics=[],allow_auto_topic_creation=true},response:{throttle_time_ms=0,brokers=[{node_id=0,host=localhost,port=59716,rack=null}],cluster_id=zfAayvJzT1W78feO7Y00sA,controller_id=0,topic_metadata=[]} from connection 127.0.0.1:59716-127.0.0.1:59718-0;totalTime:3.763,requestQueueTime:0.081,localTime:3.422,remoteTime:0.0,throttleTime:1.293,responseQueueTime:0.105,sendTime:0.191,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.472 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.admin.internals.AdminMetadataManager - [AdminClient clientId=adminclient-1] Updating cluster metadata to Cluster(id = zfAayvJzT1W78feO7Y00sA, nodes = [localhost:59716 (id: 0 rack: null)], partitions = [], controller = localhost:59716 (id: 0 rack: null))
09:51:26.473 [Test worker] DEBUG org.apache.kafka.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Queueing Call(callName=createTopics, deadlineMs=1566518006470) with a timeout 120000 ms from now.
09:51:26.474 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating connection to node localhost:59716 (id: 0 rack: null)
09:51:26.474 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
09:51:26.475 [kafka-socket-acceptor-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Acceptor - Accepted connection from /127.0.0.1:59719 on /127.0.0.1:59716 and assigned it to processor 2, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400]
09:51:26.475 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
09:51:26.475 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG kafka.network.Processor - Processor 2 listening to new connection from /127.0.0.1:59719
09:51:26.475 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
09:51:26.476 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.network.Selector - [AdminClient clientId=adminclient-1] Created socket with SO_RCVBUF = 342972, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node 0
09:51:26.476 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Completed connection to node 0. Fetching API versions.
09:51:26.476 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Initiating API versions fetch from node 0.
09:51:26.478 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=API_VERSIONS, apiVersion=2, clientId=adminclient-1, correlationId=2) -- {},response:{error_code=0,api_versions=[{api_key=0,min_version=0,max_version=6},{api_key=1,min_version=0,max_version=8},{api_key=2,min_version=0,max_version=3},{api_key=3,min_version=0,max_version=6},{api_key=4,min_version=0,max_version=1},{api_key=5,min_version=0,max_version=0},{api_key=6,min_version=0,max_version=4},{api_key=7,min_version=0,max_version=1},{api_key=8,min_version=0,max_version=4},{api_key=9,min_version=0,max_version=4},{api_key=10,min_version=0,max_version=2},{api_key=11,min_version=0,max_version=3},{api_key=12,min_version=0,max_version=2},{api_key=13,min_version=0,max_version=2},{api_key=14,min_version=0,max_version=2},{api_key=15,min_version=0,max_version=2},{api_key=16,min_version=0,max_version=2},{api_key=17,min_version=0,max_version=1},{api_key=18,min_version=0,max_version=2},{api_key=19,min_version=0,max_version=3},{api_key=20,min_version=0,max_version=2},{api_key=21,min_version=0,max_version=1},{api_key=22,min_version=0,max_version=1},{api_key=23,min_version=0,max_version=1},{api_key=24,min_version=0,max_version=1},{api_key=25,min_version=0,max_version=1},{api_key=26,min_version=0,max_version=1},{api_key=27,min_version=0,max_version=0},{api_key=28,min_version=0,max_version=1},{api_key=29,min_version=0,max_version=1},{api_key=30,min_version=0,max_version=1},{api_key=31,min_version=0,max_version=1},{api_key=32,min_version=0,max_version=2},{api_key=33,min_version=0,max_version=1},{api_key=34,min_version=0,max_version=1},{api_key=35,min_version=0,max_version=1},{api_key=36,min_version=0,max_version=0},{api_key=37,min_version=0,max_version=1},{api_key=38,min_version=0,max_version=1},{api_key=39,min_version=0,max_version=1},{api_key=40,min_version=0,max_version=1},{api_key=41,min_version=0,max_version=1},{api_key=42,min_version=0,max_version=1}],throttle_time_ms=0} from connection 127.0.0.1:59716-127.0.0.1:59719-0;totalTime:1.398,requestQueueTime:0.064,localTime:0.841,remoteTime:0.0,throttleTime:0.8,responseQueueTime:0.097,sendTime:0.413,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.478 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.NetworkClient - [AdminClient clientId=adminclient-1] Recorded API versions for node 0: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
09:51:26.490 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:exists cxid:0x3e zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/templateTopic
09:51:26.490 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:exists cxid:0x3e zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/templateTopic
09:51:26.490 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/templateTopic serverPath:/brokers/topics/templateTopic finished:false header:: 62,3  replyHeader:: 62,31,-101  request:: '/brokers/topics/templateTopic,F  response::  
09:51:26.492 [ProcessThread(sid:0 cport:59713):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1000a57cb210001 type:setData cxid:0x3f zxid:0x20 txntype:-1 reqpath:n/a Error Path:/config/topics/templateTopic Error:KeeperErrorCode = NoNode for /config/topics/templateTopic
09:51:26.493 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:setData cxid:0x3f zxid:0x20 txntype:-1 reqpath:n/a
09:51:26.493 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Ignoring processTxn failure hdr: -1 : error: -101
09:51:26.493 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/topics/templateTopic serverPath:/config/topics/templateTopic finished:false header:: 63,5  replyHeader:: 63,32,-101  request:: '/config/topics/templateTopic,#7b2276657273696f6e223a312c22636f6e666967223a7b7d7d,-1  response::  
09:51:26.494 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x40 zxid:0x21 txntype:1 reqpath:n/a
09:51:26.494 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x40 zxid:0x21 txntype:1 reqpath:n/a
09:51:26.495 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/topics/templateTopic serverPath:/config/topics/templateTopic finished:false header:: 64,1  replyHeader:: 64,33,0  request:: '/config/topics/templateTopic,#7b2276657273696f6e223a312c22636f6e666967223a7b7d7d,v{s{31,s{'world,'anyone}}},0  response:: '/config/topics/templateTopic 
09:51:26.496 [kafka-request-handler-4] INFO kafka.zk.AdminZkClient - Topic creation Map(templateTopic-1 -> ArrayBuffer(0), templateTopic-0 -> ArrayBuffer(0))
09:51:26.498 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x41 zxid:0x22 txntype:1 reqpath:n/a
09:51:26.499 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x41 zxid:0x22 txntype:1 reqpath:n/a
09:51:26.499 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Got notification sessionid:0x1000a57cb210001
09:51:26.499 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Got WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/brokers/topics for sessionid 0x1000a57cb210001
09:51:26.499 [Test worker-EventThread] DEBUG kafka.zookeeper.ZooKeeperClient - [ZooKeeperClient] Received event: WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/brokers/topics
09:51:26.499 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/templateTopic serverPath:/brokers/topics/templateTopic finished:false header:: 65,1  replyHeader:: 65,34,0  request:: '/brokers/topics/templateTopic,#7b2276657273696f6e223a312c22706172746974696f6e73223a7b2231223a5b305d2c2230223a5b305d7d7d,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/templateTopic 
09:51:26.505 [kafka-request-handler-4] DEBUG kafka.zk.AdminZkClient - Updated path /brokers/topics/templateTopic with Map(templateTopic-1 -> ArrayBuffer(0), templateTopic-0 -> ArrayBuffer(0)) for replica assignment
09:51:26.507 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x42 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics
09:51:26.507 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x42 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics
09:51:26.507 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics serverPath:/brokers/topics finished:false header:: 66,12  replyHeader:: 66,34,0  request:: '/brokers/topics,T  response:: v{'templateTopic},s{7,7,1566517885644,1566517885644,0,1,0,0,0,1,34} 
09:51:26.509 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x43 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/templateTopic
09:51:26.509 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x43 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/templateTopic
09:51:26.509 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/templateTopic serverPath:/brokers/topics/templateTopic finished:false header:: 67,4  replyHeader:: 67,34,0  request:: '/brokers/topics/templateTopic,T  response:: #7b2276657273696f6e223a312c22706172746974696f6e73223a7b2231223a5b305d2c2230223a5b305d7d7d,s{34,34,1566517886498,1566517886498,0,0,0,0,44,0,34} 
09:51:26.514 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] New topics: [Set(templateTopic)], deleted topics: [Set()], new partition replica assignment [Map(templateTopic-1 -> Vector(0), templateTopic-0 -> Vector(0))]
09:51:26.515 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] New partition creation callback for templateTopic-1,templateTopic-0
09:51:26.526 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x44 zxid:0x23 txntype:1 reqpath:n/a
09:51:26.526 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x44 zxid:0x23 txntype:1 reqpath:n/a
09:51:26.527 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/templateTopic/partitions serverPath:/brokers/topics/templateTopic/partitions finished:false header:: 68,1  replyHeader:: 68,35,0  request:: '/brokers/topics/templateTopic/partitions,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/templateTopic/partitions 
09:51:26.528 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x45 zxid:0x24 txntype:1 reqpath:n/a
09:51:26.528 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x45 zxid:0x24 txntype:1 reqpath:n/a
09:51:26.529 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x46 zxid:0x25 txntype:1 reqpath:n/a
09:51:26.529 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x46 zxid:0x25 txntype:1 reqpath:n/a
09:51:26.529 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/templateTopic/partitions/1 serverPath:/brokers/topics/templateTopic/partitions/1 finished:false header:: 69,1  replyHeader:: 69,36,0  request:: '/brokers/topics/templateTopic/partitions/1,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/templateTopic/partitions/1 
09:51:26.529 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/templateTopic/partitions/0 serverPath:/brokers/topics/templateTopic/partitions/0 finished:false header:: 70,1  replyHeader:: 70,37,0  request:: '/brokers/topics/templateTopic/partitions/0,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/templateTopic/partitions/0 
09:51:26.531 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x47 zxid:0x26 txntype:1 reqpath:n/a
09:51:26.531 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x47 zxid:0x26 txntype:1 reqpath:n/a
09:51:26.532 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x48 zxid:0x27 txntype:1 reqpath:n/a
09:51:26.532 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/templateTopic/partitions/1/state serverPath:/brokers/topics/templateTopic/partitions/1/state finished:false header:: 71,1  replyHeader:: 71,38,0  request:: '/brokers/topics/templateTopic/partitions/1/state,#7b22636f6e74726f6c6c65725f65706f6368223a312c226c6561646572223a302c2276657273696f6e223a312c226c65616465725f65706f6368223a302c22697372223a5b305d7d,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/templateTopic/partitions/1/state 
09:51:26.532 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x48 zxid:0x27 txntype:1 reqpath:n/a
09:51:26.532 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/templateTopic/partitions/0/state serverPath:/brokers/topics/templateTopic/partitions/0/state finished:false header:: 72,1  replyHeader:: 72,39,0  request:: '/brokers/topics/templateTopic/partitions/0/state,#7b22636f6e74726f6c6c65725f65706f6368223a312c226c6561646572223a302c2276657273696f6e223a312c226c65616465725f65706f6368223a302c22697372223a5b305d7d,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/templateTopic/partitions/0/state 
09:51:26.548 [kafka-request-handler-5] INFO kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions templateTopic-0,templateTopic-1
09:51:26.552 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x49 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics/templateTopic
09:51:26.552 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x49 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics/templateTopic
09:51:26.552 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/topics/templateTopic serverPath:/config/topics/templateTopic finished:false header:: 73,4  replyHeader:: 73,39,0  request:: '/config/topics/templateTopic,F  response:: #7b2276657273696f6e223a312c22636f6e666967223a7b7d7d,s{33,33,1566517886494,1566517886494,0,0,0,0,25,0,33} 
09:51:26.584 [kafka-request-handler-5] DEBUG kafka.log.OffsetIndex - Loaded index file /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473/templateTopic-0/00000000000000000000.index with maxEntries = 1310720, maxIndexSize = 10485760, entries = 0, lastOffset = 0, file position = 0
09:51:26.589 [kafka-request-handler-5] INFO kafka.log.Log - [Log partition=templateTopic-0, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Loading producer state till offset 0 with message format version 2
09:51:26.593 [kafka-request-handler-5] INFO kafka.log.Log - [Log partition=templateTopic-0, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 25 ms
09:51:26.595 [kafka-request-handler-5] DEBUG kafka.utils.KafkaScheduler - Scheduling task PeriodicProducerExpirationCheck with initial delay 600000 ms and period 600000 ms.
09:51:26.595 [kafka-request-handler-5] INFO kafka.log.LogManager - Created log for partition templateTopic-0 in /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
09:51:26.596 [kafka-request-handler-5] INFO kafka.cluster.Partition - [Partition templateTopic-0 broker=0] No checkpointed highwatermark is found for partition templateTopic-0
09:51:26.598 [kafka-request-handler-5] INFO kafka.cluster.Replica - Replica loaded for partition templateTopic-0 with initial high watermark 0
09:51:26.599 [kafka-request-handler-5] INFO kafka.cluster.Partition - [Partition templateTopic-0 broker=0] templateTopic-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
09:51:26.601 [kafka-request-handler-5] DEBUG kafka.server.epoch.LeaderEpochFileCache - [LeaderEpochCache templateTopic-0] Appended new epoch entry EpochEntry(epoch=0, startOffset=0). Cache now contains 1 entries.
09:51:26.609 [kafka-request-handler-5] DEBUG kafka.cluster.Partition - [Partition templateTopic-0 broker=0] Skipping update high watermark since new hw (offset=0 segment=[0:0]) is not larger than old hw (offset=0 segment=[0:0]). All current LEOs are Set(replica 0: (offset=0 segment=[0:0]))
09:51:26.610 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x4a zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics/templateTopic
09:51:26.610 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x4a zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics/templateTopic
09:51:26.611 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/topics/templateTopic serverPath:/config/topics/templateTopic finished:false header:: 74,4  replyHeader:: 74,39,0  request:: '/config/topics/templateTopic,F  response:: #7b2276657273696f6e223a312c22636f6e666967223a7b7d7d,s{33,33,1566517886494,1566517886494,0,0,0,0,25,0,33} 
09:51:26.613 [kafka-request-handler-5] DEBUG kafka.log.OffsetIndex - Loaded index file /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473/templateTopic-1/00000000000000000000.index with maxEntries = 1310720, maxIndexSize = 10485760, entries = 0, lastOffset = 0, file position = 0
09:51:26.613 [kafka-request-handler-5] INFO kafka.log.Log - [Log partition=templateTopic-1, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Loading producer state till offset 0 with message format version 2
09:51:26.614 [kafka-request-handler-5] INFO kafka.log.Log - [Log partition=templateTopic-1, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
09:51:26.615 [kafka-request-handler-5] DEBUG kafka.utils.KafkaScheduler - Scheduling task PeriodicProducerExpirationCheck with initial delay 600000 ms and period 600000 ms.
09:51:26.615 [kafka-request-handler-5] INFO kafka.log.LogManager - Created log for partition templateTopic-1 in /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> [delete], flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 1073741824, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
09:51:26.615 [kafka-request-handler-5] INFO kafka.cluster.Partition - [Partition templateTopic-1 broker=0] No checkpointed highwatermark is found for partition templateTopic-1
09:51:26.615 [kafka-request-handler-5] INFO kafka.cluster.Replica - Replica loaded for partition templateTopic-1 with initial high watermark 0
09:51:26.615 [kafka-request-handler-5] INFO kafka.cluster.Partition - [Partition templateTopic-1 broker=0] templateTopic-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
09:51:26.615 [kafka-request-handler-5] DEBUG kafka.server.epoch.LeaderEpochFileCache - [LeaderEpochCache templateTopic-1] Appended new epoch entry EpochEntry(epoch=0, startOffset=0). Cache now contains 1 entries.
09:51:26.616 [kafka-request-handler-5] DEBUG kafka.cluster.Partition - [Partition templateTopic-1 broker=0] Skipping update high watermark since new hw (offset=0 segment=[0:0]) is not larger than old hw (offset=0 segment=[0:0]). All current LEOs are Set(replica 0: (offset=0 segment=[0:0]))
09:51:26.618 [kafka-request-handler-5] DEBUG kafka.utils.KafkaScheduler - Scheduling task highwatermark-checkpoint with initial delay 0 ms and period 9223372036854775807 ms.
09:51:26.621 [kafka-request-handler-5] INFO kafka.server.ReplicaAlterLogDirsManager - [ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List()
09:51:26.624 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=LEADER_AND_ISR, apiVersion=1, clientId=0, correlationId=1) -- {controller_id=0,controller_epoch=1,partition_states=[{topic=templateTopic,partition=0,controller_epoch=1,leader=0,leader_epoch=0,isr=[0],zk_version=0,replicas=[0],is_new=true},{topic=templateTopic,partition=1,controller_epoch=1,leader=0,leader_epoch=0,isr=[0],zk_version=0,replicas=[0],is_new=true}],live_leaders=[{id=0,host=localhost,port=59716}]},response:{error_code=0,partitions=[{topic=templateTopic,partition=1,error_code=0},{topic=templateTopic,partition=0,error_code=0}]} from connection 127.0.0.1:59716-127.0.0.1:59717-0;totalTime:80.854,requestQueueTime:0.151,localTime:80.427,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.094,sendTime:0.206,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.630 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=CREATE_TOPICS, apiVersion=3, clientId=adminclient-1, correlationId=3) -- {create_topic_requests=[{topic=templateTopic,num_partitions=2,replication_factor=1,replica_assignment=[],config_entries=[]}],timeout=119992,validate_only=false},response:{throttle_time_ms=0,topic_errors=[{topic=templateTopic,error_code=0,error_message=null}]} from connection 127.0.0.1:59716-127.0.0.1:59719-0;totalTime:150.558,requestQueueTime:0.115,localTime:37.062,remoteTime:112.409,throttleTime:0.688,responseQueueTime:0.088,sendTime:0.193,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.630 [Test worker] DEBUG org.apache.kafka.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Initiating close operation.
09:51:26.630 [kafka-request-handler-6] DEBUG kafka.server.AdminManager - [Admin Manager on Broker 0]: Request key templateTopic unblocked 1 topic requests.
09:51:26.630 [Test worker] DEBUG org.apache.kafka.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Waiting for the I/O thread to exit. Hard shutdown in 30000 ms.
09:51:26.630 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=UPDATE_METADATA, apiVersion=4, clientId=0, correlationId=2) -- {controller_id=0,controller_epoch=1,partition_states=[{topic=templateTopic,partition=0,controller_epoch=1,leader=0,leader_epoch=0,isr=[0],zk_version=0,replicas=[0],offline_replicas=[]},{topic=templateTopic,partition=1,controller_epoch=1,leader=0,leader_epoch=0,isr=[0],zk_version=0,replicas=[0],offline_replicas=[]}],live_brokers=[{id=0,end_points=[{port=59716,host=localhost,listener_name=PLAINTEXT,security_protocol_type=0}],rack=null}]},response:{error_code=0} from connection 127.0.0.1:59716-127.0.0.1:59717-0;totalTime:5.4,requestQueueTime:0.14,localTime:5.048,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.069,sendTime:0.157,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.631 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
09:51:26.632 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
09:51:26.632 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name successful-authentication:
09:51:26.632 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name failed-authentication:
09:51:26.632 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
09:51:26.632 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
09:51:26.632 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
09:51:26.633 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
09:51:26.633 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
09:51:26.633 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
09:51:26.633 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
09:51:26.633 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
09:51:26.633 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG org.apache.kafka.common.network.Selector - [SocketServer brokerId=0] Connection with /127.0.0.1 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:96)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:335)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:296)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:562)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:498)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:427)
	at kafka.network.Processor.poll(SocketServer.scala:679)
	at kafka.network.Processor.run(SocketServer.scala:584)
	at java.lang.Thread.run(Thread.java:748)
09:51:26.633 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG org.apache.kafka.common.network.Selector - [SocketServer brokerId=0] Connection with /127.0.0.1 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:96)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:335)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:296)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:562)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:498)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:427)
	at kafka.network.Processor.poll(SocketServer.scala:679)
	at kafka.network.Processor.run(SocketServer.scala:584)
	at java.lang.Thread.run(Thread.java:748)
09:51:26.633 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-0.bytes-sent
09:51:26.634 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-0.bytes-received
09:51:26.634 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node-0.latency
09:51:26.634 [kafka-admin-client-thread | adminclient-1] DEBUG org.apache.kafka.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Exiting AdminClientRunnable thread.
09:51:26.634 [Test worker] DEBUG org.apache.kafka.clients.admin.KafkaAdminClient - [AdminClient clientId=adminclient-1] Kafka admin client closed.
09:51:26.732 [Test worker] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 10
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59716]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testT
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 60000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

09:51:26.733 [Test worker] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-1, groupId=testT] Initializing the Kafka consumer
09:51:26.739 [Test worker] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [127.0.0.1:59716 (id: -1 rack: null)], partitions = [], controller = null)
09:51:26.747 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
09:51:26.748 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
09:51:26.748 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
09:51:26.748 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name successful-authentication:
09:51:26.748 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name failed-authentication:
09:51:26.748 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
09:51:26.748 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
09:51:26.749 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
09:51:26.749 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
09:51:26.749 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
09:51:26.763 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
09:51:26.763 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
09:51:26.764 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
09:51:26.765 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
09:51:26.768 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
09:51:26.768 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
09:51:26.769 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
09:51:26.769 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
09:51:26.769 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lead
09:51:26.769 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
09:51:26.770 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
09:51:26.770 [Test worker] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-1, groupId=testT] Kafka consumer initialized
09:51:26.772 [Test worker] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-1, groupId=testT] Initiating connection to node 127.0.0.1:59716 (id: -1 rack: null)
09:51:26.785 [kafka-socket-acceptor-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Acceptor - Accepted connection from /127.0.0.1:59720 on /127.0.0.1:59716 and assigned it to processor 0, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400]
09:51:26.785 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Processor - Processor 0 listening to new connection from /127.0.0.1:59720
09:51:26.785 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
09:51:26.785 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
09:51:26.786 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
09:51:26.786 [Test worker] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-1, groupId=testT] Created socket with SO_RCVBUF = 342972, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node -1
09:51:26.786 [Test worker] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-1, groupId=testT] Completed connection to node -1. Fetching API versions.
09:51:26.786 [Test worker] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-1, groupId=testT] Initiating API versions fetch from node -1.
09:51:26.789 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=API_VERSIONS, apiVersion=2, clientId=consumer-1, correlationId=1) -- {},response:{error_code=0,api_versions=[{api_key=0,min_version=0,max_version=6},{api_key=1,min_version=0,max_version=8},{api_key=2,min_version=0,max_version=3},{api_key=3,min_version=0,max_version=6},{api_key=4,min_version=0,max_version=1},{api_key=5,min_version=0,max_version=0},{api_key=6,min_version=0,max_version=4},{api_key=7,min_version=0,max_version=1},{api_key=8,min_version=0,max_version=4},{api_key=9,min_version=0,max_version=4},{api_key=10,min_version=0,max_version=2},{api_key=11,min_version=0,max_version=3},{api_key=12,min_version=0,max_version=2},{api_key=13,min_version=0,max_version=2},{api_key=14,min_version=0,max_version=2},{api_key=15,min_version=0,max_version=2},{api_key=16,min_version=0,max_version=2},{api_key=17,min_version=0,max_version=1},{api_key=18,min_version=0,max_version=2},{api_key=19,min_version=0,max_version=3},{api_key=20,min_version=0,max_version=2},{api_key=21,min_version=0,max_version=1},{api_key=22,min_version=0,max_version=1},{api_key=23,min_version=0,max_version=1},{api_key=24,min_version=0,max_version=1},{api_key=25,min_version=0,max_version=1},{api_key=26,min_version=0,max_version=1},{api_key=27,min_version=0,max_version=0},{api_key=28,min_version=0,max_version=1},{api_key=29,min_version=0,max_version=1},{api_key=30,min_version=0,max_version=1},{api_key=31,min_version=0,max_version=1},{api_key=32,min_version=0,max_version=2},{api_key=33,min_version=0,max_version=1},{api_key=34,min_version=0,max_version=1},{api_key=35,min_version=0,max_version=1},{api_key=36,min_version=0,max_version=0},{api_key=37,min_version=0,max_version=1},{api_key=38,min_version=0,max_version=1},{api_key=39,min_version=0,max_version=1},{api_key=40,min_version=0,max_version=1},{api_key=41,min_version=0,max_version=1},{api_key=42,min_version=0,max_version=1}],throttle_time_ms=0} from connection 127.0.0.1:59716-127.0.0.1:59720-1;totalTime:1.018,requestQueueTime:0.105,localTime:0.666,remoteTime:0.0,throttleTime:0.529,responseQueueTime:0.069,sendTime:0.196,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.789 [Test worker] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-1, groupId=testT] Recorded API versions for node -1: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
09:51:26.790 [Test worker] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-1, groupId=testT] Sending metadata request (type=MetadataRequest, topics=) to node 127.0.0.1:59716 (id: -1 rack: null)
09:51:26.791 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=METADATA, apiVersion=6, clientId=consumer-1, correlationId=2) -- {topics=[],allow_auto_topic_creation=true},response:{throttle_time_ms=0,brokers=[{node_id=0,host=localhost,port=59716,rack=null}],cluster_id=zfAayvJzT1W78feO7Y00sA,controller_id=0,topic_metadata=[]} from connection 127.0.0.1:59716-127.0.0.1:59720-1;totalTime:0.462,requestQueueTime:0.074,localTime:0.236,remoteTime:0.0,throttleTime:0.125,responseQueueTime:0.052,sendTime:0.112,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.795 [Test worker] INFO org.apache.kafka.clients.Metadata - Cluster ID: zfAayvJzT1W78feO7Y00sA
09:51:26.797 [Test worker] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = zfAayvJzT1W78feO7Y00sA, nodes = [localhost:59716 (id: 0 rack: null)], partitions = [], controller = localhost:59716 (id: 0 rack: null))
09:51:26.798 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=METADATA, apiVersion=6, clientId=consumer-1, correlationId=0) -- {topics=[templateTopic],allow_auto_topic_creation=true},response:{throttle_time_ms=0,brokers=[{node_id=0,host=localhost,port=59716,rack=null}],cluster_id=zfAayvJzT1W78feO7Y00sA,controller_id=0,topic_metadata=[{error_code=0,topic=templateTopic,is_internal=false,partition_metadata=[{error_code=0,partition=1,leader=0,replicas=[0],isr=[0],offline_replicas=[]},{error_code=0,partition=0,leader=0,replicas=[0],isr=[0],offline_replicas=[]}]}]} from connection 127.0.0.1:59716-127.0.0.1:59720-1;totalTime:6.716,requestQueueTime:0.063,localTime:6.309,remoteTime:0.0,throttleTime:0.625,responseQueueTime:0.207,sendTime:0.156,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.799 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
09:51:26.799 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG org.apache.kafka.common.network.Selector - [SocketServer brokerId=0] Connection with /127.0.0.1 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:96)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:335)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:296)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:562)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:498)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:427)
	at kafka.network.Processor.poll(SocketServer.scala:679)
	at kafka.network.Processor.run(SocketServer.scala:584)
	at java.lang.Thread.run(Thread.java:748)
09:51:26.799 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
09:51:26.799 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name successful-authentication:
09:51:26.800 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name failed-authentication:
09:51:26.800 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
09:51:26.800 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
09:51:26.800 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
09:51:26.800 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
09:51:26.800 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
09:51:26.800 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-sent
09:51:26.801 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.bytes-received
09:51:26.801 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name node--1.latency
09:51:26.801 [Test worker] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-1, groupId=testT] Kafka consumer has been closed
09:51:26.810 [Test worker] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 10
	auto.offset.reset = latest
	bootstrap.servers = [127.0.0.1:59716]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testT
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.IntegerDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 60000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

09:51:26.811 [Test worker] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-2, groupId=testT] Initializing the Kafka consumer
09:51:26.811 [Test worker] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 1 to Cluster(id = null, nodes = [127.0.0.1:59716 (id: -1 rack: null)], partitions = [], controller = null)
09:51:26.812 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-throttle-time
09:51:26.812 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-closed:
09:51:26.812 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name connections-created:
09:51:26.813 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name successful-authentication:
09:51:26.813 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name failed-authentication:
09:51:26.813 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent-received:
09:51:26.813 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-sent:
09:51:26.814 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-received:
09:51:26.814 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name select-time:
09:51:26.814 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name io-time:
09:51:26.815 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name heartbeat-latency
09:51:26.815 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name join-latency
09:51:26.815 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name sync-latency
09:51:26.816 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name commit-latency
09:51:26.816 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name bytes-fetched
09:51:26.816 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-fetched
09:51:26.817 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name fetch-latency
09:51:26.817 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lag
09:51:26.817 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name records-lead
09:51:26.817 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 2.0.1
09:51:26.817 [Test worker] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : fa14705e51bd2ce5
09:51:26.817 [Test worker] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-2, groupId=testT] Kafka consumer initialized
09:51:26.818 [Test worker] DEBUG org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-2, groupId=testT] Subscribed to topic(s): templateTopic
09:51:26.822 [Test worker] INFO org.springframework.scheduling.concurrent.ThreadPoolTaskScheduler - Initializing ExecutorService
09:51:26.828 [templateTests-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
09:51:26.828 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=testT] Sending FindCoordinator request to broker 127.0.0.1:59716 (id: -1 rack: null)
09:51:26.829 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initiating connection to node 127.0.0.1:59716 (id: -1 rack: null)
09:51:26.830 [templateTests-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-sent
09:51:26.830 [kafka-socket-acceptor-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Acceptor - Accepted connection from /127.0.0.1:59721 on /127.0.0.1:59716 and assigned it to processor 1, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400]
09:51:26.830 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG kafka.network.Processor - Processor 1 listening to new connection from /127.0.0.1:59721
09:51:26.830 [templateTests-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.bytes-received
09:51:26.830 [templateTests-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node--1.latency
09:51:26.830 [templateTests-C-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-2, groupId=testT] Created socket with SO_RCVBUF = 342972, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node -1
09:51:26.830 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Completed connection to node -1. Fetching API versions.
09:51:26.830 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initiating API versions fetch from node -1.
09:51:26.832 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=API_VERSIONS, apiVersion=2, clientId=consumer-2, correlationId=1) -- {},response:{error_code=0,api_versions=[{api_key=0,min_version=0,max_version=6},{api_key=1,min_version=0,max_version=8},{api_key=2,min_version=0,max_version=3},{api_key=3,min_version=0,max_version=6},{api_key=4,min_version=0,max_version=1},{api_key=5,min_version=0,max_version=0},{api_key=6,min_version=0,max_version=4},{api_key=7,min_version=0,max_version=1},{api_key=8,min_version=0,max_version=4},{api_key=9,min_version=0,max_version=4},{api_key=10,min_version=0,max_version=2},{api_key=11,min_version=0,max_version=3},{api_key=12,min_version=0,max_version=2},{api_key=13,min_version=0,max_version=2},{api_key=14,min_version=0,max_version=2},{api_key=15,min_version=0,max_version=2},{api_key=16,min_version=0,max_version=2},{api_key=17,min_version=0,max_version=1},{api_key=18,min_version=0,max_version=2},{api_key=19,min_version=0,max_version=3},{api_key=20,min_version=0,max_version=2},{api_key=21,min_version=0,max_version=1},{api_key=22,min_version=0,max_version=1},{api_key=23,min_version=0,max_version=1},{api_key=24,min_version=0,max_version=1},{api_key=25,min_version=0,max_version=1},{api_key=26,min_version=0,max_version=1},{api_key=27,min_version=0,max_version=0},{api_key=28,min_version=0,max_version=1},{api_key=29,min_version=0,max_version=1},{api_key=30,min_version=0,max_version=1},{api_key=31,min_version=0,max_version=1},{api_key=32,min_version=0,max_version=2},{api_key=33,min_version=0,max_version=1},{api_key=34,min_version=0,max_version=1},{api_key=35,min_version=0,max_version=1},{api_key=36,min_version=0,max_version=0},{api_key=37,min_version=0,max_version=1},{api_key=38,min_version=0,max_version=1},{api_key=39,min_version=0,max_version=1},{api_key=40,min_version=0,max_version=1},{api_key=41,min_version=0,max_version=1},{api_key=42,min_version=0,max_version=1}],throttle_time_ms=0} from connection 127.0.0.1:59716-127.0.0.1:59721-1;totalTime:0.556,requestQueueTime:0.044,localTime:0.323,remoteTime:0.0,throttleTime:0.279,responseQueueTime:0.061,sendTime:0.146,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.832 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Recorded API versions for node -1: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
09:51:26.832 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Sending metadata request (type=MetadataRequest, topics=templateTopic) to node 127.0.0.1:59716 (id: -1 rack: null)
09:51:26.833 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=METADATA, apiVersion=6, clientId=consumer-2, correlationId=2) -- {topics=[templateTopic],allow_auto_topic_creation=true},response:{throttle_time_ms=0,brokers=[{node_id=0,host=localhost,port=59716,rack=null}],cluster_id=zfAayvJzT1W78feO7Y00sA,controller_id=0,topic_metadata=[{error_code=0,topic=templateTopic,is_internal=false,partition_metadata=[{error_code=0,partition=1,leader=0,replicas=[0],isr=[0],offline_replicas=[]},{error_code=0,partition=0,leader=0,replicas=[0],isr=[0],offline_replicas=[]}]}]} from connection 127.0.0.1:59716-127.0.0.1:59721-1;totalTime:0.738,requestQueueTime:0.05,localTime:0.53,remoteTime:0.0,throttleTime:0.236,responseQueueTime:0.059,sendTime:0.116,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.834 [templateTests-C-1] INFO org.apache.kafka.clients.Metadata - Cluster ID: zfAayvJzT1W78feO7Y00sA
09:51:26.835 [templateTests-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 2 to Cluster(id = zfAayvJzT1W78feO7Y00sA, nodes = [localhost:59716 (id: 0 rack: null)], partitions = [Partition(topic = templateTopic, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = []), Partition(topic = templateTopic, partition = 1, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])], controller = localhost:59716 (id: 0 rack: null))
09:51:26.835 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x4b zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids
09:51:26.835 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x4b zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids
09:51:26.835 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/ids serverPath:/brokers/ids finished:false header:: 75,12  replyHeader:: 75,39,0  request:: '/brokers/ids,T  response:: v{'0},s{6,6,1566517885642,1566517885642,0,1,0,0,0,1,25} 
09:51:26.836 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x4c zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids/0
09:51:26.836 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x4c zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids/0
09:51:26.836 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/ids/0 serverPath:/brokers/ids/0 finished:false header:: 76,4  replyHeader:: 76,39,0  request:: '/brokers/ids/0,T  response:: #7b226c697374656e65725f73656375726974795f70726f746f636f6c5f6d6170223a7b22504c41494e54455854223a22504c41494e54455854227d2c22656e64706f696e7473223a5b22504c41494e544558543a2f2f6c6f63616c686f73743a3539373136225d2c226a6d785f706f7274223a2d312c22686f7374223a226c6f63616c686f7374222c2274696d657374616d70223a2231353636353137383836323037222c22706f7274223a35393731362c2276657273696f6e223a347d,s{25,25,1566517886227,1566517886227,0,0,0,72068966224297985,190,0,25} 
09:51:26.839 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:exists cxid:0x4d zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/__consumer_offsets
09:51:26.839 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:exists cxid:0x4d zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/__consumer_offsets
09:51:26.839 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/__consumer_offsets serverPath:/brokers/topics/__consumer_offsets finished:false header:: 77,3  replyHeader:: 77,39,-101  request:: '/brokers/topics/__consumer_offsets,F  response::  
09:51:26.840 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x4e zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics
09:51:26.840 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x4e zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics
09:51:26.840 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics serverPath:/brokers/topics finished:false header:: 78,12  replyHeader:: 78,39,0  request:: '/brokers/topics,T  response:: v{'templateTopic},s{7,7,1566517885644,1566517885644,0,1,0,0,0,1,34} 
09:51:26.842 [ProcessThread(sid:0 cport:59713):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x1000a57cb210001 type:setData cxid:0x4f zxid:0x28 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
09:51:26.842 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:setData cxid:0x4f zxid:0x28 txntype:-1 reqpath:n/a
09:51:26.842 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Ignoring processTxn failure hdr: -1 : error: -101
09:51:26.842 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/topics/__consumer_offsets serverPath:/config/topics/__consumer_offsets finished:false header:: 79,5  replyHeader:: 79,40,-101  request:: '/config/topics/__consumer_offsets,#7b2276657273696f6e223a312c22636f6e666967223a7b227365676d656e742e6279746573223a22313034383537363030222c22636f6d7072657373696f6e2e74797065223a2270726f6475636572222c22636c65616e75702e706f6c696379223a22636f6d70616374227d7d,-1  response::  
09:51:26.843 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x50 zxid:0x29 txntype:1 reqpath:n/a
09:51:26.843 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x50 zxid:0x29 txntype:1 reqpath:n/a
09:51:26.844 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/topics/__consumer_offsets serverPath:/config/topics/__consumer_offsets finished:false header:: 80,1  replyHeader:: 80,41,0  request:: '/config/topics/__consumer_offsets,#7b2276657273696f6e223a312c22636f6e666967223a7b227365676d656e742e6279746573223a22313034383537363030222c22636f6d7072657373696f6e2e74797065223a2270726f6475636572222c22636c65616e75702e706f6c696379223a22636f6d70616374227d7d,v{s{31,s{'world,'anyone}}},0  response:: '/config/topics/__consumer_offsets 
09:51:26.844 [kafka-request-handler-1] INFO kafka.zk.AdminZkClient - Topic creation Map(__consumer_offsets-4 -> ArrayBuffer(0), __consumer_offsets-3 -> ArrayBuffer(0), __consumer_offsets-2 -> ArrayBuffer(0), __consumer_offsets-0 -> ArrayBuffer(0), __consumer_offsets-1 -> ArrayBuffer(0))
09:51:26.845 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x51 zxid:0x2a txntype:1 reqpath:n/a
09:51:26.845 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x51 zxid:0x2a txntype:1 reqpath:n/a
09:51:26.845 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Got notification sessionid:0x1000a57cb210001
09:51:26.845 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Got WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/brokers/topics for sessionid 0x1000a57cb210001
09:51:26.845 [Test worker-EventThread] DEBUG kafka.zookeeper.ZooKeeperClient - [ZooKeeperClient] Received event: WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/brokers/topics
09:51:26.845 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/__consumer_offsets serverPath:/brokers/topics/__consumer_offsets finished:false header:: 81,1  replyHeader:: 81,42,0  request:: '/brokers/topics/__consumer_offsets,#7b2276657273696f6e223a312c22706172746974696f6e73223a7b2234223a5b305d2c2231223a5b305d2c2230223a5b305d2c2232223a5b305d2c2233223a5b305d7d7d,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/__consumer_offsets 
09:51:26.845 [kafka-request-handler-1] DEBUG kafka.zk.AdminZkClient - Updated path /brokers/topics/__consumer_offsets with Map(__consumer_offsets-4 -> ArrayBuffer(0), __consumer_offsets-3 -> ArrayBuffer(0), __consumer_offsets-2 -> ArrayBuffer(0), __consumer_offsets-0 -> ArrayBuffer(0), __consumer_offsets-1 -> ArrayBuffer(0)) for replica assignment
09:51:26.846 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x52 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics
09:51:26.846 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getChildren2 cxid:0x52 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics
09:51:26.846 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics serverPath:/brokers/topics finished:false header:: 82,12  replyHeader:: 82,42,0  request:: '/brokers/topics,T  response:: v{'templateTopic,'__consumer_offsets},s{7,7,1566517885644,1566517885644,0,2,0,0,0,2,42} 
09:51:26.846 [kafka-request-handler-1] INFO kafka.server.KafkaApis - [KafkaApi-0] Auto creation of topic __consumer_offsets with 5 partitions and replication factor 1 is successful
09:51:26.846 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x53 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/__consumer_offsets
09:51:26.847 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x53 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/topics/__consumer_offsets
09:51:26.847 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/__consumer_offsets serverPath:/brokers/topics/__consumer_offsets finished:false header:: 83,4  replyHeader:: 83,42,0  request:: '/brokers/topics/__consumer_offsets,T  response:: #7b2276657273696f6e223a312c22706172746974696f6e73223a7b2234223a5b305d2c2231223a5b305d2c2230223a5b305d2c2232223a5b305d2c2233223a5b305d7d7d,s{42,42,1566517886844,1566517886844,0,0,0,0,68,0,42} 
09:51:26.848 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=testT] Received FindCoordinator response ClientResponse(receivedTimeMs=1566517886847, latencyMs=18, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=2, clientId=consumer-2, correlationId=0), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=COORDINATOR_NOT_AVAILABLE, node=:-1 (id: -1 rack: null)))
09:51:26.848 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=testT] Group coordinator lookup failed: The coordinator is not available.
09:51:26.848 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=testT] Coordinator discovery failed, refreshing metadata
09:51:26.848 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] New topics: [Set(__consumer_offsets)], deleted topics: [Set()], new partition replica assignment [Map(__consumer_offsets-4 -> Vector(0), __consumer_offsets-3 -> Vector(0), __consumer_offsets-2 -> Vector(0), __consumer_offsets-0 -> Vector(0), __consumer_offsets-1 -> Vector(0))]
09:51:26.848 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] New partition creation callback for __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
09:51:26.849 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=2, clientId=consumer-2, correlationId=0) -- {coordinator_key=testT,coordinator_type=0},response:{throttle_time_ms=0,error_code=15,error_message=null,coordinator={node_id=-1,host=,port=-1}} from connection 127.0.0.1:59716-127.0.0.1:59721-1;totalTime:13.876,requestQueueTime:0.08,localTime:13.608,remoteTime:0.0,throttleTime:0.758,responseQueueTime:0.07,sendTime:0.136,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.850 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x54 zxid:0x2b txntype:1 reqpath:n/a
09:51:26.850 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x54 zxid:0x2b txntype:1 reqpath:n/a
09:51:26.850 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/__consumer_offsets/partitions serverPath:/brokers/topics/__consumer_offsets/partitions finished:false header:: 84,1  replyHeader:: 84,43,0  request:: '/brokers/topics/__consumer_offsets/partitions,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/__consumer_offsets/partitions 
09:51:26.851 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x55 zxid:0x2c txntype:1 reqpath:n/a
09:51:26.851 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x55 zxid:0x2c txntype:1 reqpath:n/a
09:51:26.852 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/__consumer_offsets/partitions/4 serverPath:/brokers/topics/__consumer_offsets/partitions/4 finished:false header:: 85,1  replyHeader:: 85,44,0  request:: '/brokers/topics/__consumer_offsets/partitions/4,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/__consumer_offsets/partitions/4 
09:51:26.852 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x56 zxid:0x2d txntype:1 reqpath:n/a
09:51:26.852 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x56 zxid:0x2d txntype:1 reqpath:n/a
09:51:26.852 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x57 zxid:0x2e txntype:1 reqpath:n/a
09:51:26.852 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x57 zxid:0x2e txntype:1 reqpath:n/a
09:51:26.852 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x58 zxid:0x2f txntype:1 reqpath:n/a
09:51:26.852 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/__consumer_offsets/partitions/3 serverPath:/brokers/topics/__consumer_offsets/partitions/3 finished:false header:: 86,1  replyHeader:: 86,45,0  request:: '/brokers/topics/__consumer_offsets/partitions/3,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/__consumer_offsets/partitions/3 
09:51:26.852 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x58 zxid:0x2f txntype:1 reqpath:n/a
09:51:26.852 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x59 zxid:0x30 txntype:1 reqpath:n/a
09:51:26.852 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/__consumer_offsets/partitions/2 serverPath:/brokers/topics/__consumer_offsets/partitions/2 finished:false header:: 87,1  replyHeader:: 87,46,0  request:: '/brokers/topics/__consumer_offsets/partitions/2,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/__consumer_offsets/partitions/2 
09:51:26.852 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x59 zxid:0x30 txntype:1 reqpath:n/a
09:51:26.852 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/__consumer_offsets/partitions/0 serverPath:/brokers/topics/__consumer_offsets/partitions/0 finished:false header:: 88,1  replyHeader:: 88,47,0  request:: '/brokers/topics/__consumer_offsets/partitions/0,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/__consumer_offsets/partitions/0 
09:51:26.853 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/__consumer_offsets/partitions/1 serverPath:/brokers/topics/__consumer_offsets/partitions/1 finished:false header:: 89,1  replyHeader:: 89,48,0  request:: '/brokers/topics/__consumer_offsets/partitions/1,,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/__consumer_offsets/partitions/1 
09:51:26.854 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x5a zxid:0x31 txntype:1 reqpath:n/a
09:51:26.854 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x5a zxid:0x31 txntype:1 reqpath:n/a
09:51:26.855 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/__consumer_offsets/partitions/4/state serverPath:/brokers/topics/__consumer_offsets/partitions/4/state finished:false header:: 90,1  replyHeader:: 90,49,0  request:: '/brokers/topics/__consumer_offsets/partitions/4/state,#7b22636f6e74726f6c6c65725f65706f6368223a312c226c6561646572223a302c2276657273696f6e223a312c226c65616465725f65706f6368223a302c22697372223a5b305d7d,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/__consumer_offsets/partitions/4/state 
09:51:26.855 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x5b zxid:0x32 txntype:1 reqpath:n/a
09:51:26.855 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x5b zxid:0x32 txntype:1 reqpath:n/a
09:51:26.855 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x5c zxid:0x33 txntype:1 reqpath:n/a
09:51:26.855 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x5c zxid:0x33 txntype:1 reqpath:n/a
09:51:26.855 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x5d zxid:0x34 txntype:1 reqpath:n/a
09:51:26.855 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x5d zxid:0x34 txntype:1 reqpath:n/a
09:51:26.855 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/__consumer_offsets/partitions/3/state serverPath:/brokers/topics/__consumer_offsets/partitions/3/state finished:false header:: 91,1  replyHeader:: 91,50,0  request:: '/brokers/topics/__consumer_offsets/partitions/3/state,#7b22636f6e74726f6c6c65725f65706f6368223a312c226c6561646572223a302c2276657273696f6e223a312c226c65616465725f65706f6368223a302c22697372223a5b305d7d,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/__consumer_offsets/partitions/3/state 
09:51:26.855 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:create cxid:0x5e zxid:0x35 txntype:1 reqpath:n/a
09:51:26.855 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:create cxid:0x5e zxid:0x35 txntype:1 reqpath:n/a
09:51:26.855 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/__consumer_offsets/partitions/2/state serverPath:/brokers/topics/__consumer_offsets/partitions/2/state finished:false header:: 92,1  replyHeader:: 92,51,0  request:: '/brokers/topics/__consumer_offsets/partitions/2/state,#7b22636f6e74726f6c6c65725f65706f6368223a312c226c6561646572223a302c2276657273696f6e223a312c226c65616465725f65706f6368223a302c22697372223a5b305d7d,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/__consumer_offsets/partitions/2/state 
09:51:26.856 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/__consumer_offsets/partitions/0/state serverPath:/brokers/topics/__consumer_offsets/partitions/0/state finished:false header:: 93,1  replyHeader:: 93,52,0  request:: '/brokers/topics/__consumer_offsets/partitions/0/state,#7b22636f6e74726f6c6c65725f65706f6368223a312c226c6561646572223a302c2276657273696f6e223a312c226c65616465725f65706f6368223a302c22697372223a5b305d7d,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/__consumer_offsets/partitions/0/state 
09:51:26.856 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/topics/__consumer_offsets/partitions/1/state serverPath:/brokers/topics/__consumer_offsets/partitions/1/state finished:false header:: 94,1  replyHeader:: 94,53,0  request:: '/brokers/topics/__consumer_offsets/partitions/1/state,#7b22636f6e74726f6c6c65725f65706f6368223a312c226c6561646572223a302c2276657273696f6e223a312c226c65616465725f65706f6368223a302c22697372223a5b305d7d,v{s{31,s{'world,'anyone}}},0  response:: '/brokers/topics/__consumer_offsets/partitions/1/state 
09:51:26.861 [kafka-request-handler-2] INFO kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-4,__consumer_offsets-3,__consumer_offsets-2,__consumer_offsets-0,__consumer_offsets-1
09:51:26.861 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x5f zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics/__consumer_offsets
09:51:26.861 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x5f zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics/__consumer_offsets
09:51:26.862 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/topics/__consumer_offsets serverPath:/config/topics/__consumer_offsets finished:false header:: 95,4  replyHeader:: 95,53,0  request:: '/config/topics/__consumer_offsets,F  response:: #7b2276657273696f6e223a312c22636f6e666967223a7b227365676d656e742e6279746573223a22313034383537363030222c22636f6d7072657373696f6e2e74797065223a2270726f6475636572222c22636c65616e75702e706f6c696379223a22636f6d70616374227d7d,s{41,41,1566517886843,1566517886843,0,0,0,0,109,0,41} 
09:51:26.864 [kafka-request-handler-2] DEBUG kafka.log.OffsetIndex - Loaded index file /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473/__consumer_offsets-0/00000000000000000000.index with maxEntries = 1310720, maxIndexSize = 10485760, entries = 0, lastOffset = 0, file position = 0
09:51:26.864 [kafka-request-handler-2] INFO kafka.log.Log - [Log partition=__consumer_offsets-0, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Loading producer state till offset 0 with message format version 2
09:51:26.865 [kafka-request-handler-2] INFO kafka.log.Log - [Log partition=__consumer_offsets-0, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
09:51:26.866 [kafka-request-handler-2] DEBUG kafka.utils.KafkaScheduler - Scheduling task PeriodicProducerExpirationCheck with initial delay 600000 ms and period 600000 ms.
09:51:26.866 [kafka-request-handler-2] INFO kafka.log.LogManager - Created log for partition __consumer_offsets-0 in /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
09:51:26.866 [kafka-request-handler-2] INFO kafka.cluster.Partition - [Partition __consumer_offsets-0 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-0
09:51:26.866 [kafka-request-handler-2] INFO kafka.cluster.Replica - Replica loaded for partition __consumer_offsets-0 with initial high watermark 0
09:51:26.866 [kafka-request-handler-2] INFO kafka.cluster.Partition - [Partition __consumer_offsets-0 broker=0] __consumer_offsets-0 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
09:51:26.866 [kafka-request-handler-2] DEBUG kafka.server.epoch.LeaderEpochFileCache - [LeaderEpochCache __consumer_offsets-0] Appended new epoch entry EpochEntry(epoch=0, startOffset=0). Cache now contains 1 entries.
09:51:26.868 [kafka-request-handler-2] DEBUG kafka.cluster.Partition - [Partition __consumer_offsets-0 broker=0] Skipping update high watermark since new hw (offset=0 segment=[0:0]) is not larger than old hw (offset=0 segment=[0:0]). All current LEOs are Set(replica 0: (offset=0 segment=[0:0]))
09:51:26.868 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x60 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics/__consumer_offsets
09:51:26.868 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x60 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics/__consumer_offsets
09:51:26.868 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/topics/__consumer_offsets serverPath:/config/topics/__consumer_offsets finished:false header:: 96,4  replyHeader:: 96,53,0  request:: '/config/topics/__consumer_offsets,F  response:: #7b2276657273696f6e223a312c22636f6e666967223a7b227365676d656e742e6279746573223a22313034383537363030222c22636f6d7072657373696f6e2e74797065223a2270726f6475636572222c22636c65616e75702e706f6c696379223a22636f6d70616374227d7d,s{41,41,1566517886843,1566517886843,0,0,0,0,109,0,41} 
09:51:26.870 [kafka-request-handler-2] DEBUG kafka.log.OffsetIndex - Loaded index file /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473/__consumer_offsets-4/00000000000000000000.index with maxEntries = 1310720, maxIndexSize = 10485760, entries = 0, lastOffset = 0, file position = 0
09:51:26.871 [kafka-request-handler-2] INFO kafka.log.Log - [Log partition=__consumer_offsets-4, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Loading producer state till offset 0 with message format version 2
09:51:26.872 [kafka-request-handler-2] INFO kafka.log.Log - [Log partition=__consumer_offsets-4, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
09:51:26.873 [kafka-request-handler-2] DEBUG kafka.utils.KafkaScheduler - Scheduling task PeriodicProducerExpirationCheck with initial delay 600000 ms and period 600000 ms.
09:51:26.873 [kafka-request-handler-2] INFO kafka.log.LogManager - Created log for partition __consumer_offsets-4 in /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
09:51:26.873 [kafka-request-handler-2] INFO kafka.cluster.Partition - [Partition __consumer_offsets-4 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-4
09:51:26.873 [kafka-request-handler-2] INFO kafka.cluster.Replica - Replica loaded for partition __consumer_offsets-4 with initial high watermark 0
09:51:26.873 [kafka-request-handler-2] INFO kafka.cluster.Partition - [Partition __consumer_offsets-4 broker=0] __consumer_offsets-4 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
09:51:26.873 [kafka-request-handler-2] DEBUG kafka.server.epoch.LeaderEpochFileCache - [LeaderEpochCache __consumer_offsets-4] Appended new epoch entry EpochEntry(epoch=0, startOffset=0). Cache now contains 1 entries.
09:51:26.874 [kafka-request-handler-2] DEBUG kafka.cluster.Partition - [Partition __consumer_offsets-4 broker=0] Skipping update high watermark since new hw (offset=0 segment=[0:0]) is not larger than old hw (offset=0 segment=[0:0]). All current LEOs are Set(replica 0: (offset=0 segment=[0:0]))
09:51:26.875 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x61 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics/__consumer_offsets
09:51:26.875 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x61 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics/__consumer_offsets
09:51:26.875 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/topics/__consumer_offsets serverPath:/config/topics/__consumer_offsets finished:false header:: 97,4  replyHeader:: 97,53,0  request:: '/config/topics/__consumer_offsets,F  response:: #7b2276657273696f6e223a312c22636f6e666967223a7b227365676d656e742e6279746573223a22313034383537363030222c22636f6d7072657373696f6e2e74797065223a2270726f6475636572222c22636c65616e75702e706f6c696379223a22636f6d70616374227d7d,s{41,41,1566517886843,1566517886843,0,0,0,0,109,0,41} 
09:51:26.877 [kafka-request-handler-2] DEBUG kafka.log.OffsetIndex - Loaded index file /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473/__consumer_offsets-1/00000000000000000000.index with maxEntries = 1310720, maxIndexSize = 10485760, entries = 0, lastOffset = 0, file position = 0
09:51:26.877 [kafka-request-handler-2] INFO kafka.log.Log - [Log partition=__consumer_offsets-1, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Loading producer state till offset 0 with message format version 2
09:51:26.878 [kafka-request-handler-2] INFO kafka.log.Log - [Log partition=__consumer_offsets-1, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
09:51:26.879 [kafka-request-handler-2] DEBUG kafka.utils.KafkaScheduler - Scheduling task PeriodicProducerExpirationCheck with initial delay 600000 ms and period 600000 ms.
09:51:26.879 [kafka-request-handler-2] INFO kafka.log.LogManager - Created log for partition __consumer_offsets-1 in /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
09:51:26.879 [kafka-request-handler-2] INFO kafka.cluster.Partition - [Partition __consumer_offsets-1 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-1
09:51:26.879 [kafka-request-handler-2] INFO kafka.cluster.Replica - Replica loaded for partition __consumer_offsets-1 with initial high watermark 0
09:51:26.880 [kafka-request-handler-2] INFO kafka.cluster.Partition - [Partition __consumer_offsets-1 broker=0] __consumer_offsets-1 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
09:51:26.880 [kafka-request-handler-2] DEBUG kafka.server.epoch.LeaderEpochFileCache - [LeaderEpochCache __consumer_offsets-1] Appended new epoch entry EpochEntry(epoch=0, startOffset=0). Cache now contains 1 entries.
09:51:26.881 [kafka-request-handler-2] DEBUG kafka.cluster.Partition - [Partition __consumer_offsets-1 broker=0] Skipping update high watermark since new hw (offset=0 segment=[0:0]) is not larger than old hw (offset=0 segment=[0:0]). All current LEOs are Set(replica 0: (offset=0 segment=[0:0]))
09:51:26.881 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x62 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics/__consumer_offsets
09:51:26.881 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x62 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics/__consumer_offsets
09:51:26.882 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/topics/__consumer_offsets serverPath:/config/topics/__consumer_offsets finished:false header:: 98,4  replyHeader:: 98,53,0  request:: '/config/topics/__consumer_offsets,F  response:: #7b2276657273696f6e223a312c22636f6e666967223a7b227365676d656e742e6279746573223a22313034383537363030222c22636f6d7072657373696f6e2e74797065223a2270726f6475636572222c22636c65616e75702e706f6c696379223a22636f6d70616374227d7d,s{41,41,1566517886843,1566517886843,0,0,0,0,109,0,41} 
09:51:26.884 [kafka-request-handler-2] DEBUG kafka.log.OffsetIndex - Loaded index file /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473/__consumer_offsets-2/00000000000000000000.index with maxEntries = 1310720, maxIndexSize = 10485760, entries = 0, lastOffset = 0, file position = 0
09:51:26.884 [kafka-request-handler-2] INFO kafka.log.Log - [Log partition=__consumer_offsets-2, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Loading producer state till offset 0 with message format version 2
09:51:26.885 [kafka-request-handler-2] INFO kafka.log.Log - [Log partition=__consumer_offsets-2, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
09:51:26.885 [kafka-request-handler-2] DEBUG kafka.utils.KafkaScheduler - Scheduling task PeriodicProducerExpirationCheck with initial delay 600000 ms and period 600000 ms.
09:51:26.886 [kafka-request-handler-2] INFO kafka.log.LogManager - Created log for partition __consumer_offsets-2 in /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
09:51:26.886 [kafka-request-handler-2] INFO kafka.cluster.Partition - [Partition __consumer_offsets-2 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-2
09:51:26.886 [kafka-request-handler-2] INFO kafka.cluster.Replica - Replica loaded for partition __consumer_offsets-2 with initial high watermark 0
09:51:26.886 [kafka-request-handler-2] INFO kafka.cluster.Partition - [Partition __consumer_offsets-2 broker=0] __consumer_offsets-2 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
09:51:26.886 [kafka-request-handler-2] DEBUG kafka.server.epoch.LeaderEpochFileCache - [LeaderEpochCache __consumer_offsets-2] Appended new epoch entry EpochEntry(epoch=0, startOffset=0). Cache now contains 1 entries.
09:51:26.887 [kafka-request-handler-2] DEBUG kafka.cluster.Partition - [Partition __consumer_offsets-2 broker=0] Skipping update high watermark since new hw (offset=0 segment=[0:0]) is not larger than old hw (offset=0 segment=[0:0]). All current LEOs are Set(replica 0: (offset=0 segment=[0:0]))
09:51:26.887 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x63 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics/__consumer_offsets
09:51:26.887 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x63 zxid:0xfffffffffffffffe txntype:unknown reqpath:/config/topics/__consumer_offsets
09:51:26.888 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/config/topics/__consumer_offsets serverPath:/config/topics/__consumer_offsets finished:false header:: 99,4  replyHeader:: 99,53,0  request:: '/config/topics/__consumer_offsets,F  response:: #7b2276657273696f6e223a312c22636f6e666967223a7b227365676d656e742e6279746573223a22313034383537363030222c22636f6d7072657373696f6e2e74797065223a2270726f6475636572222c22636c65616e75702e706f6c696379223a22636f6d70616374227d7d,s{41,41,1566517886843,1566517886843,0,0,0,0,109,0,41} 
09:51:26.890 [kafka-request-handler-2] DEBUG kafka.log.OffsetIndex - Loaded index file /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473/__consumer_offsets-3/00000000000000000000.index with maxEntries = 1310720, maxIndexSize = 10485760, entries = 0, lastOffset = 0, file position = 0
09:51:26.890 [kafka-request-handler-2] INFO kafka.log.Log - [Log partition=__consumer_offsets-3, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Loading producer state till offset 0 with message format version 2
09:51:26.891 [kafka-request-handler-2] INFO kafka.log.Log - [Log partition=__consumer_offsets-3, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Completed load of log with 1 segments, log start offset 0 and log end offset 0 in 2 ms
09:51:26.892 [kafka-request-handler-2] DEBUG kafka.utils.KafkaScheduler - Scheduling task PeriodicProducerExpirationCheck with initial delay 600000 ms and period 600000 ms.
09:51:26.892 [kafka-request-handler-2] INFO kafka.log.LogManager - Created log for partition __consumer_offsets-3 in /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473 with properties {compression.type -> producer, message.format.version -> 2.0-IV1, file.delete.delay.ms -> 1000, max.message.bytes -> 1000012, min.compaction.lag.ms -> 0, message.timestamp.type -> CreateTime, message.downconversion.enable -> true, min.insync.replicas -> 1, segment.jitter.ms -> 0, preallocate -> false, min.cleanable.dirty.ratio -> 0.5, index.interval.bytes -> 4096, unclean.leader.election.enable -> false, retention.bytes -> -1, delete.retention.ms -> 86400000, cleanup.policy -> compact, flush.ms -> 9223372036854775807, segment.ms -> 604800000, segment.bytes -> 104857600, retention.ms -> 604800000, message.timestamp.difference.max.ms -> 9223372036854775807, segment.index.bytes -> 10485760, flush.messages -> 9223372036854775807}.
09:51:26.892 [kafka-request-handler-2] INFO kafka.cluster.Partition - [Partition __consumer_offsets-3 broker=0] No checkpointed highwatermark is found for partition __consumer_offsets-3
09:51:26.892 [kafka-request-handler-2] INFO kafka.cluster.Replica - Replica loaded for partition __consumer_offsets-3 with initial high watermark 0
09:51:26.892 [kafka-request-handler-2] INFO kafka.cluster.Partition - [Partition __consumer_offsets-3 broker=0] __consumer_offsets-3 starts at Leader Epoch 0 from offset 0. Previous Leader Epoch was: -1
09:51:26.892 [kafka-request-handler-2] DEBUG kafka.server.epoch.LeaderEpochFileCache - [LeaderEpochCache __consumer_offsets-3] Appended new epoch entry EpochEntry(epoch=0, startOffset=0). Cache now contains 1 entries.
09:51:26.893 [kafka-request-handler-2] DEBUG kafka.cluster.Partition - [Partition __consumer_offsets-3 broker=0] Skipping update high watermark since new hw (offset=0 segment=[0:0]) is not larger than old hw (offset=0 segment=[0:0]). All current LEOs are Set(replica 0: (offset=0 segment=[0:0]))
09:51:26.894 [kafka-request-handler-2] INFO kafka.server.ReplicaAlterLogDirsManager - [ReplicaAlterLogDirsManager on broker 0] Added fetcher for partitions List()
09:51:26.895 [kafka-request-handler-2] INFO kafka.coordinator.group.GroupMetadataManager - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-3
09:51:26.895 [kafka-request-handler-2] DEBUG kafka.utils.KafkaScheduler - Scheduling task __consumer_offsets-3 with initial delay 0 ms and period -1 ms.
09:51:26.895 [kafka-request-handler-2] INFO kafka.coordinator.group.GroupMetadataManager - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-2
09:51:26.895 [kafka-request-handler-2] DEBUG kafka.utils.KafkaScheduler - Scheduling task __consumer_offsets-2 with initial delay 0 ms and period -1 ms.
09:51:26.895 [kafka-request-handler-2] INFO kafka.coordinator.group.GroupMetadataManager - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-1
09:51:26.895 [kafka-request-handler-2] DEBUG kafka.utils.KafkaScheduler - Scheduling task __consumer_offsets-1 with initial delay 0 ms and period -1 ms.
09:51:26.895 [kafka-request-handler-2] INFO kafka.coordinator.group.GroupMetadataManager - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-4
09:51:26.895 [kafka-request-handler-2] DEBUG kafka.utils.KafkaScheduler - Scheduling task __consumer_offsets-4 with initial delay 0 ms and period -1 ms.
09:51:26.896 [kafka-request-handler-2] INFO kafka.coordinator.group.GroupMetadataManager - [GroupMetadataManager brokerId=0] Scheduling loading of offsets and group metadata from __consumer_offsets-0
09:51:26.896 [kafka-request-handler-2] DEBUG kafka.utils.KafkaScheduler - Scheduling task __consumer_offsets-0 with initial delay 0 ms and period -1 ms.
09:51:26.896 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=LEADER_AND_ISR, apiVersion=1, clientId=0, correlationId=3) -- {controller_id=0,controller_epoch=1,partition_states=[{topic=__consumer_offsets,partition=0,controller_epoch=1,leader=0,leader_epoch=0,isr=[0],zk_version=0,replicas=[0],is_new=true},{topic=__consumer_offsets,partition=3,controller_epoch=1,leader=0,leader_epoch=0,isr=[0],zk_version=0,replicas=[0],is_new=true},{topic=__consumer_offsets,partition=4,controller_epoch=1,leader=0,leader_epoch=0,isr=[0],zk_version=0,replicas=[0],is_new=true},{topic=__consumer_offsets,partition=1,controller_epoch=1,leader=0,leader_epoch=0,isr=[0],zk_version=0,replicas=[0],is_new=true},{topic=__consumer_offsets,partition=2,controller_epoch=1,leader=0,leader_epoch=0,isr=[0],zk_version=0,replicas=[0],is_new=true}],live_leaders=[{id=0,host=localhost,port=59716}]},response:{error_code=0,partitions=[{topic=__consumer_offsets,partition=2,error_code=0},{topic=__consumer_offsets,partition=4,error_code=0},{topic=__consumer_offsets,partition=1,error_code=0},{topic=__consumer_offsets,partition=3,error_code=0},{topic=__consumer_offsets,partition=0,error_code=0}]} from connection 127.0.0.1:59716-127.0.0.1:59717-0;totalTime:38.706,requestQueueTime:0.113,localTime:38.339,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.076,sendTime:0.197,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.898 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=UPDATE_METADATA, apiVersion=4, clientId=0, correlationId=4) -- {controller_id=0,controller_epoch=1,partition_states=[{topic=__consumer_offsets,partition=0,controller_epoch=1,leader=0,leader_epoch=0,isr=[0],zk_version=0,replicas=[0],offline_replicas=[]},{topic=__consumer_offsets,partition=3,controller_epoch=1,leader=0,leader_epoch=0,isr=[0],zk_version=0,replicas=[0],offline_replicas=[]},{topic=__consumer_offsets,partition=4,controller_epoch=1,leader=0,leader_epoch=0,isr=[0],zk_version=0,replicas=[0],offline_replicas=[]},{topic=__consumer_offsets,partition=1,controller_epoch=1,leader=0,leader_epoch=0,isr=[0],zk_version=0,replicas=[0],offline_replicas=[]},{topic=__consumer_offsets,partition=2,controller_epoch=1,leader=0,leader_epoch=0,isr=[0],zk_version=0,replicas=[0],offline_replicas=[]}],live_brokers=[{id=0,end_points=[{port=59716,host=localhost,listener_name=PLAINTEXT,security_protocol_type=0}],rack=null}]},response:{error_code=0} from connection 127.0.0.1:59716-127.0.0.1:59717-0;totalTime:0.53,requestQueueTime:0.137,localTime:0.23,remoteTime:0.0,throttleTime:0.0,responseQueueTime:0.052,sendTime:0.125,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.903 [group-metadata-manager-0] INFO kafka.coordinator.group.GroupMetadataManager - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-3 in 8 milliseconds.
09:51:26.903 [group-metadata-manager-0] INFO kafka.coordinator.group.GroupMetadataManager - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-2 in 0 milliseconds.
09:51:26.904 [group-metadata-manager-0] INFO kafka.coordinator.group.GroupMetadataManager - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-1 in 0 milliseconds.
09:51:26.904 [group-metadata-manager-0] INFO kafka.coordinator.group.GroupMetadataManager - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-4 in 0 milliseconds.
09:51:26.904 [group-metadata-manager-0] INFO kafka.coordinator.group.GroupMetadataManager - [GroupMetadataManager brokerId=0] Finished loading offsets and group metadata from __consumer_offsets-0 in 0 milliseconds.
09:51:26.933 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initialize connection to node localhost:59716 (id: 0 rack: null) for sending metadata request
09:51:26.933 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initiating connection to node localhost:59716 (id: 0 rack: null)
09:51:26.933 [templateTests-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-sent
09:51:26.934 [kafka-socket-acceptor-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Acceptor - Accepted connection from /127.0.0.1:59722 on /127.0.0.1:59716 and assigned it to processor 2, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400]
09:51:26.934 [templateTests-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.bytes-received
09:51:26.934 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG kafka.network.Processor - Processor 2 listening to new connection from /127.0.0.1:59722
09:51:26.934 [templateTests-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-0.latency
09:51:26.934 [templateTests-C-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-2, groupId=testT] Created socket with SO_RCVBUF = 342972, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node 0
09:51:26.934 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Completed connection to node 0. Fetching API versions.
09:51:26.934 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initiating API versions fetch from node 0.
09:51:26.935 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=API_VERSIONS, apiVersion=2, clientId=consumer-2, correlationId=3) -- {},response:{error_code=0,api_versions=[{api_key=0,min_version=0,max_version=6},{api_key=1,min_version=0,max_version=8},{api_key=2,min_version=0,max_version=3},{api_key=3,min_version=0,max_version=6},{api_key=4,min_version=0,max_version=1},{api_key=5,min_version=0,max_version=0},{api_key=6,min_version=0,max_version=4},{api_key=7,min_version=0,max_version=1},{api_key=8,min_version=0,max_version=4},{api_key=9,min_version=0,max_version=4},{api_key=10,min_version=0,max_version=2},{api_key=11,min_version=0,max_version=3},{api_key=12,min_version=0,max_version=2},{api_key=13,min_version=0,max_version=2},{api_key=14,min_version=0,max_version=2},{api_key=15,min_version=0,max_version=2},{api_key=16,min_version=0,max_version=2},{api_key=17,min_version=0,max_version=1},{api_key=18,min_version=0,max_version=2},{api_key=19,min_version=0,max_version=3},{api_key=20,min_version=0,max_version=2},{api_key=21,min_version=0,max_version=1},{api_key=22,min_version=0,max_version=1},{api_key=23,min_version=0,max_version=1},{api_key=24,min_version=0,max_version=1},{api_key=25,min_version=0,max_version=1},{api_key=26,min_version=0,max_version=1},{api_key=27,min_version=0,max_version=0},{api_key=28,min_version=0,max_version=1},{api_key=29,min_version=0,max_version=1},{api_key=30,min_version=0,max_version=1},{api_key=31,min_version=0,max_version=1},{api_key=32,min_version=0,max_version=2},{api_key=33,min_version=0,max_version=1},{api_key=34,min_version=0,max_version=1},{api_key=35,min_version=0,max_version=1},{api_key=36,min_version=0,max_version=0},{api_key=37,min_version=0,max_version=1},{api_key=38,min_version=0,max_version=1},{api_key=39,min_version=0,max_version=1},{api_key=40,min_version=0,max_version=1},{api_key=41,min_version=0,max_version=1},{api_key=42,min_version=0,max_version=1}],throttle_time_ms=0} from connection 127.0.0.1:59716-127.0.0.1:59722-1;totalTime:0.571,requestQueueTime:0.047,localTime:0.344,remoteTime:0.0,throttleTime:0.309,responseQueueTime:0.054,sendTime:0.142,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.936 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Recorded API versions for node 0: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
09:51:26.936 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Sending metadata request (type=MetadataRequest, topics=templateTopic) to node localhost:59716 (id: 0 rack: null)
09:51:26.937 [templateTests-C-1] DEBUG org.apache.kafka.clients.Metadata - Updated cluster metadata version 3 to Cluster(id = zfAayvJzT1W78feO7Y00sA, nodes = [localhost:59716 (id: 0 rack: null)], partitions = [Partition(topic = templateTopic, partition = 0, leader = 0, replicas = [0], isr = [0], offlineReplicas = []), Partition(topic = templateTopic, partition = 1, leader = 0, replicas = [0], isr = [0], offlineReplicas = [])], controller = localhost:59716 (id: 0 rack: null))
09:51:26.937 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=testT] Sending FindCoordinator request to broker localhost:59716 (id: 0 rack: null)
09:51:26.937 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=METADATA, apiVersion=6, clientId=consumer-2, correlationId=4) -- {topics=[templateTopic],allow_auto_topic_creation=true},response:{throttle_time_ms=0,brokers=[{node_id=0,host=localhost,port=59716,rack=null}],cluster_id=zfAayvJzT1W78feO7Y00sA,controller_id=0,topic_metadata=[{error_code=0,topic=templateTopic,is_internal=false,partition_metadata=[{error_code=0,partition=1,leader=0,replicas=[0],isr=[0],offline_replicas=[]},{error_code=0,partition=0,leader=0,replicas=[0],isr=[0],offline_replicas=[]}]}]} from connection 127.0.0.1:59716-127.0.0.1:59722-1;totalTime:0.785,requestQueueTime:0.089,localTime:0.534,remoteTime:0.0,throttleTime:0.251,responseQueueTime:0.056,sendTime:0.123,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.940 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=2, clientId=consumer-2, correlationId=5) -- {coordinator_key=testT,coordinator_type=0},response:{throttle_time_ms=0,error_code=0,error_message=null,coordinator={node_id=0,host=localhost,port=59716}} from connection 127.0.0.1:59716-127.0.0.1:59722-1;totalTime:2.076,requestQueueTime:0.072,localTime:1.772,remoteTime:0.0,throttleTime:1.468,responseQueueTime:0.072,sendTime:0.18,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.940 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=testT] Received FindCoordinator response ClientResponse(receivedTimeMs=1566517886940, latencyMs=3, disconnected=false, requestHeader=RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=2, clientId=consumer-2, correlationId=5), responseBody=FindCoordinatorResponse(throttleTimeMs=0, errorMessage='null', error=NONE, node=localhost:59716 (id: 0 rack: null)))
09:51:26.940 [templateTests-C-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=testT] Discovered group coordinator localhost:59716 (id: 2147483647 rack: null)
09:51:26.940 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initiating connection to node localhost:59716 (id: 2147483647 rack: null)
09:51:26.941 [kafka-socket-acceptor-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Acceptor - Accepted connection from /127.0.0.1:59723 on /127.0.0.1:59716 and assigned it to processor 0, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400]
09:51:26.941 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Processor - Processor 0 listening to new connection from /127.0.0.1:59723
09:51:26.942 [templateTests-C-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=testT] Revoking previously assigned partitions []
09:51:26.942 [kafka-coordinator-heartbeat-thread | testT] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=testT] Heartbeat thread started
09:51:26.942 [templateTests-C-1] INFO org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions revoked: []
09:51:26.942 [templateTests-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Commit list: {}
09:51:26.942 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=testT] Disabling heartbeat thread
09:51:26.942 [templateTests-C-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=testT] (Re-)joining group
09:51:26.944 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=testT] Sending JoinGroup ((type: JoinGroupRequest, groupId=testT, sessionTimeout=60000, rebalanceTimeout=300000, memberId=, protocolType=consumer, groupProtocols=org.apache.kafka.common.requests.JoinGroupRequest$ProtocolMetadata@2888e28d)) to coordinator localhost:59716 (id: 2147483647 rack: null)
09:51:26.945 [templateTests-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-sent
09:51:26.945 [templateTests-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.bytes-received
09:51:26.945 [templateTests-C-1] DEBUG org.apache.kafka.common.metrics.Metrics - Added sensor with name node-2147483647.latency
09:51:26.945 [templateTests-C-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-2, groupId=testT] Created socket with SO_RCVBUF = 342972, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node 2147483647
09:51:26.945 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Completed connection to node 2147483647. Fetching API versions.
09:51:26.945 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initiating API versions fetch from node 2147483647.
09:51:26.955 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=API_VERSIONS, apiVersion=2, clientId=consumer-2, correlationId=7) -- {},response:{error_code=0,api_versions=[{api_key=0,min_version=0,max_version=6},{api_key=1,min_version=0,max_version=8},{api_key=2,min_version=0,max_version=3},{api_key=3,min_version=0,max_version=6},{api_key=4,min_version=0,max_version=1},{api_key=5,min_version=0,max_version=0},{api_key=6,min_version=0,max_version=4},{api_key=7,min_version=0,max_version=1},{api_key=8,min_version=0,max_version=4},{api_key=9,min_version=0,max_version=4},{api_key=10,min_version=0,max_version=2},{api_key=11,min_version=0,max_version=3},{api_key=12,min_version=0,max_version=2},{api_key=13,min_version=0,max_version=2},{api_key=14,min_version=0,max_version=2},{api_key=15,min_version=0,max_version=2},{api_key=16,min_version=0,max_version=2},{api_key=17,min_version=0,max_version=1},{api_key=18,min_version=0,max_version=2},{api_key=19,min_version=0,max_version=3},{api_key=20,min_version=0,max_version=2},{api_key=21,min_version=0,max_version=1},{api_key=22,min_version=0,max_version=1},{api_key=23,min_version=0,max_version=1},{api_key=24,min_version=0,max_version=1},{api_key=25,min_version=0,max_version=1},{api_key=26,min_version=0,max_version=1},{api_key=27,min_version=0,max_version=0},{api_key=28,min_version=0,max_version=1},{api_key=29,min_version=0,max_version=1},{api_key=30,min_version=0,max_version=1},{api_key=31,min_version=0,max_version=1},{api_key=32,min_version=0,max_version=2},{api_key=33,min_version=0,max_version=1},{api_key=34,min_version=0,max_version=1},{api_key=35,min_version=0,max_version=1},{api_key=36,min_version=0,max_version=0},{api_key=37,min_version=0,max_version=1},{api_key=38,min_version=0,max_version=1},{api_key=39,min_version=0,max_version=1},{api_key=40,min_version=0,max_version=1},{api_key=41,min_version=0,max_version=1},{api_key=42,min_version=0,max_version=1}],throttle_time_ms=0} from connection 127.0.0.1:59716-127.0.0.1:59723-2;totalTime:9.043,requestQueueTime:0.041,localTime:8.766,remoteTime:0.0,throttleTime:8.726,responseQueueTime:0.089,sendTime:0.17,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.955 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Recorded API versions for node 2147483647: (Produce(0): 0 to 6 [usable: 6], Fetch(1): 0 to 8 [usable: 8], ListOffsets(2): 0 to 3 [usable: 3], Metadata(3): 0 to 6 [usable: 6], LeaderAndIsr(4): 0 to 1 [usable: 1], StopReplica(5): 0 [usable: 0], UpdateMetadata(6): 0 to 4 [usable: 4], ControlledShutdown(7): 0 to 1 [usable: 1], OffsetCommit(8): 0 to 4 [usable: 4], OffsetFetch(9): 0 to 4 [usable: 4], FindCoordinator(10): 0 to 2 [usable: 2], JoinGroup(11): 0 to 3 [usable: 3], Heartbeat(12): 0 to 2 [usable: 2], LeaveGroup(13): 0 to 2 [usable: 2], SyncGroup(14): 0 to 2 [usable: 2], DescribeGroups(15): 0 to 2 [usable: 2], ListGroups(16): 0 to 2 [usable: 2], SaslHandshake(17): 0 to 1 [usable: 1], ApiVersions(18): 0 to 2 [usable: 2], CreateTopics(19): 0 to 3 [usable: 3], DeleteTopics(20): 0 to 2 [usable: 2], DeleteRecords(21): 0 to 1 [usable: 1], InitProducerId(22): 0 to 1 [usable: 1], OffsetForLeaderEpoch(23): 0 to 1 [usable: 1], AddPartitionsToTxn(24): 0 to 1 [usable: 1], AddOffsetsToTxn(25): 0 to 1 [usable: 1], EndTxn(26): 0 to 1 [usable: 1], WriteTxnMarkers(27): 0 [usable: 0], TxnOffsetCommit(28): 0 to 1 [usable: 1], DescribeAcls(29): 0 to 1 [usable: 1], CreateAcls(30): 0 to 1 [usable: 1], DeleteAcls(31): 0 to 1 [usable: 1], DescribeConfigs(32): 0 to 2 [usable: 2], AlterConfigs(33): 0 to 1 [usable: 1], AlterReplicaLogDirs(34): 0 to 1 [usable: 1], DescribeLogDirs(35): 0 to 1 [usable: 1], SaslAuthenticate(36): 0 [usable: 0], CreatePartitions(37): 0 to 1 [usable: 1], CreateDelegationToken(38): 0 to 1 [usable: 1], RenewDelegationToken(39): 0 to 1 [usable: 1], ExpireDelegationToken(40): 0 to 1 [usable: 1], DescribeDelegationToken(41): 0 to 1 [usable: 1], DeleteGroups(42): 0 to 1 [usable: 1])
09:51:26.966 [kafka-request-handler-0] INFO kafka.coordinator.group.GroupCoordinator - [GroupCoordinator 0]: Preparing to rebalance group testT with old generation 0 (__consumer_offsets-2)
09:51:26.971 [executor-Rebalance] INFO kafka.coordinator.group.GroupCoordinator - [GroupCoordinator 0]: Stabilized group testT generation 1 (__consumer_offsets-2)
09:51:26.975 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=testT] Received successful JoinGroup response: JoinGroupResponse(throttleTimeMs=0, error=NONE, generationId=1, groupProtocol=range, memberId=consumer-2-56b6edc0-daa3-4948-8a1a-168802f6b42e, leaderId=consumer-2-56b6edc0-daa3-4948-8a1a-168802f6b42e, members=consumer-2-56b6edc0-daa3-4948-8a1a-168802f6b42e)
09:51:26.975 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=JOIN_GROUP, apiVersion=3, clientId=consumer-2, correlationId=6) -- {group_id=testT,session_timeout=60000,rebalance_timeout=300000,member_id=,protocol_type=consumer,group_protocols=[{protocol_name=range,protocol_metadata=java.nio.HeapByteBuffer[pos=0 lim=25 cap=25]}]},response:{throttle_time_ms=0,error_code=0,generation_id=1,group_protocol=range,leader_id=consumer-2-56b6edc0-daa3-4948-8a1a-168802f6b42e,member_id=consumer-2-56b6edc0-daa3-4948-8a1a-168802f6b42e,members=[{member_id=consumer-2-56b6edc0-daa3-4948-8a1a-168802f6b42e,member_metadata=java.nio.HeapByteBuffer[pos=0 lim=25 cap=25]}]} from connection 127.0.0.1:59716-127.0.0.1:59723-2;totalTime:19.039,requestQueueTime:0.095,localTime:11.2,remoteTime:6.667,throttleTime:0.807,responseQueueTime:0.105,sendTime:0.162,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:26.975 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=testT] Performing assignment using strategy range with subscriptions {consumer-2-56b6edc0-daa3-4948-8a1a-168802f6b42e=Subscription(topics=[templateTopic])}
09:51:26.976 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=testT] Finished assignment for group: {consumer-2-56b6edc0-daa3-4948-8a1a-168802f6b42e=Assignment(partitions=[templateTopic-0, templateTopic-1])}
09:51:26.976 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=testT] Sending leader SyncGroup to coordinator localhost:59716 (id: 2147483647 rack: null): (type=SyncGroupRequest, groupId=testT, generationId=1, memberId=consumer-2-56b6edc0-daa3-4948-8a1a-168802f6b42e, groupAssignment=consumer-2-56b6edc0-daa3-4948-8a1a-168802f6b42e)
09:51:26.979 [kafka-request-handler-1] INFO kafka.coordinator.group.GroupCoordinator - [GroupCoordinator 0]: Assignment received from leader for group testT for generation 1
09:51:27.013 [kafka-request-handler-1] DEBUG kafka.server.ReplicaManager - [ReplicaManager broker=0] Request key __consumer_offsets-2 unblocked 0 fetch requests.
09:51:27.014 [kafka-request-handler-1] DEBUG kafka.cluster.Partition - [Partition __consumer_offsets-2 broker=0] High watermark updated to (offset=1 segment=[0:306])
09:51:27.014 [kafka-request-handler-1] DEBUG kafka.server.ReplicaManager - [ReplicaManager broker=0] Request key __consumer_offsets-2 unblocked 0 fetch requests.
09:51:27.014 [kafka-request-handler-1] DEBUG kafka.server.ReplicaManager - [ReplicaManager broker=0] Request key __consumer_offsets-2 unblocked 0 producer requests.
09:51:27.015 [kafka-request-handler-1] DEBUG kafka.server.ReplicaManager - [ReplicaManager broker=0] Request key __consumer_offsets-2 unblocked 0 DeleteRecordsRequest.
09:51:27.016 [kafka-request-handler-1] DEBUG kafka.server.ReplicaManager - [ReplicaManager broker=0] Produce to local log in 22 ms
09:51:27.023 [templateTests-C-1] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=testT] Successfully joined group with generation 1
09:51:27.023 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=testT] Enabling heartbeat thread
09:51:27.023 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=SYNC_GROUP, apiVersion=2, clientId=consumer-2, correlationId=8) -- {group_id=testT,generation_id=1,member_id=consumer-2-56b6edc0-daa3-4948-8a1a-168802f6b42e,group_assignment=[{member_id=consumer-2-56b6edc0-daa3-4948-8a1a-168802f6b42e,member_assignment=java.nio.HeapByteBuffer[pos=0 lim=37 cap=37]}]},response:{throttle_time_ms=0,error_code=0,member_assignment=java.nio.HeapByteBuffer[pos=0 lim=37 cap=37]} from connection 127.0.0.1:59716-127.0.0.1:59723-2;totalTime:45.343,requestQueueTime:0.093,localTime:45.201,remoteTime:0.0,throttleTime:0.459,responseQueueTime:0.089,sendTime:0.185,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:27.024 [templateTests-C-1] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=testT] Setting newly assigned partitions [templateTopic-0, templateTopic-1]
09:51:27.025 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=testT] Fetching committed offsets for partitions: [templateTopic-0, templateTopic-1]
09:51:27.030 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=testT] Found no committed offset for partition templateTopic-0
09:51:27.030 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=testT] Found no committed offset for partition templateTopic-1
09:51:27.030 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=OFFSET_FETCH, apiVersion=4, clientId=consumer-2, correlationId=9) -- {group_id=testT,topics=[{topic=templateTopic,partitions=[{partition=0},{partition=1}]}]},response:{throttle_time_ms=0,responses=[{topic=templateTopic,partition_responses=[{partition=0,offset=-1,metadata=,error_code=0},{partition=1,offset=-1,metadata=,error_code=0}]}],error_code=0} from connection 127.0.0.1:59716-127.0.0.1:59723-2;totalTime:3.997,requestQueueTime:0.119,localTime:3.662,remoteTime:0.0,throttleTime:3.327,responseQueueTime:0.065,sendTime:0.171,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:27.030 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-2, groupId=testT] Sending ListOffsetRequest (type=ListOffsetRequest, replicaId=-1, partitionTimestamps={templateTopic-0=-1, templateTopic-1=-1}, isolationLevel=READ_UNCOMMITTED) to broker localhost:59716 (id: 0 rack: null)
09:51:27.034 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-2, groupId=testT] Handling ListOffsetResponse response for templateTopic-0. Fetched offset 0, timestamp -1
09:51:27.035 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=LIST_OFFSETS, apiVersion=3, clientId=consumer-2, correlationId=10) -- {replica_id=-1,isolation_level=0,topics=[{topic=templateTopic,partitions=[{partition=0,timestamp=-1},{partition=1,timestamp=-1}]}]},response:{throttle_time_ms=0,responses=[{topic=templateTopic,partition_responses=[{partition=0,error_code=0,timestamp=-1,offset=0},{partition=1,error_code=0,timestamp=-1,offset=0}]}]} from connection 127.0.0.1:59716-127.0.0.1:59722-1;totalTime:2.735,requestQueueTime:0.112,localTime:2.445,remoteTime:0.0,throttleTime:0.527,responseQueueTime:0.069,sendTime:0.129,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:27.035 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-2, groupId=testT] Handling ListOffsetResponse response for templateTopic-1. Fetched offset 0, timestamp -1
09:51:27.035 [templateTests-C-1] INFO org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-2, groupId=testT] Resetting offset for partition templateTopic-0 to offset 0.
09:51:27.035 [templateTests-C-1] INFO org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-2, groupId=testT] Resetting offset for partition templateTopic-1 to offset 0.
09:51:27.036 [templateTests-C-1] DEBUG org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer - Committing on assignment: {templateTopic-0=OffsetAndMetadata{offset=0, metadata=''}, templateTopic-1=OffsetAndMetadata{offset=0, metadata=''}}
09:51:27.043 [kafka-request-handler-4] DEBUG kafka.server.ReplicaManager - [ReplicaManager broker=0] Request key __consumer_offsets-2 unblocked 0 fetch requests.
09:51:27.043 [kafka-request-handler-4] DEBUG kafka.cluster.Partition - [Partition __consumer_offsets-2 broker=0] High watermark updated to (offset=3 segment=[0:493])
09:51:27.044 [kafka-request-handler-4] DEBUG kafka.server.ReplicaManager - [ReplicaManager broker=0] Request key __consumer_offsets-2 unblocked 0 fetch requests.
09:51:27.044 [kafka-request-handler-4] DEBUG kafka.server.ReplicaManager - [ReplicaManager broker=0] Request key __consumer_offsets-2 unblocked 0 producer requests.
09:51:27.044 [kafka-request-handler-4] DEBUG kafka.server.ReplicaManager - [ReplicaManager broker=0] Request key __consumer_offsets-2 unblocked 0 DeleteRecordsRequest.
09:51:27.044 [kafka-request-handler-4] DEBUG kafka.server.ReplicaManager - [ReplicaManager broker=0] Produce to local log in 1 ms
09:51:27.047 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=testT] Committed offset 0 for partition templateTopic-0
09:51:27.047 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - [Consumer clientId=consumer-2, groupId=testT] Committed offset 0 for partition templateTopic-1
09:51:27.047 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=OFFSET_COMMIT, apiVersion=4, clientId=consumer-2, correlationId=11) -- {group_id=testT,generation_id=1,member_id=consumer-2-56b6edc0-daa3-4948-8a1a-168802f6b42e,retention_time=-1,topics=[{topic=templateTopic,partitions=[{partition=0,offset=0,metadata=},{partition=1,offset=0,metadata=}]}]},response:{throttle_time_ms=0,responses=[{topic=templateTopic,partition_responses=[{partition=0,error_code=0},{partition=1,error_code=0}]}]} from connection 127.0.0.1:59716-127.0.0.1:59723-2;totalTime:8.809,requestQueueTime:0.134,localTime:8.441,remoteTime:0.0,throttleTime:0.397,responseQueueTime:0.118,sendTime:0.143,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:27.047 [templateTests-C-1] INFO org.springframework.kafka.listener.KafkaMessageListenerContainer - partitions assigned: [templateTopic-0, templateTopic-1]
09:51:27.049 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-2, groupId=testT] Added READ_UNCOMMITTED fetch request for partition templateTopic-0 at offset 0 to node localhost:59716 (id: 0 rack: null)
09:51:27.049 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-2, groupId=testT] Added READ_UNCOMMITTED fetch request for partition templateTopic-1 at offset 0 to node localhost:59716 (id: 0 rack: null)
09:51:27.049 [templateTests-C-1] DEBUG org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-2, groupId=testT] Built full fetch (sessionId=INVALID, epoch=INITIAL) for node 0 with 2 partition(s).
09:51:27.049 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.Fetcher - [Consumer clientId=consumer-2, groupId=testT] Sending READ_UNCOMMITTED FullFetchRequest(templateTopic-0, templateTopic-1) to broker localhost:59716 (id: 0 rack: null)
09:51:27.053 [kafka-request-handler-5] DEBUG kafka.server.FetchManager - Created a new full FetchContext with 2 partition(s).
09:51:27.144 [Test worker] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [127.0.0.1:59716]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
	linger.ms = 1
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

09:51:27.146 [Test worker] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 0 ms.
09:51:27.146 [Test worker] DEBUG org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Kafka producer has been closed
09:51:27.148 [Test worker] INFO kafka.server.KafkaServer - [KafkaServer id=0] shutting down
09:51:27.149 [Test worker] INFO kafka.server.KafkaServer - [KafkaServer id=0] Starting controlled shutdown
09:51:27.150 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x64 zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller
09:51:27.150 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x64 zxid:0xfffffffffffffffe txntype:unknown reqpath:/controller
09:51:27.151 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/controller serverPath:/controller finished:false header:: 100,4  replyHeader:: 100,53,0  request:: '/controller,T  response:: #7b2276657273696f6e223a312c2262726f6b65726964223a302c2274696d657374616d70223a2231353636353137383836323738227d,s{26,26,1566517886280,1566517886280,0,0,0,72068966224297985,54,0,26} 
09:51:27.151 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:getData cxid:0x65 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids/0
09:51:27.151 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:getData cxid:0x65 zxid:0xfffffffffffffffe txntype:unknown reqpath:/brokers/ids/0
09:51:27.151 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:/brokers/ids/0 serverPath:/brokers/ids/0 finished:false header:: 101,4  replyHeader:: 101,53,0  request:: '/brokers/ids/0,T  response:: #7b226c697374656e65725f73656375726974795f70726f746f636f6c5f6d6170223a7b22504c41494e54455854223a22504c41494e54455854227d2c22656e64706f696e7473223a5b22504c41494e544558543a2f2f6c6f63616c686f73743a3539373136225d2c226a6d785f706f7274223a2d312c22686f7374223a226c6f63616c686f7374222c2274696d657374616d70223a2231353636353137383836323037222c22706f7274223a35393731362c2276657273696f6e223a347d,s{25,25,1566517886227,1566517886227,0,0,0,72068966224297985,190,0,25} 
09:51:27.152 [Test worker] DEBUG org.apache.kafka.clients.NetworkClient - [KafkaServer id=0] Initiating connection to node localhost:59716 (id: 0 rack: null)
09:51:27.152 [kafka-socket-acceptor-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Acceptor - Accepted connection from /127.0.0.1:59724 on /127.0.0.1:59716 and assigned it to processor 1, sendBufferSize [actual|requested]: [102400|102400] recvBufferSize [actual|requested]: [375636|102400]
09:51:27.153 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG kafka.network.Processor - Processor 1 listening to new connection from /127.0.0.1:59724
09:51:27.153 [Test worker] DEBUG org.apache.kafka.common.network.Selector - [KafkaServer id=0] Created socket with SO_RCVBUF = 408300, SO_SNDBUF = 146988, SO_TIMEOUT = 0 to node 0
09:51:27.153 [Test worker] DEBUG org.apache.kafka.clients.NetworkClient - [KafkaServer id=0] Completed connection to node 0. Ready.
09:51:27.157 [controller-event-thread] INFO kafka.controller.KafkaController - [Controller id=0] Shutting down broker 0
09:51:27.158 [controller-event-thread] DEBUG kafka.controller.KafkaController - [Controller id=0] All shutting down brokers: 0
09:51:27.158 [controller-event-thread] DEBUG kafka.controller.KafkaController - [Controller id=0] Live brokers: 
09:51:27.162 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG kafka.request.logger - Completed request:RequestHeader(apiKey=CONTROLLED_SHUTDOWN, apiVersion=1, clientId=0, correlationId=0) -- {broker_id=0},response:{error_code=0,partitions_remaining=[]} from connection 127.0.0.1:59716-127.0.0.1:59724-2;totalTime:8.781,requestQueueTime:0.061,localTime:1.032,remoteTime:7.443,throttleTime:0.0,responseQueueTime:0.071,sendTime:0.173,securityProtocol:PLAINTEXT,principal:User:ANONYMOUS,listener:PLAINTEXT
09:51:27.163 [Test worker] INFO kafka.server.KafkaServer - [KafkaServer id=0] Controlled shutdown succeeded
09:51:27.163 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG org.apache.kafka.common.network.Selector - [SocketServer brokerId=0] Connection with /127.0.0.1 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:96)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:335)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:296)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:562)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:498)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:427)
	at kafka.network.Processor.poll(SocketServer.scala:679)
	at kafka.network.Processor.run(SocketServer.scala:584)
	at java.lang.Thread.run(Thread.java:748)
09:51:27.164 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:
09:51:27.164 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:
09:51:27.164 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name successful-authentication:
09:51:27.164 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name failed-authentication:
09:51:27.164 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:
09:51:27.165 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:
09:51:27.165 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:
09:51:27.165 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:
09:51:27.165 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:
09:51:27.204 [Test worker] INFO kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread - [/config/changes-event-process-thread]: Shutting down
09:51:27.204 [/config/changes-event-process-thread] INFO kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread - [/config/changes-event-process-thread]: Stopped
09:51:27.206 [Test worker] INFO kafka.common.ZkNodeChangeNotificationListener$ChangeEventProcessThread - [/config/changes-event-process-thread]: Shutdown completed
09:51:27.207 [Test worker] INFO kafka.network.SocketServer - [SocketServer brokerId=0] Stopping socket server request processors
09:51:27.208 [kafka-socket-acceptor-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Acceptor - Closing server socket and selector.
09:51:27.209 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Processor - Closing selector - processor 0
09:51:27.210 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Processor - Closing selector connection 127.0.0.1:59716-127.0.0.1:59717-0
09:51:27.210 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG kafka.network.Processor - Closing selector connection 127.0.0.1:59716-127.0.0.1:59723-2
09:51:27.211 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:listener-PLAINTEXTnetworkProcessor-0
09:51:27.211 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:listener-PLAINTEXTnetworkProcessor-0
09:51:27.211 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name successful-authentication:listener-PLAINTEXTnetworkProcessor-0
09:51:27.212 [templateTests-C-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-2, groupId=testT] Connection with localhost/127.0.0.1 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:96)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:335)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:296)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:562)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:498)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:427)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:271)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:242)
	at org.apache.kafka.clients.consumer.KafkaConsumer.pollForFetches(KafkaConsumer.java:1247)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1187)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1154)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:743)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:700)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
09:51:27.212 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Node 2147483647 disconnected.
09:51:27.213 [kafka-coordinator-heartbeat-thread | testT] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Sending metadata request (type=MetadataRequest, topics=templateTopic) to node localhost:59716 (id: 0 rack: null)
09:51:27.213 [kafka-coordinator-heartbeat-thread | testT] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=testT] Group coordinator localhost:59716 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
09:51:27.214 [kafka-coordinator-heartbeat-thread | testT] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=testT] Sending FindCoordinator request to broker localhost:59716 (id: 0 rack: null)
09:51:27.214 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name failed-authentication:listener-PLAINTEXTnetworkProcessor-0
09:51:27.214 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:listener-PLAINTEXTnetworkProcessor-0
09:51:27.214 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:listener-PLAINTEXTnetworkProcessor-0
09:51:27.214 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:listener-PLAINTEXTnetworkProcessor-0
09:51:27.214 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:listener-PLAINTEXTnetworkProcessor-0
09:51:27.214 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-0] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:listener-PLAINTEXTnetworkProcessor-0
09:51:27.220 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG kafka.network.Processor - Closing selector - processor 1
09:51:27.220 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG kafka.network.Processor - Closing selector connection 127.0.0.1:59716-127.0.0.1:59721-1
09:51:27.220 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:listener-PLAINTEXTnetworkProcessor-1
09:51:27.220 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:listener-PLAINTEXTnetworkProcessor-1
09:51:27.220 [templateTests-C-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-2, groupId=testT] Connection with /127.0.0.1 disconnected
java.io.EOFException: null
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:96)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:335)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:296)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:562)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:498)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:427)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:271)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:242)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:218)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:230)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:314)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1218)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1175)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1154)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:743)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:700)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
09:51:27.220 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name successful-authentication:listener-PLAINTEXTnetworkProcessor-1
09:51:27.220 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Node -1 disconnected.
09:51:27.220 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name failed-authentication:listener-PLAINTEXTnetworkProcessor-1
09:51:27.220 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:listener-PLAINTEXTnetworkProcessor-1
09:51:27.221 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:listener-PLAINTEXTnetworkProcessor-1
09:51:27.221 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:listener-PLAINTEXTnetworkProcessor-1
09:51:27.222 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:listener-PLAINTEXTnetworkProcessor-1
09:51:27.222 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-1] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:listener-PLAINTEXTnetworkProcessor-1
09:51:27.223 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG kafka.network.Processor - Closing selector - processor 2
09:51:27.223 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG kafka.network.Processor - Closing selector connection 127.0.0.1:59716-127.0.0.1:59722-1
09:51:27.224 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:listener-PLAINTEXTnetworkProcessor-2
09:51:27.224 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:listener-PLAINTEXTnetworkProcessor-2
09:51:27.224 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name successful-authentication:listener-PLAINTEXTnetworkProcessor-2
09:51:27.224 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name failed-authentication:listener-PLAINTEXTnetworkProcessor-2
09:51:27.224 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:listener-PLAINTEXTnetworkProcessor-2
09:51:27.224 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:listener-PLAINTEXTnetworkProcessor-2
09:51:27.224 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:listener-PLAINTEXTnetworkProcessor-2
09:51:27.224 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:listener-PLAINTEXTnetworkProcessor-2
09:51:27.224 [kafka-network-thread-0-ListenerName(PLAINTEXT)-PLAINTEXT-2] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:listener-PLAINTEXTnetworkProcessor-2
09:51:27.225 [templateTests-C-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-2, groupId=testT] Connection with localhost/127.0.0.1 disconnected
java.io.IOException: Connection reset by peer
	at sun.nio.ch.FileDispatcherImpl.read0(Native Method)
	at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39)
	at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223)
	at sun.nio.ch.IOUtil.read(IOUtil.java:197)
	at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:380)
	at org.apache.kafka.common.network.PlaintextTransportLayer.read(PlaintextTransportLayer.java:104)
	at org.apache.kafka.common.network.NetworkReceive.readFrom(NetworkReceive.java:94)
	at org.apache.kafka.common.network.KafkaChannel.receive(KafkaChannel.java:335)
	at org.apache.kafka.common.network.KafkaChannel.read(KafkaChannel.java:296)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:562)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:498)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:427)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:271)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:242)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:218)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:230)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:314)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1218)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1175)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1154)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:743)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:700)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
09:51:27.225 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Node 0 disconnected.
09:51:27.225 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient - [Consumer clientId=consumer-2, groupId=testT] Cancelled request with header RequestHeader(apiKey=FETCH, apiVersion=8, clientId=consumer-2, correlationId=12) due to node 0 being disconnected
09:51:27.225 [templateTests-C-1] INFO org.apache.kafka.clients.FetchSessionHandler - [Consumer clientId=consumer-2, groupId=testT] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 0: org.apache.kafka.common.errors.DisconnectException.
09:51:27.225 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient - [Consumer clientId=consumer-2, groupId=testT] Cancelled request with header RequestHeader(apiKey=FIND_COORDINATOR, apiVersion=2, clientId=consumer-2, correlationId=14) due to node 0 being disconnected
09:51:27.225 [templateTests-C-1] DEBUG org.apache.kafka.clients.consumer.internals.AbstractCoordinator - [Consumer clientId=consumer-2, groupId=testT] Coordinator discovery failed, refreshing metadata
09:51:27.225 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:27.226 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:27.229 [Test worker] INFO kafka.network.SocketServer - [SocketServer brokerId=0] Stopped socket server request processors
09:51:27.230 [Test worker] INFO kafka.server.KafkaRequestHandlerPool - [Kafka Request Handler on Broker 0], shutting down
09:51:27.232 [kafka-request-handler-0] DEBUG kafka.server.KafkaRequestHandler - [Kafka Request Handler 0 on Broker 0], Kafka request handler 0 on broker 0 received shut down command
09:51:27.232 [kafka-request-handler-5] DEBUG kafka.server.KafkaRequestHandler - [Kafka Request Handler 5 on Broker 0], Kafka request handler 5 on broker 0 received shut down command
09:51:27.232 [kafka-request-handler-3] DEBUG kafka.server.KafkaRequestHandler - [Kafka Request Handler 3 on Broker 0], Kafka request handler 3 on broker 0 received shut down command
09:51:27.232 [kafka-request-handler-4] DEBUG kafka.server.KafkaRequestHandler - [Kafka Request Handler 4 on Broker 0], Kafka request handler 4 on broker 0 received shut down command
09:51:27.232 [kafka-request-handler-2] DEBUG kafka.server.KafkaRequestHandler - [Kafka Request Handler 2 on Broker 0], Kafka request handler 2 on broker 0 received shut down command
09:51:27.232 [kafka-request-handler-1] DEBUG kafka.server.KafkaRequestHandler - [Kafka Request Handler 1 on Broker 0], Kafka request handler 1 on broker 0 received shut down command
09:51:27.232 [kafka-request-handler-7] DEBUG kafka.server.KafkaRequestHandler - [Kafka Request Handler 7 on Broker 0], Kafka request handler 7 on broker 0 received shut down command
09:51:27.232 [kafka-request-handler-6] DEBUG kafka.server.KafkaRequestHandler - [Kafka Request Handler 6 on Broker 0], Kafka request handler 6 on broker 0 received shut down command
09:51:27.233 [Test worker] INFO kafka.server.KafkaRequestHandlerPool - [Kafka Request Handler on Broker 0], shut down completely
09:51:27.233 [Test worker] DEBUG kafka.utils.KafkaScheduler - Shutting down task scheduler.
09:51:27.235 [Test worker] INFO kafka.server.KafkaApis - [KafkaApi-0] Shutdown complete.
09:51:27.238 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-topic]: Shutting down
09:51:27.278 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initialize connection to node localhost:59716 (id: 0 rack: null) for sending metadata request
09:51:27.278 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initiating connection to node localhost:59716 (id: 0 rack: null)
09:51:27.279 [templateTests-C-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-2, groupId=testT] Connection with localhost/127.0.0.1 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:152)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:473)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:427)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:271)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:242)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:233)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:161)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:243)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:314)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1218)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1175)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1154)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:743)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:700)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
09:51:27.279 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Node 0 disconnected.
09:51:27.279 [templateTests-C-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Connection to node 0 could not be established. Broker may not be available.
09:51:27.280 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:27.287 [ExpirationReaper-0-topic] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-topic]: Stopped
09:51:27.287 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-topic]: Shutdown completed
09:51:27.289 [Test worker] INFO kafka.coordinator.transaction.TransactionCoordinator - [TransactionCoordinator id=0] Shutting down.
09:51:27.289 [Test worker] DEBUG kafka.utils.KafkaScheduler - Shutting down task scheduler.
09:51:27.290 [Test worker] INFO kafka.coordinator.transaction.ProducerIdManager - [ProducerId Manager 0]: Shutdown complete: last producerId assigned 0
09:51:27.290 [Test worker] INFO kafka.coordinator.transaction.TransactionStateManager - [Transaction State Manager 0]: Shutdown complete
09:51:27.290 [Test worker] INFO kafka.coordinator.transaction.TransactionMarkerChannelManager - [Transaction Marker Channel Manager 0]: Shutting down
09:51:27.291 [TxnMarkerSenderThread-0] INFO kafka.coordinator.transaction.TransactionMarkerChannelManager - [Transaction Marker Channel Manager 0]: Stopped
09:51:27.291 [Test worker] INFO kafka.coordinator.transaction.TransactionMarkerChannelManager - [Transaction Marker Channel Manager 0]: Shutdown completed
09:51:27.292 [Test worker] INFO kafka.coordinator.transaction.TransactionCoordinator - [TransactionCoordinator id=0] Shutdown complete.
09:51:27.292 [Test worker] INFO kafka.coordinator.group.GroupCoordinator - [GroupCoordinator 0]: Shutting down.
09:51:27.292 [Test worker] DEBUG kafka.utils.KafkaScheduler - Shutting down task scheduler.
09:51:27.292 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Heartbeat]: Shutting down
09:51:27.325 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210000 type:ping cxid:0xfffffffffffffffe zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a
09:51:27.325 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210000 type:ping cxid:0xfffffffffffffffe zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a
09:51:27.325 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x1000a57cb210000 after 0ms
09:51:27.330 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:27.384 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initialize connection to node localhost:59716 (id: 0 rack: null) for sending metadata request
09:51:27.384 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initiating connection to node localhost:59716 (id: 0 rack: null)
09:51:27.385 [templateTests-C-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-2, groupId=testT] Connection with localhost/127.0.0.1 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:152)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:473)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:427)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:271)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:242)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:233)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:161)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:243)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:314)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1218)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1175)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1154)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:743)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:700)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
09:51:27.385 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Node 0 disconnected.
09:51:27.385 [templateTests-C-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Connection to node 0 could not be established. Broker may not be available.
09:51:27.385 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:27.439 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:27.491 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:27.491 [ExpirationReaper-0-Heartbeat] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Heartbeat]: Stopped
09:51:27.491 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Heartbeat]: Shutdown completed
09:51:27.492 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Rebalance]: Shutting down
09:51:27.544 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:27.572 [executor-Fetch] DEBUG kafka.server.FetchSessionCache - Created fetch session FetchSession(id=22278050, privileged=false, partitionMap.size=2, creationMs=1566517887569, creationMs=1566517887569, epoch=1)
09:51:27.578 [executor-Fetch] DEBUG kafka.server.FullFetchContext - Full fetch context with session id 22278050 returning 2 partition(s)
09:51:27.598 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:27.608 [ExpirationReaper-0-Rebalance] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Rebalance]: Stopped
09:51:27.608 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Rebalance]: Shutdown completed
09:51:27.608 [Test worker] INFO kafka.coordinator.group.GroupCoordinator - [GroupCoordinator 0]: Shutdown complete.
09:51:27.609 [Test worker] INFO kafka.server.ReplicaManager - [ReplicaManager broker=0] Shutting down
09:51:27.610 [Test worker] INFO kafka.server.ReplicaManager$LogDirFailureHandler - [LogDirFailureHandler]: Shutting down
09:51:27.610 [LogDirFailureHandler] INFO kafka.server.ReplicaManager$LogDirFailureHandler - [LogDirFailureHandler]: Stopped
09:51:27.610 [Test worker] INFO kafka.server.ReplicaManager$LogDirFailureHandler - [LogDirFailureHandler]: Shutdown completed
09:51:27.610 [Test worker] INFO kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 0] shutting down
09:51:27.612 [Test worker] INFO kafka.server.ReplicaFetcherManager - [ReplicaFetcherManager on broker 0] shutdown completed
09:51:27.612 [Test worker] INFO kafka.server.ReplicaAlterLogDirsManager - [ReplicaAlterLogDirsManager on broker 0] shutting down
09:51:27.612 [Test worker] INFO kafka.server.ReplicaAlterLogDirsManager - [ReplicaAlterLogDirsManager on broker 0] shutdown completed
09:51:27.612 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Fetch]: Shutting down
09:51:27.651 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initialize connection to node localhost:59716 (id: 0 rack: null) for sending metadata request
09:51:27.651 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initiating connection to node localhost:59716 (id: 0 rack: null)
09:51:27.652 [templateTests-C-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-2, groupId=testT] Connection with localhost/127.0.0.1 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:152)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:473)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:427)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:271)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:242)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:233)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:161)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:243)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:314)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1218)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1175)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1154)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:743)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:700)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
09:51:27.652 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Node 0 disconnected.
09:51:27.652 [templateTests-C-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Connection to node 0 could not be established. Broker may not be available.
09:51:27.653 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:27.703 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:27.755 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:27.765 [ExpirationReaper-0-Fetch] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Fetch]: Stopped
09:51:27.765 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Fetch]: Shutdown completed
09:51:27.765 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Produce]: Shutting down
09:51:27.806 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:27.808 [ExpirationReaper-0-Produce] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Produce]: Stopped
09:51:27.808 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-Produce]: Shutdown completed
09:51:27.808 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-DeleteRecords]: Shutting down
09:51:27.857 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:27.909 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:27.962 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.008 [ExpirationReaper-0-DeleteRecords] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-DeleteRecords]: Stopped
09:51:28.008 [Test worker] INFO kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper - [ExpirationReaper-0-DeleteRecords]: Shutdown completed
09:51:28.013 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.015 [Test worker] INFO kafka.server.ReplicaManager - [ReplicaManager broker=0] Shut down completely
09:51:28.018 [Test worker] INFO kafka.log.LogManager - Shutting down.
09:51:28.020 [Test worker] INFO kafka.log.LogCleaner - Shutting down the log cleaner.
09:51:28.020 [Test worker] INFO kafka.log.LogCleaner - [kafka-log-cleaner-thread-0]: Shutting down
09:51:28.021 [kafka-log-cleaner-thread-0] INFO kafka.log.LogCleaner - [kafka-log-cleaner-thread-0]: Stopped
09:51:28.021 [Test worker] INFO kafka.log.LogCleaner - [kafka-log-cleaner-thread-0]: Shutdown completed
09:51:28.025 [Test worker] DEBUG kafka.log.LogManager - Flushing and closing logs at /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473
09:51:28.032 [pool-8-thread-1] DEBUG kafka.log.Log - [Log partition=__consumer_offsets-4, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Closing log
09:51:28.049 [pool-8-thread-1] DEBUG kafka.log.Log - [Log partition=__consumer_offsets-3, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Closing log
09:51:28.050 [pool-8-thread-1] DEBUG kafka.log.Log - [Log partition=templateTopic-0, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Closing log
09:51:28.052 [pool-8-thread-1] DEBUG kafka.log.Log - [Log partition=__consumer_offsets-2, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Flushing log up to offset 3, last flushed: 1566517886882,  current time: 1566517888052, unflushed: 3
09:51:28.059 [pool-8-thread-1] DEBUG kafka.log.Log - [Log partition=__consumer_offsets-2, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Closing log
09:51:28.060 [pool-8-thread-1] INFO kafka.log.ProducerStateManager - [ProducerStateManager partition=__consumer_offsets-2] Writing producer snapshot at offset 3
09:51:28.062 [pool-8-thread-1] DEBUG kafka.log.TimeIndex - Adding index entry 1566517887041 => 1 to 00000000000000000000.timeindex.
09:51:28.063 [pool-8-thread-1] DEBUG kafka.log.Log - [Log partition=templateTopic-1, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Closing log
09:51:28.064 [pool-8-thread-1] DEBUG kafka.log.Log - [Log partition=__consumer_offsets-0, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Closing log
09:51:28.065 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.066 [pool-8-thread-1] DEBUG kafka.log.Log - [Log partition=__consumer_offsets-1, dir=/var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473] Closing log
09:51:28.068 [Test worker] DEBUG kafka.log.LogManager - Updating recovery points at /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473
09:51:28.081 [Test worker] DEBUG kafka.log.LogManager - Updating log start offsets at /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473
09:51:28.084 [Test worker] DEBUG kafka.log.LogManager - Writing clean shutdown marker at /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-291968453170352473
09:51:28.089 [Test worker] INFO kafka.log.LogManager - Shutdown complete.
09:51:28.090 [controller-event-thread] INFO kafka.controller.ControllerEventManager$ControllerEventThread - [ControllerEventThread controllerId=0] Shutting down
09:51:28.090 [controller-event-thread] INFO kafka.controller.ControllerEventManager$ControllerEventThread - [ControllerEventThread controllerId=0] Stopped
09:51:28.090 [Test worker] INFO kafka.controller.ControllerEventManager$ControllerEventThread - [ControllerEventThread controllerId=0] Shutdown completed
09:51:28.091 [Test worker] DEBUG kafka.controller.KafkaController - [Controller id=0] Resigning
09:51:28.091 [Test worker] DEBUG kafka.controller.KafkaController - [Controller id=0] Unregister BrokerModifications handler for Set(0)
09:51:28.092 [Test worker] DEBUG kafka.utils.KafkaScheduler - Shutting down task scheduler.
09:51:28.093 [Test worker] INFO kafka.controller.PartitionStateMachine - [PartitionStateMachine controllerId=0] Stopped partition state machine
09:51:28.094 [Test worker] INFO kafka.controller.ReplicaStateMachine - [ReplicaStateMachine controllerId=0] Stopped replica state machine
09:51:28.094 [Test worker] INFO kafka.controller.RequestSendThread - [RequestSendThread controllerId=0] Shutting down
09:51:28.094 [Controller-0-to-broker-0-send-thread] INFO kafka.controller.RequestSendThread - [RequestSendThread controllerId=0] Stopped
09:51:28.094 [Test worker] INFO kafka.controller.RequestSendThread - [RequestSendThread controllerId=0] Shutdown completed
09:51:28.095 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-closed:broker-id-0
09:51:28.095 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name connections-created:broker-id-0
09:51:28.095 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name successful-authentication:broker-id-0
09:51:28.095 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name failed-authentication:broker-id-0
09:51:28.095 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent-received:broker-id-0
09:51:28.095 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-sent:broker-id-0
09:51:28.095 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name bytes-received:broker-id-0
09:51:28.095 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name select-time:broker-id-0
09:51:28.095 [Test worker] DEBUG org.apache.kafka.common.metrics.Metrics - Removed sensor with name io-time:broker-id-0
09:51:28.096 [Test worker] INFO kafka.controller.KafkaController - [Controller id=0] Resigned
09:51:28.097 [Test worker] INFO kafka.zookeeper.ZooKeeperClient - [ZooKeeperClient] Closing.
09:51:28.097 [Test worker] DEBUG org.apache.zookeeper.ZooKeeper - Closing session: 0x1000a57cb210001
09:51:28.097 [Test worker] DEBUG org.apache.zookeeper.ClientCnxn - Closing client for session: 0x1000a57cb210001
09:51:28.097 [ProcessThread(sid:0 cport:59713):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Processed session termination for sessionid: 0x1000a57cb210001
09:51:28.098 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210001 type:closeSession cxid:0x66 zxid:0x36 txntype:-11 reqpath:n/a
09:51:28.098 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Deleting ephemeral node /controller for session 0x1000a57cb210001
09:51:28.098 [SyncThread:0] DEBUG org.apache.zookeeper.server.DataTree - Deleting ephemeral node /brokers/ids/0 for session 0x1000a57cb210001
09:51:28.098 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Got notification sessionid:0x1000a57cb210001
09:51:28.098 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Got WatchedEvent state:SyncConnected type:NodeDeleted path:/controller for sessionid 0x1000a57cb210001
09:51:28.098 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210001 type:closeSession cxid:0x66 zxid:0x36 txntype:-11 reqpath:n/a
09:51:28.098 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Got notification sessionid:0x1000a57cb210001
09:51:28.098 [Test worker-EventThread] DEBUG kafka.zookeeper.ZooKeeperClient - [ZooKeeperClient] Received event: WatchedEvent state:SyncConnected type:NodeDeleted path:/controller
09:51:28.098 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Got WatchedEvent state:SyncConnected type:NodeDeleted path:/brokers/ids/0 for sessionid 0x1000a57cb210001
09:51:28.099 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Got notification sessionid:0x1000a57cb210001
09:51:28.099 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Got WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/brokers/ids for sessionid 0x1000a57cb210001
09:51:28.099 [Test worker-EventThread] DEBUG kafka.zookeeper.ZooKeeperClient - [ZooKeeperClient] Received event: WatchedEvent state:SyncConnected type:NodeDeleted path:/brokers/ids/0
09:51:28.099 [Test worker-EventThread] DEBUG kafka.zookeeper.ZooKeeperClient - [ZooKeeperClient] Received event: WatchedEvent state:SyncConnected type:NodeChildrenChanged path:/brokers/ids
09:51:28.099 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210001, packet:: clientPath:null serverPath:null finished:false header:: 102,-11  replyHeader:: 102,54,0  request:: null response:: null
09:51:28.099 [Test worker] DEBUG org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x1000a57cb210001
09:51:28.099 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Session: 0x1000a57cb210001 closed
09:51:28.099 [Test worker-EventThread] INFO org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x1000a57cb210001
09:51:28.100 [Test worker] DEBUG kafka.utils.KafkaScheduler - Shutting down task scheduler.
09:51:28.100 [Test worker] INFO kafka.zookeeper.ZooKeeperClient - [ZooKeeperClient] Closed.
09:51:28.099 [NIOServerCxn.Factory:/127.0.0.1:0] INFO org.apache.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:59715 which had sessionid 0x1000a57cb210001
09:51:28.100 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper - [ThrottledChannelReaper-Fetch]: Shutting down
09:51:28.116 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.168 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initialize connection to node localhost:59716 (id: 0 rack: null) for sending metadata request
09:51:28.168 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initiating connection to node localhost:59716 (id: 0 rack: null)
09:51:28.168 [templateTests-C-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-2, groupId=testT] Connection with localhost/127.0.0.1 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:152)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:473)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:427)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:271)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:242)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:233)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:161)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:243)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:314)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1218)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1175)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1154)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:743)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:700)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
09:51:28.169 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Node 0 disconnected.
09:51:28.169 [templateTests-C-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Connection to node 0 could not be established. Broker may not be available.
09:51:28.169 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.223 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.274 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.324 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.376 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.427 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.481 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.533 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.584 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.635 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.685 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.736 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.789 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.840 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initialize connection to node localhost:59716 (id: 0 rack: null) for sending metadata request
09:51:28.840 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initiating connection to node localhost:59716 (id: 0 rack: null)
09:51:28.840 [templateTests-C-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-2, groupId=testT] Connection with localhost/127.0.0.1 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:152)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:473)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:427)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:271)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:242)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:233)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:161)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:243)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:314)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1218)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1175)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1154)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:743)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:700)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
09:51:28.841 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Node 0 disconnected.
09:51:28.841 [templateTests-C-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Connection to node 0 could not be established. Broker may not be available.
09:51:28.841 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.895 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.948 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:28.957 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper - [ThrottledChannelReaper-Fetch]: Shutdown completed
09:51:28.957 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper - [ThrottledChannelReaper-Produce]: Shutting down
09:51:28.957 [ThrottledChannelReaper-Fetch] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper - [ThrottledChannelReaper-Fetch]: Stopped
09:51:29.000 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.053 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.107 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.163 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.213 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.264 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.314 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.326 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210000 type:ping cxid:0xfffffffffffffffe zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a
09:51:29.326 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210000 type:ping cxid:0xfffffffffffffffe zxid:0xfffffffffffffffe txntype:unknown reqpath:n/a
09:51:29.326 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Got ping response for sessionid: 0x1000a57cb210000 after 0ms
09:51:29.365 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.418 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.472 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.526 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.580 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.635 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.687 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.742 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.797 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.851 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.906 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initialize connection to node localhost:59716 (id: 0 rack: null) for sending metadata request
09:51:29.906 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initiating connection to node localhost:59716 (id: 0 rack: null)
09:51:29.907 [templateTests-C-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-2, groupId=testT] Connection with localhost/127.0.0.1 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:152)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:473)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:427)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:271)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:242)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:233)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:161)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:243)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:314)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1218)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1175)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1154)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:743)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:700)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
09:51:29.907 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Node 0 disconnected.
09:51:29.907 [templateTests-C-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Connection to node 0 could not be established. Broker may not be available.
09:51:29.907 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.961 [ThrottledChannelReaper-Produce] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper - [ThrottledChannelReaper-Produce]: Stopped
09:51:29.961 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper - [ThrottledChannelReaper-Produce]: Shutdown completed
09:51:29.961 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:29.961 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper - [ThrottledChannelReaper-Request]: Shutting down
09:51:30.015 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.067 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.119 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.172 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.223 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.274 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.329 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.384 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.438 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.493 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.547 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.598 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.651 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.703 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.754 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.807 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initialize connection to node localhost:59716 (id: 0 rack: null) for sending metadata request
09:51:30.807 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Initiating connection to node localhost:59716 (id: 0 rack: null)
09:51:30.808 [templateTests-C-1] DEBUG org.apache.kafka.common.network.Selector - [Consumer clientId=consumer-2, groupId=testT] Connection with localhost/127.0.0.1 disconnected
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.kafka.common.network.PlaintextTransportLayer.finishConnect(PlaintextTransportLayer.java:50)
	at org.apache.kafka.common.network.KafkaChannel.finishConnect(KafkaChannel.java:152)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:473)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:427)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:271)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:242)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:233)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.awaitMetadataUpdate(ConsumerNetworkClient.java:161)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator.ensureCoordinatorReady(AbstractCoordinator.java:243)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.poll(ConsumerCoordinator.java:314)
	at org.apache.kafka.clients.consumer.KafkaConsumer.updateAssignmentMetadataIfNeeded(KafkaConsumer.java:1218)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1175)
	at org.apache.kafka.clients.consumer.KafkaConsumer.poll(KafkaConsumer.java:1154)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:743)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:700)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:748)
09:51:30.808 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Node 0 disconnected.
09:51:30.808 [templateTests-C-1] WARN org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Connection to node 0 could not be established. Broker may not be available.
09:51:30.808 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.861 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.912 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.961 [ThrottledChannelReaper-Request] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper - [ThrottledChannelReaper-Request]: Stopped
09:51:30.961 [Test worker] INFO kafka.server.ClientQuotaManager$ThrottledChannelReaper - [ThrottledChannelReaper-Request]: Shutdown completed
09:51:30.963 [Test worker] INFO kafka.network.SocketServer - [SocketServer brokerId=0] Shutting down socket server
09:51:30.963 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
09:51:30.989 [Test worker] INFO kafka.network.SocketServer - [SocketServer brokerId=0] Shutdown completed
09:51:30.992 [Test worker] INFO kafka.server.KafkaServer - [KafkaServer id=0] shut down completed
09:51:31.001 [Test worker] DEBUG org.I0Itec.zkclient.ZkClient - Closing ZkClient...
09:51:31.002 [ZkClient-EventThread-19-127.0.0.1:59713] INFO org.I0Itec.zkclient.ZkEventThread - Terminate ZkClient event thread.
09:51:31.002 [Test worker] DEBUG org.I0Itec.zkclient.ZkConnection - Closing ZooKeeper connected to 127.0.0.1:59713
09:51:31.002 [Test worker] DEBUG org.apache.zookeeper.ZooKeeper - Closing session: 0x1000a57cb210000
09:51:31.002 [Test worker] DEBUG org.apache.zookeeper.ClientCnxn - Closing client for session: 0x1000a57cb210000
09:51:31.002 [ProcessThread(sid:0 cport:59713):] INFO org.apache.zookeeper.server.PrepRequestProcessor - Processed session termination for sessionid: 0x1000a57cb210000
09:51:31.004 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - Processing request:: sessionid:0x1000a57cb210000 type:closeSession cxid:0x1 zxid:0x37 txntype:-11 reqpath:n/a
09:51:31.004 [SyncThread:0] DEBUG org.apache.zookeeper.server.FinalRequestProcessor - sessionid:0x1000a57cb210000 type:closeSession cxid:0x1 zxid:0x37 txntype:-11 reqpath:n/a
09:51:31.004 [NIOServerCxn.Factory:/127.0.0.1:0] INFO org.apache.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:59714 which had sessionid 0x1000a57cb210000
09:51:31.004 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - Reading reply sessionid:0x1000a57cb210000, packet:: clientPath:null serverPath:null finished:false header:: 1,-11  replyHeader:: 1,55,0  request:: null response:: null
09:51:31.004 [Test worker] DEBUG org.apache.zookeeper.ClientCnxn - Disconnecting client for session: 0x1000a57cb210000
09:51:31.004 [Test worker] INFO org.apache.zookeeper.ZooKeeper - Session: 0x1000a57cb210000 closed
09:51:31.004 [Test worker] DEBUG org.I0Itec.zkclient.ZkClient - Closing ZkClient...done
09:51:31.005 [Test worker-EventThread] INFO org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x1000a57cb210000
09:51:31.005 [Test worker-SendThread(localhost:59713)] DEBUG org.apache.zookeeper.ClientCnxn - An exception was thrown while closing send thread for session 0x1000a57cb210000 : Unable to read additional data from server sessionid 0x1000a57cb210000, likely server has closed socket
09:51:31.005 [Test worker] INFO org.apache.zookeeper.server.ZooKeeperServer - shutting down
09:51:31.005 [Test worker] DEBUG org.apache.zookeeper.server.ZooKeeperServer - ZKShutdownHandler is not registered, so ZooKeeper server won't take any action on ERROR or SHUTDOWN server state changes
09:51:31.005 [Test worker] INFO org.apache.zookeeper.server.SessionTrackerImpl - Shutting down
09:51:31.005 [Test worker] INFO org.apache.zookeeper.server.PrepRequestProcessor - Shutting down
09:51:31.005 [ProcessThread(sid:0 cport:59713):] INFO org.apache.zookeeper.server.PrepRequestProcessor - PrepRequestProcessor exited loop!
09:51:31.005 [Test worker] INFO org.apache.zookeeper.server.SyncRequestProcessor - Shutting down
09:51:31.005 [SyncThread:0] INFO org.apache.zookeeper.server.SyncRequestProcessor - SyncRequestProcessor exited!
09:51:31.005 [Test worker] INFO org.apache.zookeeper.server.FinalRequestProcessor - shutdown of request processor complete
09:51:31.006 [Test worker] DEBUG org.apache.zookeeper.server.persistence.FileTxnLog - Created new input stream /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-4438925975171885947/version-2/log.1
09:51:31.006 [Test worker] DEBUG org.apache.zookeeper.server.persistence.FileTxnLog - Created new input archive /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-4438925975171885947/version-2/log.1
09:51:31.007 [Test worker] DEBUG org.apache.zookeeper.server.persistence.FileTxnLog - EOF excepton java.io.EOFException: Failed to read /var/folders/rb/ftkq4r193039vvt_p0103d1r0000gn/T/kafka-4438925975171885947/version-2/log.1
09:51:31.007 [NIOServerCxn.Factory:/127.0.0.1:0] INFO org.apache.zookeeper.server.NIOServerCnxnFactory - NIOServerCnxn factory exited run method
09:51:31.008 [Test worker] DEBUG org.apache.zookeeper.server.ZooKeeperServer - ZooKeeper server is not running, so not proceeding to shutdown!
09:51:31.015 [templateTests-C-1] DEBUG org.apache.kafka.clients.NetworkClient - [Consumer clientId=consumer-2, groupId=testT] Give up sending metadata request since no node is available
]]></system-out>
  <system-err><![CDATA[]]></system-err>
</testsuite>
